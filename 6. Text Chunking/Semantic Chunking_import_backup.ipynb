{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba7cf0e-ec8e-4115-be32-e49aaf5adccc",
   "metadata": {},
   "source": [
    "## Level 4: Semantic Chunking <a id=\"SemanticChunking\"></a>\n",
    "Isn't it weird that we have a global constant for chunk size? Isn't it even weirder that our normal chunking mechanisms don't take into account the actual content?\n",
    "\n",
    "I'm not the only one who thinks so\n",
    "\n",
    "<!-- <div style=\"text-align: center;\">\n",
    "    <img src=\"static/SemanticChunkingtweet.png\" style=\"max-width:50%; height:auto;\"><br>\n",
    "    <span><i><a href=\"https://twitter.com/thesephist/status/1724159343237456248?s=46\">Source</a></i></span>\n",
    "</div> -->\n",
    "\n",
    "There has to be a better way - let's explore and find out.\n",
    "\n",
    "Embeddings represent the semantic meaning of a string. They don't do much on their own, but when compared to embeddings of other texts you can start to infer the relationship between chunks. I want to lean into this property and explore using embeddings to find clusters of semantically similar texts.\n",
    "\n",
    "The hypothesis is that semantically similar chunks should be held together.\n",
    "\n",
    "I tried a few methods:\n",
    "1) **Heirarchical clustering with positional reward** - I wanted to see how heirarchical clustering of sentence embeddings would do. But because I chose to split on sentences, there was an issue with small short sentences after a long one. You know? (like this last sentenence). They could change the meaning of a chunk, so I added a positional reward and clusters were more likely to form if they were sentences next to each other. This ended up being ok, but tuning the parameters was slow and unoptimal.\n",
    "2) **Find break points between sequential sentences** - Next up I tried a walk method. I started at the first sentence, got the embedding, then compared it to sentence #2, then compared #2 and #3 and so on. I was looking for \"break points\" where embedding distance was large. If it was above a threshold, then I considered it the start of a new semantic section. I originally tried taking embeddings of every sentence, but this turned out to be too noisy. So I ended up taking groups of 3 sentences (a window), then got an embedding, then dropped the first sentence, and added the next one. This worked out a bit better.\n",
    "\n",
    "I'll show method #2 here - It's not perfect by any means, but it's a good starting point for an exploration and I'd love to hear about how you think it could be improved.\n",
    "\n",
    "First, let's load up our essay that we'll run through. I'm just doing a single essay here to keep the tokens down.\n",
    "\n",
    "We'll be using Paul Graham's [MIT essay](https://paulgraham.com/mit.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7655fbb4-73a8-43dd-a6b7-565ecf85890a",
   "metadata": {},
   "source": [
    "Great, now that we have our sentences, I want to combine the sentence before and after so that we reduce noise and capture more of the relationships between sequential sentences.\n",
    "\n",
    "Let's create a function so we can use it again. The `buffer_size` is configurable so you can select how big of a window you want. Keep this number in mind for the later steps. I'll just use `buffer_size=1` for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "503f6ed2-399e-4684-85bc-aa08ac400c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\miniconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import SemChunk as sc\n",
    "from SemChunk import Document\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "845e7668-7e9e-4d62-a8fa-c108fcc676ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mit.txt') as file:\n",
    "    document = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ecb942-438e-465d-9530-130d63d2b94c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\miniconda3\\envs\\nlp\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('D:\\\\DSAI\\\\Pre-Trained Models\\\\all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('D:\\\\DSAI\\\\Pre-Trained Models\\\\all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b348bcf3-2ff0-40f7-af4c-cbb1c7f8623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e16021-363e-49d8-af61-173b1ba8b14a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__get_sentences_timing: 1099.0056991577148ms\n",
      "__get_token_length_timing: 25.99954605102539ms\n",
      "__combine_sentences_timing: 0.0ms\n",
      "__get_embeddings_timing: 5604.042291641235ms\n",
      "__combine_sentence_embeddings_timing: 0.0ms\n",
      "__calculate_cosine_distances_timing: 4.999876022338867ms\n",
      "95 4362\n",
      "__get_optimal_chunks_timing: 7.998943328857422ms\n",
      "get_semantic_chunks_timing: 6746.0479736328125ms\n"
     ]
    }
   ],
   "source": [
    "chunks = doc.get_semantic_chunks(tokenizer=tokenizer, model=model, starting_threshold=95, step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "02790378-2bfa-4e44-a7bc-71f1b9e5b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "38bf47be-0b09-414b-aa40-53da6c2607e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = np.array([[1,2,3], [2,3,4], [5,6,7]])\n",
    "# B = np.array([[1,2,3], [1,2,3], [1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "060b1687-b81c-4b00-a7b9-37f6ecef8e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine_sim_1 = \"\"\"\n",
    "# def cos_sim(anchor_array, comparison_array):   \n",
    "#     return cosine_similarity(anchor_array, comparison_array)\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0d1d3293-b36a-40df-99b1-af7d047519e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.mean(timeit.repeat(stmt=cosine_sim_1, number=1000000, repeat=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f265f367-989a-4ed4-86f2-5302c7328737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine_sim_2 = \"\"\"\n",
    "# def cos_sim(anchor_array, comparison_array):   \n",
    "#     # return np.dot(comparison_array, anchor_array)/(norm(comparison_array, axis=1)*norm(anchor_array))\n",
    "#     # print (np.dot(comparison_array, anchor_array))\n",
    "#     # print (norm(comparison_array, axis=1))\n",
    "#     # print (norm(anchor_array, axis=1))\n",
    "#     return np.dot(comparison_array, anchor_array)/(norm(comparison_array, axis=1)*norm(anchor_array, axis=1))\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9f0fc543-0324-4164-b89a-c1c664977b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(timeit.repeat(stmt=cosine_sim_2, number=1000000, repeat=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd10be07-d75d-4629-bcca-cc6283fdeacc",
   "metadata": {},
   "source": [
    "---\n",
    "Cosine Similarity from Sklearn is of comparable speed already, no point optimising it\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "78e5101a-d0f9-43c3-bea4-4be579281e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load in nlp model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_sentences(document):\n",
    "    return [str(sentence) for sentence in nlp(document).sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "88587fe0-ada5-4319-861a-fdc3bda622cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_length(sentences, tokenizer):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    return torch.sum(encoded_input[\"attention_mask\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0d1926e8-4ed9-4286-b7ac-8279cfbd7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sentences(single_sentences_list, buffer_size=1):\n",
    "    indexed_sentences = [{'sentence': x, 'index' : i} for i, x in enumerate(single_sentences_list)]\n",
    "    # Go through each sentence dict\n",
    "    for i in range(len(indexed_sentences)):\n",
    "\n",
    "        # Create a string that will hold the sentences which are joined\n",
    "        combined_sentence = ''\n",
    "\n",
    "        # Add sentences before the current one, based on the buffer size.\n",
    "        for j in range(i - buffer_size, i):\n",
    "            # Check if the index j is not negative (to avoid index out of range like on the first one)\n",
    "            if j >= 0:\n",
    "                # Add the sentence at index j to the combined_sentence string\n",
    "                combined_sentence += indexed_sentences[j]['sentence'] + ' '\n",
    "\n",
    "        # Add the current sentence\n",
    "        combined_sentence += indexed_sentences[i]['sentence']\n",
    "\n",
    "        # Add sentences after the current one, based on the buffer size\n",
    "        for j in range(i + 1, i + 1 + buffer_size):\n",
    "            # Check if the index j is within the range of the sentences list\n",
    "            if j < len(indexed_sentences):\n",
    "                # Add the sentence at index j to the combined_sentence string\n",
    "                combined_sentence += ' ' + indexed_sentences[j]['sentence']\n",
    "\n",
    "        # Then add the whole thing to your dict\n",
    "        # Store the combined sentence in the current sentence dict\n",
    "        indexed_sentences[i]['combined_sentence'] = combined_sentence\n",
    "        # sentences[i]['combined_sentences_indexes'] = [i-buffer_size, i, i+buffer_size] # Don't need the indexes anymore\n",
    "\n",
    "    return indexed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b4fc2c82-147c-4d5b-8064-8c335843ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(sentences, model, tokenizer):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    respective_token_len = torch.sum(encoded_input[\"attention_mask\"], axis=1)\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    # Normalize embeddings\n",
    "    sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "    # return sentence_embeddings, respective_token_len\n",
    "\n",
    "    # Map into dictionary for ease of future lookup\n",
    "    emb_token_pair = [{'embedding': emb, 'token_length': length} for emb, length in zip(sentence_embeddings, respective_token_len)]\n",
    "\n",
    "    return dict(enumerate(emb_token_pair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "3f276a34-78ae-4124-b031-f8414d50dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sentence_embeddings(combined_sentences, embeddings):\n",
    "    for i, sentence in enumerate(combined_sentences):\n",
    "        sentence['combined_sentence_embedding'] = embeddings[i]['embedding']\n",
    "        sentence['token_length'] = embeddings[i][\"token_length\"]\n",
    "\n",
    "    return combined_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ed5cd556-b768-4bfe-bf2d-dba2960d2f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_distances(sentences):\n",
    "    distances = []\n",
    "    for i in range(len(sentences) - 1):\n",
    "        embedding_current = sentences[i]['combined_sentence_embedding']\n",
    "        embedding_next = sentences[i + 1]['combined_sentence_embedding']\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        similarity = cosine_similarity([embedding_current], [embedding_next])[0][0]\n",
    "        \n",
    "        # Convert to cosine distance\n",
    "        distance = 1 - similarity\n",
    "\n",
    "        # Append cosine distance to the list\n",
    "        distances.append(distance)\n",
    "\n",
    "        # Store distance in the dictionary\n",
    "        sentences[i]['distance_to_next'] = distance\n",
    "\n",
    "    # Optionally handle the last sentence\n",
    "    # sentences[-1]['distance_to_next'] = None  # or a default value\n",
    "\n",
    "    return distances, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3cc4cd21-d200-4574-935c-bee8adfa6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a7eb34eb-c903-49df-aaf0-a6d1bdd71aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sentences_list = get_sentences(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b21f0b9b-ce7d-4749-a902-f7025e4c8bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "respective_sentence_length = get_token_length(single_sentences_list, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e77c8d1f-4149-42ba-9702-4f56c44a165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_sentences = combine_sentences(single_sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "47a1983f-5ff4-47c9-88b2-fd278d1e592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_embeddings([x['combined_sentence'] for x in combined_sentences], model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "093be8e4-5d6d-4782-8825-93bc669deddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_sentences = combine_sentence_embeddings(combined_sentences, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "32ea7978-7917-40d4-ba31-bf99b763c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, _ = calculate_cosine_distances(combined_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5fa1671c-2375-4511-88e6-bb5fae7db07b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08057284355163574,\n",
       " 0.1375684142112732,\n",
       " 0.17561519145965576,\n",
       " 0.06512320041656494,\n",
       " 0.18760502338409424,\n",
       " 0.1476793885231018,\n",
       " 0.16683268547058105,\n",
       " 0.18630290031433105,\n",
       " 0.15812575817108154,\n",
       " 0.07983028888702393,\n",
       " 0.08562672138214111,\n",
       " 0.1622338891029358,\n",
       " 0.07978606224060059,\n",
       " 0.18610018491744995,\n",
       " 0.06589436531066895,\n",
       " 0.09110867977142334,\n",
       " 0.45044267177581787,\n",
       " 0.2242092490196228,\n",
       " 0.32570064067840576,\n",
       " 0.071067214012146,\n",
       " 0.18791961669921875,\n",
       " 0.10814130306243896,\n",
       " 0.09627401828765869,\n",
       " 0.23668622970581055,\n",
       " 0.2781423330307007,\n",
       " 0.11351317167282104,\n",
       " 0.2664569020271301,\n",
       " 0.27265340089797974,\n",
       " 0.2593122720718384,\n",
       " 0.2754741311073303,\n",
       " 0.09199053049087524,\n",
       " 0.32527297735214233,\n",
       " 0.7885842025279999,\n",
       " 0.3085896968841553,\n",
       " 0.1764904260635376,\n",
       " 0.5832135677337646,\n",
       " 0.38720273971557617,\n",
       " 0.3229341506958008,\n",
       " 0.3504432439804077,\n",
       " 0.17462849617004395,\n",
       " 0.20303332805633545,\n",
       " 0.272402286529541,\n",
       " 0.21797770261764526,\n",
       " 0.41525721549987793,\n",
       " 0.12195217609405518,\n",
       " 0.39996421337127686,\n",
       " 0.18376541137695312,\n",
       " 0.3260151147842407,\n",
       " 0.14166688919067383,\n",
       " 0.16475629806518555,\n",
       " 0.46901512145996094,\n",
       " 0.1890554428100586,\n",
       " 0.6911007463932037,\n",
       " 0.31579500436782837,\n",
       " 0.12639665603637695,\n",
       " 0.45682787895202637,\n",
       " 0.19163739681243896,\n",
       " 0.1971098780632019,\n",
       " 0.29990190267562866,\n",
       " 0.18545186519622803,\n",
       " 0.13161128759384155,\n",
       " 0.29354095458984375,\n",
       " 0.17007946968078613,\n",
       " 0.12362265586853027,\n",
       " 0.3272378444671631,\n",
       " 0.05673009157180786,\n",
       " 0.37116116285324097,\n",
       " 0.3967784643173218,\n",
       " 0.22782772779464722,\n",
       " 0.1611396074295044,\n",
       " 0.3425949811935425,\n",
       " 0.1575109362602234,\n",
       " 0.30207371711730957,\n",
       " 0.48306411504745483,\n",
       " 0.06345605850219727,\n",
       " 0.1414136290550232,\n",
       " 0.12875276803970337,\n",
       " 0.241446852684021,\n",
       " 0.2796895503997803,\n",
       " 0.4345623254776001,\n",
       " 0.14164108037948608,\n",
       " 0.03925609588623047,\n",
       " 0.40132570266723633,\n",
       " 0.2657172679901123,\n",
       " 0.07572793960571289,\n",
       " 0.18301337957382202,\n",
       " 0.19130194187164307,\n",
       " 0.13309651613235474,\n",
       " 0.2688930034637451,\n",
       " 0.11033117771148682,\n",
       " 0.06084096431732178,\n",
       " 0.19285863637924194,\n",
       " 0.3235095739364624,\n",
       " 0.31763768196105957,\n",
       " 0.24682384729385376,\n",
       " 0.3185156583786011,\n",
       " 0.18904608488082886,\n",
       " 0.4734870195388794,\n",
       " 0.13109862804412842,\n",
       " 0.12028515338897705,\n",
       " 0.36701083183288574,\n",
       " 0.18923377990722656,\n",
       " 0.10605514049530029,\n",
       " 0.5271275639533997,\n",
       " 0.08719098567962646,\n",
       " 0.11085700988769531,\n",
       " 0.2223745584487915,\n",
       " 0.19472086429595947,\n",
       " 0.2568981647491455,\n",
       " 0.13618683815002441,\n",
       " 0.3530334234237671,\n",
       " 0.537276953458786,\n",
       " 0.1215289831161499,\n",
       " 0.1725097894668579,\n",
       " 0.39296460151672363,\n",
       " 0.3310186266899109,\n",
       " 0.2049761414527893,\n",
       " 0.22826027870178223,\n",
       " 0.3266324996948242,\n",
       " 0.21187067031860352,\n",
       " 0.38292229175567627,\n",
       " 0.1373049020767212,\n",
       " 0.3380817174911499,\n",
       " 0.4797728657722473,\n",
       " 0.1807948350906372,\n",
       " 0.17792296409606934,\n",
       " 0.08993494510650635,\n",
       " 0.06167382001876831,\n",
       " 0.34935033321380615,\n",
       " 0.26548588275909424,\n",
       " 0.1351172924041748,\n",
       " 0.26240861415863037,\n",
       " 0.23537582159042358,\n",
       " 0.045266926288604736,\n",
       " 0.40956151485443115,\n",
       " 0.1319800615310669,\n",
       " 0.22056490182876587,\n",
       " 0.25088369846343994,\n",
       " 0.1441672444343567,\n",
       " 0.17367470264434814,\n",
       " 0.45631980895996094,\n",
       " 0.20398283004760742,\n",
       " 0.27103251218795776,\n",
       " 0.4762154817581177,\n",
       " 0.3641194701194763,\n",
       " 0.20130956172943115,\n",
       " 0.25339990854263306,\n",
       " 0.46706974506378174,\n",
       " 0.31257057189941406,\n",
       " 0.10057187080383301,\n",
       " 0.3095393776893616,\n",
       " 0.17008930444717407,\n",
       " 0.0826188325881958,\n",
       " 0.12942856550216675,\n",
       " 0.24616527557373047,\n",
       " 0.4724233150482178,\n",
       " 0.24416232109069824,\n",
       " 0.08850258588790894,\n",
       " 0.3281775712966919,\n",
       " 0.3190385103225708,\n",
       " 0.19739437103271484,\n",
       " 0.18124723434448242,\n",
       " 0.29693758487701416,\n",
       " 0.21469295024871826,\n",
       " 0.3300445079803467,\n",
       " 0.3047412633895874,\n",
       " 0.061473190784454346,\n",
       " 0.3071444034576416,\n",
       " 0.3196723461151123,\n",
       " 0.10487490892410278,\n",
       " 0.38023483753204346,\n",
       " 0.2051500678062439,\n",
       " 0.25450611114501953,\n",
       " 0.2627255320549011,\n",
       " 0.21990537643432617,\n",
       " 0.037154316902160645,\n",
       " 0.27306169271469116,\n",
       " 0.3465709686279297,\n",
       " 0.07075881958007812,\n",
       " 0.1571144461631775,\n",
       " 0.3910332918167114,\n",
       " 0.4522274136543274,\n",
       " 0.27524900436401367,\n",
       " 0.1360529661178589,\n",
       " 0.4737074375152588,\n",
       " 0.1555614471435547,\n",
       " 0.18773174285888672,\n",
       " 0.15351569652557373,\n",
       " 0.20310050249099731,\n",
       " 0.36367595195770264,\n",
       " 0.46394670009613037,\n",
       " 0.2155037522315979,\n",
       " 0.16736137866973877,\n",
       " 0.19669800996780396,\n",
       " 0.21233278512954712,\n",
       " 0.579374223947525,\n",
       " 0.3849567770957947,\n",
       " 0.1424732208251953,\n",
       " 0.11866927146911621,\n",
       " 0.17609846591949463,\n",
       " 0.10827040672302246,\n",
       " 0.25832611322402954,\n",
       " 0.3649131655693054,\n",
       " 0.3305577039718628,\n",
       " 0.2353706955909729,\n",
       " 0.1882476806640625,\n",
       " 0.1252535581588745,\n",
       " 0.2658842206001282,\n",
       " 0.2883434295654297,\n",
       " 0.12832093238830566,\n",
       " 0.5651725828647614,\n",
       " 0.49965178966522217,\n",
       " 0.36592888832092285,\n",
       " 0.1569652557373047,\n",
       " 0.3397215008735657,\n",
       " 0.08751380443572998,\n",
       " 0.3920605778694153,\n",
       " 0.16750997304916382,\n",
       " 0.2361835241317749,\n",
       " 0.13675224781036377,\n",
       " 0.34478944540023804,\n",
       " 0.10066425800323486,\n",
       " 0.18911635875701904,\n",
       " 0.1890103816986084,\n",
       " 0.16697680950164795,\n",
       " 0.12917137145996094,\n",
       " 0.13731306791305542,\n",
       " 0.40436887741088867,\n",
       " 0.13729411363601685,\n",
       " 0.19227635860443115,\n",
       " 0.2435007095336914,\n",
       " 0.19244170188903809,\n",
       " 0.2825348377227783,\n",
       " 0.28878581523895264,\n",
       " 0.29418063163757324,\n",
       " 0.34603655338287354,\n",
       " 0.14565730094909668,\n",
       " 0.2572004795074463,\n",
       " 0.1818002462387085,\n",
       " 0.3191404342651367,\n",
       " 0.22153258323669434,\n",
       " 0.15095019340515137,\n",
       " 0.1901378035545349,\n",
       " 0.1273289918899536,\n",
       " 0.1501556634902954,\n",
       " 0.11984306573867798,\n",
       " 0.2398698329925537,\n",
       " 0.24865925312042236,\n",
       " 0.09401345252990723,\n",
       " 0.10547113418579102,\n",
       " 0.12842392921447754,\n",
       " 0.2807989716529846,\n",
       " 0.17596065998077393,\n",
       " 0.19776546955108643,\n",
       " 0.14793598651885986,\n",
       " 0.05621623992919922,\n",
       " 0.4414803385734558,\n",
       " 0.12614351511001587,\n",
       " 0.30794858932495117,\n",
       " 0.19499695301055908,\n",
       " 0.05696368217468262,\n",
       " 0.2480146884918213,\n",
       " 0.30858123302459717,\n",
       " 0.34665846824645996,\n",
       " 0.1754826307296753,\n",
       " 0.19297140836715698,\n",
       " 0.4272359609603882,\n",
       " 0.2198244333267212,\n",
       " 0.18009018898010254,\n",
       " 0.06290543079376221,\n",
       " 0.23767149448394775,\n",
       " 0.21371328830718994,\n",
       " 0.27567774057388306,\n",
       " 0.2830796241760254,\n",
       " 0.41701245307922363,\n",
       " 0.3978049159049988,\n",
       " 0.19889205694198608,\n",
       " 0.21666359901428223,\n",
       " 0.18622994422912598,\n",
       " 0.6499696373939514,\n",
       " 0.15668779611587524,\n",
       " 0.34449923038482666,\n",
       " 0.2660421133041382,\n",
       " 0.37475764751434326,\n",
       " 0.23047566413879395,\n",
       " 0.27228260040283203,\n",
       " 0.15728294849395752,\n",
       " 0.2375078797340393,\n",
       " 0.24629253149032593,\n",
       " 0.12108206748962402,\n",
       " 0.13679176568984985,\n",
       " 0.36181169748306274,\n",
       " 0.192596435546875,\n",
       " 0.31398749351501465,\n",
       " 0.5584115386009216,\n",
       " 0.11262309551239014,\n",
       " 0.112723708152771,\n",
       " 0.15815705060958862,\n",
       " 0.1939077377319336,\n",
       " 0.45803558826446533,\n",
       " 0.4649335741996765,\n",
       " 0.22668766975402832,\n",
       " 0.2030314803123474,\n",
       " 0.31689906120300293,\n",
       " 0.2813614010810852,\n",
       " 0.25513261556625366,\n",
       " 0.2616572380065918,\n",
       " 0.45086050033569336,\n",
       " 0.3228750228881836,\n",
       " 0.19891691207885742,\n",
       " 0.5799567103385925,\n",
       " 0.25290316343307495,\n",
       " 0.057769060134887695,\n",
       " 0.33690404891967773,\n",
       " 0.22123098373413086,\n",
       " 0.07225596904754639,\n",
       " 0.13429319858551025,\n",
       " 0.26049256324768066,\n",
       " 0.2800334095954895,\n",
       " 0.2883601188659668,\n",
       " 0.22492581605911255,\n",
       " 0.2851375341415405,\n",
       " 0.43226033449172974,\n",
       " 0.43196403980255127,\n",
       " 0.13259601593017578,\n",
       " 0.3144947290420532,\n",
       " 0.36285996437072754,\n",
       " 0.26912057399749756,\n",
       " 0.18973761796951294,\n",
       " 0.3599557876586914,\n",
       " 0.4343913793563843,\n",
       " 0.13096165657043457,\n",
       " 0.40375208854675293,\n",
       " 0.18684124946594238,\n",
       " 0.22733521461486816,\n",
       " 0.07002568244934082,\n",
       " 0.2822948694229126,\n",
       " 0.23165273666381836,\n",
       " 0.13584721088409424,\n",
       " 0.08480679988861084,\n",
       " 0.14068424701690674,\n",
       " 0.19604986906051636,\n",
       " 0.12804150581359863,\n",
       " 0.11530041694641113,\n",
       " 0.14023196697235107,\n",
       " 0.12792325019836426,\n",
       " 0.07956743240356445,\n",
       " 0.41646814346313477,\n",
       " 0.4797402024269104,\n",
       " 0.25659382343292236,\n",
       " 0.17307651042938232,\n",
       " 0.12226951122283936,\n",
       " 0.31725335121154785,\n",
       " 0.08939766883850098,\n",
       " 0.32818281650543213,\n",
       " 0.15945851802825928,\n",
       " 0.36873459815979004,\n",
       " 0.699784517288208,\n",
       " 0.12486821413040161,\n",
       " 0.3585789203643799,\n",
       " 0.2367323637008667,\n",
       " 0.1253148317337036,\n",
       " 0.204786479473114,\n",
       " 0.32327520847320557,\n",
       " 0.23590785264968872,\n",
       " 0.20161741971969604,\n",
       " 0.22414201498031616,\n",
       " 0.12403309345245361,\n",
       " 0.2799433469772339,\n",
       " 0.5878503322601318,\n",
       " 0.3188484311103821,\n",
       " 0.09762734174728394,\n",
       " 0.2860722541809082,\n",
       " 0.2416917085647583,\n",
       " 0.12897884845733643,\n",
       " 0.23263859748840332,\n",
       " 0.14178496599197388,\n",
       " 0.15040600299835205,\n",
       " 0.22922873497009277,\n",
       " 0.2548762559890747]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8fa2f49c-645c-432f-a621-67db01823fa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# embeddings[0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "6ed0324e-8fd1-4a71-9a5f-b9013412ffdf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# embeddings[1]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "581e5462-3321-4327-af37-f9c854b9135c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[1]['embedding'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8b9eb1a7-660b-466d-bd19-6a092e461e29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.resize(embeddings[1]['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1fe26ee7-df11-41c5-8f19-74d10a529608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.cat((embeddings[0]['embedding'].reshape(-1,1), embeddings[1]['embedding'].reshape(-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8b79a718-3788-41d5-b383-eb846a0c288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = [embeddings[index]['embedding'].reshape(-1,1) for index in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6962e95a-e156-4e42-bbcb-ff5591df5813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_embeddings = torch.cat(all_embeddings, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "614be492-7ff8-4952-a469-ef06b8757105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(embeddings[277]['embedding'], all_embeddings[277])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "0e1cb61d-3fd8-49f6-b9e6-115587abf31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7833367"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(all_embeddings, all_embeddings)[277][278]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "0cf1f5e0-3828-48ac-a521-fcbb329849b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8624316]], dtype=float32)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([embeddings[1]['embedding']], [embeddings[2]['embedding']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d53ccc54-47fc-418a-a1d9-bac68700d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dist = 1-cosine_similarity(all_embeddings, all_embeddings)\n",
    "check_dist_values = check_dist.diagonal(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "9028a07f-3927-4f85-a11b-e3f647cd824b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08057254552841187,\n",
       " 0.13756811618804932,\n",
       " 0.17561495304107666,\n",
       " 0.06512308120727539,\n",
       " 0.18760502338409424,\n",
       " 0.14767926931381226,\n",
       " 0.16683244705200195,\n",
       " 0.18630284070968628,\n",
       " 0.15812557935714722,\n",
       " 0.07983016967773438,\n",
       " 0.08562678098678589,\n",
       " 0.16223376989364624,\n",
       " 0.07978606224060059,\n",
       " 0.18610018491744995,\n",
       " 0.0658942461013794,\n",
       " 0.09110856056213379,\n",
       " 0.4504425525665283,\n",
       " 0.22420907020568848,\n",
       " 0.32570070028305054,\n",
       " 0.0710674524307251,\n",
       " 0.18791961669921875,\n",
       " 0.10814177989959717,\n",
       " 0.09627443552017212,\n",
       " 0.23668622970581055,\n",
       " 0.27814245223999023,\n",
       " 0.11351287364959717,\n",
       " 0.2664564251899719,\n",
       " 0.27265334129333496,\n",
       " 0.2593120336532593,\n",
       " 0.2754738926887512,\n",
       " 0.09199070930480957,\n",
       " 0.3252732753753662,\n",
       " 0.7885842323303223,\n",
       " 0.3085898756980896,\n",
       " 0.17649054527282715,\n",
       " 0.5832134485244751,\n",
       " 0.3872026205062866,\n",
       " 0.32293426990509033,\n",
       " 0.35044336318969727,\n",
       " 0.17462831735610962,\n",
       " 0.20303308963775635,\n",
       " 0.2724020481109619,\n",
       " 0.2179776430130005,\n",
       " 0.41525715589523315,\n",
       " 0.12195241451263428,\n",
       " 0.3999640941619873,\n",
       " 0.18376541137695312,\n",
       " 0.3260151147842407,\n",
       " 0.14166676998138428,\n",
       " 0.164756178855896,\n",
       " 0.46901512145996094,\n",
       " 0.1890554428100586,\n",
       " 0.6911007165908813,\n",
       " 0.31579506397247314,\n",
       " 0.1263970136642456,\n",
       " 0.45682764053344727,\n",
       " 0.19163751602172852,\n",
       " 0.19710999727249146,\n",
       " 0.29990196228027344,\n",
       " 0.18545162677764893,\n",
       " 0.13161134719848633,\n",
       " 0.29354071617126465,\n",
       " 0.17007970809936523,\n",
       " 0.12362295389175415,\n",
       " 0.32723796367645264,\n",
       " 0.056730031967163086,\n",
       " 0.3711611032485962,\n",
       " 0.3967784643173218,\n",
       " 0.22782772779464722,\n",
       " 0.16113942861557007,\n",
       " 0.34259486198425293,\n",
       " 0.15751123428344727,\n",
       " 0.30207371711730957,\n",
       " 0.48306411504745483,\n",
       " 0.06345599889755249,\n",
       " 0.14141333103179932,\n",
       " 0.1287529468536377,\n",
       " 0.2414470911026001,\n",
       " 0.2796895503997803,\n",
       " 0.4345625638961792,\n",
       " 0.14164066314697266,\n",
       " 0.03925603628158569,\n",
       " 0.4013258218765259,\n",
       " 0.2657170295715332,\n",
       " 0.07572782039642334,\n",
       " 0.1830132007598877,\n",
       " 0.19130194187164307,\n",
       " 0.13309621810913086,\n",
       " 0.26889270544052124,\n",
       " 0.11033129692077637,\n",
       " 0.06084078550338745,\n",
       " 0.19285845756530762,\n",
       " 0.3235096335411072,\n",
       " 0.31763768196105957,\n",
       " 0.24682366847991943,\n",
       " 0.318515419960022,\n",
       " 0.18904614448547363,\n",
       " 0.4734870195388794,\n",
       " 0.13109880685806274,\n",
       " 0.12028515338897705,\n",
       " 0.3670106530189514,\n",
       " 0.1892337203025818,\n",
       " 0.10605520009994507,\n",
       " 0.5271276235580444,\n",
       " 0.08719110488891602,\n",
       " 0.11085730791091919,\n",
       " 0.22237467765808105,\n",
       " 0.19472074508666992,\n",
       " 0.2568979859352112,\n",
       " 0.13618683815002441,\n",
       " 0.35303348302841187,\n",
       " 0.5372769236564636,\n",
       " 0.1215287446975708,\n",
       " 0.17250990867614746,\n",
       " 0.39296454191207886,\n",
       " 0.3310185670852661,\n",
       " 0.2049759030342102,\n",
       " 0.22826051712036133,\n",
       " 0.3266324996948242,\n",
       " 0.21187061071395874,\n",
       " 0.3829222321510315,\n",
       " 0.13730478286743164,\n",
       " 0.33808183670043945,\n",
       " 0.4797729253768921,\n",
       " 0.18079495429992676,\n",
       " 0.17792296409606934,\n",
       " 0.08993464708328247,\n",
       " 0.061673641204833984,\n",
       " 0.34935009479522705,\n",
       " 0.26548564434051514,\n",
       " 0.13511741161346436,\n",
       " 0.26240837574005127,\n",
       " 0.2353755235671997,\n",
       " 0.04526674747467041,\n",
       " 0.4095615744590759,\n",
       " 0.13197970390319824,\n",
       " 0.22056466341018677,\n",
       " 0.2508837580680847,\n",
       " 0.14416682720184326,\n",
       " 0.17367422580718994,\n",
       " 0.4563196897506714,\n",
       " 0.20398283004760742,\n",
       " 0.27103233337402344,\n",
       " 0.4762156009674072,\n",
       " 0.3641195297241211,\n",
       " 0.20130962133407593,\n",
       " 0.25339996814727783,\n",
       " 0.4670698642730713,\n",
       " 0.3125709891319275,\n",
       " 0.10057210922241211,\n",
       " 0.3095393180847168,\n",
       " 0.1700892448425293,\n",
       " 0.0826188325881958,\n",
       " 0.12942862510681152,\n",
       " 0.24616563320159912,\n",
       " 0.4724233150482178,\n",
       " 0.24416208267211914,\n",
       " 0.08850252628326416,\n",
       " 0.3281775712966919,\n",
       " 0.3190385699272156,\n",
       " 0.1973947286605835,\n",
       " 0.18124735355377197,\n",
       " 0.2969374656677246,\n",
       " 0.2146930694580078,\n",
       " 0.33004438877105713,\n",
       " 0.30474114418029785,\n",
       " 0.06147342920303345,\n",
       " 0.30714428424835205,\n",
       " 0.3196721076965332,\n",
       " 0.10487473011016846,\n",
       " 0.38023483753204346,\n",
       " 0.20514988899230957,\n",
       " 0.25450587272644043,\n",
       " 0.26272547245025635,\n",
       " 0.21990537643432617,\n",
       " 0.03715401887893677,\n",
       " 0.2730618119239807,\n",
       " 0.34657108783721924,\n",
       " 0.07075870037078857,\n",
       " 0.15711450576782227,\n",
       " 0.39103347063064575,\n",
       " 0.4522273540496826,\n",
       " 0.27524876594543457,\n",
       " 0.1360529661178589,\n",
       " 0.4737074375152588,\n",
       " 0.1555614471435547,\n",
       " 0.18773168325424194,\n",
       " 0.15351557731628418,\n",
       " 0.20310068130493164,\n",
       " 0.3636760115623474,\n",
       " 0.46394646167755127,\n",
       " 0.21550381183624268,\n",
       " 0.16736102104187012,\n",
       " 0.19669795036315918,\n",
       " 0.21233290433883667,\n",
       " 0.5793741941452026,\n",
       " 0.3849564790725708,\n",
       " 0.1424727439880371,\n",
       " 0.11866915225982666,\n",
       " 0.17609882354736328,\n",
       " 0.10827088356018066,\n",
       " 0.2583264112472534,\n",
       " 0.36491328477859497,\n",
       " 0.3305577039718628,\n",
       " 0.23537075519561768,\n",
       " 0.18824779987335205,\n",
       " 0.1252535581588745,\n",
       " 0.2658841609954834,\n",
       " 0.2883433699607849,\n",
       " 0.12832069396972656,\n",
       " 0.5651724934577942,\n",
       " 0.49965178966522217,\n",
       " 0.3659290075302124,\n",
       " 0.15696561336517334,\n",
       " 0.3397216200828552,\n",
       " 0.08751368522644043,\n",
       " 0.39206063747406006,\n",
       " 0.16750991344451904,\n",
       " 0.23618346452713013,\n",
       " 0.13675230741500854,\n",
       " 0.3447895050048828,\n",
       " 0.10066455602645874,\n",
       " 0.1891164779663086,\n",
       " 0.18901044130325317,\n",
       " 0.16697704792022705,\n",
       " 0.12917160987854004,\n",
       " 0.13731324672698975,\n",
       " 0.4043687582015991,\n",
       " 0.13729381561279297,\n",
       " 0.19227612018585205,\n",
       " 0.2435007095336914,\n",
       " 0.1924419403076172,\n",
       " 0.28253495693206787,\n",
       " 0.28878599405288696,\n",
       " 0.29418063163757324,\n",
       " 0.3460363745689392,\n",
       " 0.14565694332122803,\n",
       " 0.25720053911209106,\n",
       " 0.18180036544799805,\n",
       " 0.3191404938697815,\n",
       " 0.22153228521347046,\n",
       " 0.15094995498657227,\n",
       " 0.1901378631591797,\n",
       " 0.1273287534713745,\n",
       " 0.15015578269958496,\n",
       " 0.1198432445526123,\n",
       " 0.23986995220184326,\n",
       " 0.2486594319343567,\n",
       " 0.09401321411132812,\n",
       " 0.10547119379043579,\n",
       " 0.12842345237731934,\n",
       " 0.2807987928390503,\n",
       " 0.17596054077148438,\n",
       " 0.1977652907371521,\n",
       " 0.14793574810028076,\n",
       " 0.05621635913848877,\n",
       " 0.4414803981781006,\n",
       " 0.12614375352859497,\n",
       " 0.3079487085342407,\n",
       " 0.19499731063842773,\n",
       " 0.05696368217468262,\n",
       " 0.24801480770111084,\n",
       " 0.3085811138153076,\n",
       " 0.3466583490371704,\n",
       " 0.17548227310180664,\n",
       " 0.1929713487625122,\n",
       " 0.4272359609603882,\n",
       " 0.21982455253601074,\n",
       " 0.18009012937545776,\n",
       " 0.06290543079376221,\n",
       " 0.23767173290252686,\n",
       " 0.21371328830718994,\n",
       " 0.27567756175994873,\n",
       " 0.28307944536209106,\n",
       " 0.4170125722885132,\n",
       " 0.3978051543235779,\n",
       " 0.19889187812805176,\n",
       " 0.21666330099105835,\n",
       " 0.18622976541519165,\n",
       " 0.6499696373939514,\n",
       " 0.15668785572052002,\n",
       " 0.34449928998947144,\n",
       " 0.26604199409484863,\n",
       " 0.37475740909576416,\n",
       " 0.23047590255737305,\n",
       " 0.27228260040283203,\n",
       " 0.15728282928466797,\n",
       " 0.23750782012939453,\n",
       " 0.2462925910949707,\n",
       " 0.12108194828033447,\n",
       " 0.13679128885269165,\n",
       " 0.36181139945983887,\n",
       " 0.19259673357009888,\n",
       " 0.313987672328949,\n",
       " 0.5584113597869873,\n",
       " 0.11262309551239014,\n",
       " 0.11272400617599487,\n",
       " 0.15815722942352295,\n",
       " 0.1939077377319336,\n",
       " 0.4580354690551758,\n",
       " 0.46493375301361084,\n",
       " 0.22668784856796265,\n",
       " 0.2030312418937683,\n",
       " 0.31689882278442383,\n",
       " 0.28136134147644043,\n",
       " 0.25513291358947754,\n",
       " 0.26165705919265747,\n",
       " 0.4508606195449829,\n",
       " 0.3228750228881836,\n",
       " 0.19891703128814697,\n",
       " 0.5799567699432373,\n",
       " 0.2529033422470093,\n",
       " 0.05776876211166382,\n",
       " 0.3369041681289673,\n",
       " 0.2212311029434204,\n",
       " 0.07225590944290161,\n",
       " 0.13429343700408936,\n",
       " 0.2604924440383911,\n",
       " 0.2800331115722656,\n",
       " 0.288360059261322,\n",
       " 0.22492587566375732,\n",
       " 0.2851375341415405,\n",
       " 0.4322601556777954,\n",
       " 0.43196403980255127,\n",
       " 0.13259583711624146,\n",
       " 0.31449466943740845,\n",
       " 0.36285996437072754,\n",
       " 0.26912033557891846,\n",
       " 0.18973761796951294,\n",
       " 0.3599560260772705,\n",
       " 0.4343913793563843,\n",
       " 0.13096153736114502,\n",
       " 0.4037519693374634,\n",
       " 0.18684124946594238,\n",
       " 0.2273353934288025,\n",
       " 0.07002609968185425,\n",
       " 0.2822948694229126,\n",
       " 0.2316523790359497,\n",
       " 0.13584697246551514,\n",
       " 0.08480650186538696,\n",
       " 0.14068400859832764,\n",
       " 0.1960499882698059,\n",
       " 0.12804150581359863,\n",
       " 0.11530041694641113,\n",
       " 0.14023184776306152,\n",
       " 0.12792348861694336,\n",
       " 0.07956719398498535,\n",
       " 0.41646790504455566,\n",
       " 0.4797402620315552,\n",
       " 0.25659358501434326,\n",
       " 0.17307651042938232,\n",
       " 0.12226986885070801,\n",
       " 0.3172537684440613,\n",
       " 0.08939802646636963,\n",
       " 0.32818305492401123,\n",
       " 0.15945816040039062,\n",
       " 0.3687347173690796,\n",
       " 0.699784517288208,\n",
       " 0.12486815452575684,\n",
       " 0.35857903957366943,\n",
       " 0.2367321252822876,\n",
       " 0.1253148913383484,\n",
       " 0.2047865390777588,\n",
       " 0.32327544689178467,\n",
       " 0.2359081506729126,\n",
       " 0.20161765813827515,\n",
       " 0.22414201498031616,\n",
       " 0.12403333187103271,\n",
       " 0.2799435257911682,\n",
       " 0.5878503322601318,\n",
       " 0.31884849071502686,\n",
       " 0.09762734174728394,\n",
       " 0.2860722541809082,\n",
       " 0.24169200658798218,\n",
       " 0.1289786696434021,\n",
       " 0.23263853788375854,\n",
       " 0.14178526401519775,\n",
       " 0.1504058837890625,\n",
       " 0.22922873497009277,\n",
       " 0.25487595796585083]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_dist_values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "44033b39-426c-4163-837c-2fc511f2fcd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08057284, 0.13756841, 0.17561519, 0.0651232 , 0.18760502,\n",
       "       0.14767939, 0.16683269, 0.1863029 , 0.15812576, 0.07983029,\n",
       "       0.08562672, 0.16223389, 0.07978606, 0.18610018, 0.06589437,\n",
       "       0.09110868, 0.45044267, 0.22420925, 0.32570064, 0.07106721,\n",
       "       0.18791962, 0.1081413 , 0.09627402, 0.23668623, 0.27814233,\n",
       "       0.11351317, 0.2664569 , 0.2726534 , 0.25931227, 0.27547413,\n",
       "       0.09199053, 0.32527298, 0.7885842 , 0.3085897 , 0.17649043,\n",
       "       0.58321357, 0.38720274, 0.32293415, 0.35044324, 0.1746285 ,\n",
       "       0.20303333, 0.27240229, 0.2179777 , 0.41525722, 0.12195218,\n",
       "       0.39996421, 0.18376541, 0.32601511, 0.14166689, 0.1647563 ,\n",
       "       0.46901512, 0.18905544, 0.69110075, 0.315795  , 0.12639666,\n",
       "       0.45682788, 0.1916374 , 0.19710988, 0.2999019 , 0.18545187,\n",
       "       0.13161129, 0.29354095, 0.17007947, 0.12362266, 0.32723784,\n",
       "       0.05673009, 0.37116116, 0.39677846, 0.22782773, 0.16113961,\n",
       "       0.34259498, 0.15751094, 0.30207372, 0.48306412, 0.06345606,\n",
       "       0.14141363, 0.12875277, 0.24144685, 0.27968955, 0.43456233,\n",
       "       0.14164108, 0.0392561 , 0.4013257 , 0.26571727, 0.07572794,\n",
       "       0.18301338, 0.19130194, 0.13309652, 0.268893  , 0.11033118,\n",
       "       0.06084096, 0.19285864, 0.32350957, 0.31763768, 0.24682385,\n",
       "       0.31851566, 0.18904608, 0.47348702, 0.13109863, 0.12028515,\n",
       "       0.36701083, 0.18923378, 0.10605514, 0.52712756, 0.08719099,\n",
       "       0.11085701, 0.22237456, 0.19472086, 0.25689816, 0.13618684,\n",
       "       0.35303342, 0.53727695, 0.12152898, 0.17250979, 0.3929646 ,\n",
       "       0.33101863, 0.20497614, 0.22826028, 0.3266325 , 0.21187067,\n",
       "       0.38292229, 0.1373049 , 0.33808172, 0.47977287, 0.18079484,\n",
       "       0.17792296, 0.08993495, 0.06167382, 0.34935033, 0.26548588,\n",
       "       0.13511729, 0.26240861, 0.23537582, 0.04526693, 0.40956151,\n",
       "       0.13198006, 0.2205649 , 0.2508837 , 0.14416724, 0.1736747 ,\n",
       "       0.45631981, 0.20398283, 0.27103251, 0.47621548, 0.36411947,\n",
       "       0.20130956, 0.25339991, 0.46706975, 0.31257057, 0.10057187,\n",
       "       0.30953938, 0.1700893 , 0.08261883, 0.12942857, 0.24616528,\n",
       "       0.47242332, 0.24416232, 0.08850259, 0.32817757, 0.31903851,\n",
       "       0.19739437, 0.18124723, 0.29693758, 0.21469295, 0.33004451,\n",
       "       0.30474126, 0.06147319, 0.3071444 , 0.31967235, 0.10487491,\n",
       "       0.38023484, 0.20515007, 0.25450611, 0.26272553, 0.21990538,\n",
       "       0.03715432, 0.27306169, 0.34657097, 0.07075882, 0.15711445,\n",
       "       0.39103329, 0.45222741, 0.275249  , 0.13605297, 0.47370744,\n",
       "       0.15556145, 0.18773174, 0.1535157 , 0.2031005 , 0.36367595,\n",
       "       0.4639467 , 0.21550375, 0.16736138, 0.19669801, 0.21233279,\n",
       "       0.57937422, 0.38495678, 0.14247322, 0.11866927, 0.17609847,\n",
       "       0.10827041, 0.25832611, 0.36491317, 0.3305577 , 0.2353707 ,\n",
       "       0.18824768, 0.12525356, 0.26588422, 0.28834343, 0.12832093,\n",
       "       0.56517258, 0.49965179, 0.36592889, 0.15696526, 0.3397215 ,\n",
       "       0.0875138 , 0.39206058, 0.16750997, 0.23618352, 0.13675225,\n",
       "       0.34478945, 0.10066426, 0.18911636, 0.18901038, 0.16697681,\n",
       "       0.12917137, 0.13731307, 0.40436888, 0.13729411, 0.19227636,\n",
       "       0.24350071, 0.1924417 , 0.28253484, 0.28878582, 0.29418063,\n",
       "       0.34603655, 0.1456573 , 0.25720048, 0.18180025, 0.31914043,\n",
       "       0.22153258, 0.15095019, 0.1901378 , 0.12732899, 0.15015566,\n",
       "       0.11984307, 0.23986983, 0.24865925, 0.09401345, 0.10547113,\n",
       "       0.12842393, 0.28079897, 0.17596066, 0.19776547, 0.14793599,\n",
       "       0.05621624, 0.44148034, 0.12614352, 0.30794859, 0.19499695,\n",
       "       0.05696368, 0.24801469, 0.30858123, 0.34665847, 0.17548263,\n",
       "       0.19297141, 0.42723596, 0.21982443, 0.18009019, 0.06290543,\n",
       "       0.23767149, 0.21371329, 0.27567774, 0.28307962, 0.41701245,\n",
       "       0.39780492, 0.19889206, 0.2166636 , 0.18622994, 0.64996964,\n",
       "       0.1566878 , 0.34449923, 0.26604211, 0.37475765, 0.23047566,\n",
       "       0.2722826 , 0.15728295, 0.23750788, 0.24629253, 0.12108207,\n",
       "       0.13679177, 0.3618117 , 0.19259644, 0.31398749, 0.55841154,\n",
       "       0.1126231 , 0.11272371, 0.15815705, 0.19390774, 0.45803559,\n",
       "       0.46493357, 0.22668767, 0.20303148, 0.31689906, 0.2813614 ,\n",
       "       0.25513262, 0.26165724, 0.4508605 , 0.32287502, 0.19891691,\n",
       "       0.57995671, 0.25290316, 0.05776906, 0.33690405, 0.22123098,\n",
       "       0.07225597, 0.1342932 , 0.26049256, 0.28003341, 0.28836012,\n",
       "       0.22492582, 0.28513753, 0.43226033, 0.43196404, 0.13259602,\n",
       "       0.31449473, 0.36285996, 0.26912057, 0.18973762, 0.35995579,\n",
       "       0.43439138, 0.13096166, 0.40375209, 0.18684125, 0.22733521,\n",
       "       0.07002568, 0.28229487, 0.23165274, 0.13584721, 0.0848068 ,\n",
       "       0.14068425, 0.19604987, 0.12804151, 0.11530042, 0.14023197,\n",
       "       0.12792325, 0.07956743, 0.41646814, 0.4797402 , 0.25659382,\n",
       "       0.17307651, 0.12226951, 0.31725335, 0.08939767, 0.32818282,\n",
       "       0.15945852, 0.3687346 , 0.69978452, 0.12486821, 0.35857892,\n",
       "       0.23673236, 0.12531483, 0.20478648, 0.32327521, 0.23590785,\n",
       "       0.20161742, 0.22414201, 0.12403309, 0.27994335, 0.58785033,\n",
       "       0.31884843, 0.09762734, 0.28607225, 0.24169171, 0.12897885,\n",
       "       0.2326386 , 0.14178497, 0.150406  , 0.22922873, 0.25487626])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "01d728bd-a649-4da8-a41e-8b914e7464a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(check_dist_values, np.array(distances), atol=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "262617b7-3c0a-44b7-add5-f0b9e2da9287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc.get_sentences()\n",
    "# doc.__get_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd8cf65e-5ae1-4ea9-95ef-b45c8a9bd471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc.single_sentences_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f11d344-8f32-4ae8-adb8-d39b2ca70f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc.get_token_length(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7bbbb5a-8bd6-469b-ba15-cab1ed6c23da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc.respective_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7629b36a-ffdc-43fa-b075-7d5e3f3e6b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc.combine_sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48477094-3d94-4113-b85b-8d17645e7bcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# doc.combined_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "054d10ae-2569-4a03-b850-014f2271e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc.get_embeddings(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e95eaaee-fa2f-422f-9808-708597d49274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# doc.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e736d908-b448-4a92-a766-77d511258f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc.combine_sentence_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af8bef2c-2c6a-41b3-9fda-784b23afa911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# doc.combined_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e840694f-8b26-412d-9a54-091de4ed905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc.calculate_cosine_distances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3290a75f-afc0-4a84-9938-a5efe8fdf8fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# doc.semantic_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48127947-626b-4603-97c7-75fcc4d286dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# output = doc.get_optimal_chunks(starting_threshold=95, step=5)\n",
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bffb97b-6830-4d4a-8979-cf18d1fbd2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0bdac7-1433-4e99-ab18-696a544098a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fff2b8-594b-4511-babe-d25f9c295fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce784f9-cea2-40f1-89b9-b500f883eab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee8de1a-b280-484c-bf3a-f7a7505c6105",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sentences_list = sc.get_sentences(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b084260-5188-4ab5-9a02-f93940aaa5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "respective_sentence_length = sc.get_token_length(single_sentences_list, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "296a6ebf-2852-49d9-b74f-2f9f82c9a701",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_sentences = sc.combine_sentences(single_sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d609a4-d74a-49bd-a72c-2e302f61d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = sc.get_embeddings([x['combined_sentence'] for x in combined_sentences], model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf8bdd7f-e8bc-4cbd-8a94-85f97f6fc608",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_sentences = sc.combine_sentence_embeddings(combined_sentences, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "308975ac-b9f7-4c4c-8297-f8f556bbb69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, combined_sentences = sc.calculate_cosine_distances(combined_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62d6e591-bccb-4d83-8488-3e40ad69bc93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'SemChunk' has no attribute 'get_optimal_chunks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_optimal_chunks\u001b[49m(distances, combined_sentences)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# chunks[:5]\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'SemChunk' has no attribute 'get_optimal_chunks'"
     ]
    }
   ],
   "source": [
    "chunks = sc.get_optimal_chunks(distances, combined_sentences)\n",
    "# chunks[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd70cac7-31ab-4273-831d-a8e0e925eee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
