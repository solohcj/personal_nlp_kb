{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b51af78c-2dbc-4d4d-8901-9547cf4fed50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\.conda\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import gensim\n",
    "import itertools\n",
    "\n",
    "from nltk import ngrams\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Importing model architecture\n",
    "from siamese_network_model_architecture import Encoder, SiameseNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f2198d-668a-4669-b753-161b09db0f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59e0af33-74d5-4c5a-abd2-6376bc59ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to GPU if not it will be processed with CPU\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a6ef912-e64e-4e29-932a-c37896d11fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\AppData\\Local\\Temp\\ipykernel_7420\\858636.py:1: DtypeWarning: Columns (3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../0. Sample Datasets/quora_question_pair_sample.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../0. Sample Datasets/quora_question_pair_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca0f32eb-b127-41dd-a6e4-848423917ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_column', None) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b623e051-dbaf-4dae-b43b-79575a8f2597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404290 entries, 0 to 404289\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   id            404290 non-null  int64 \n",
      " 1   qid1          404290 non-null  int64 \n",
      " 2   qid2          404290 non-null  int64 \n",
      " 3   question1     404289 non-null  object\n",
      " 4   question2     404288 non-null  object\n",
      " 5   is_duplicate  404290 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e17fedc-be20-49f2-9e49-891a18061674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>363362</th>\n",
       "      <td>363362</td>\n",
       "      <td>493340</td>\n",
       "      <td>493341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My Chinese name is Haichao Yu. What English na...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2 question1  \\\n",
       "363362  363362  493340  493341       NaN   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "363362  My Chinese name is Haichao Yu. What English na...             0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.question1.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64277f18-b8fd-4256-bc37-6a35292cbcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105780</th>\n",
       "      <td>105780</td>\n",
       "      <td>174363</td>\n",
       "      <td>174364</td>\n",
       "      <td>How can I develop android app?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201841</th>\n",
       "      <td>201841</td>\n",
       "      <td>303951</td>\n",
       "      <td>174364</td>\n",
       "      <td>How can I create an Android app?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2                         question1 question2  \\\n",
       "105780  105780  174363  174364    How can I develop android app?       NaN   \n",
       "201841  201841  303951  174364  How can I create an Android app?       NaN   \n",
       "\n",
       "        is_duplicate  \n",
       "105780             0  \n",
       "201841             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.question2.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "899863c9-2014-4f82-8c39-ff8bfdf16056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c66941a-f58d-4201-8610-1108d1576782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 404287 entries, 0 to 404289\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   id            404287 non-null  int64 \n",
      " 1   qid1          404287 non-null  int64 \n",
      " 2   qid2          404287 non-null  int64 \n",
      " 3   question1     404287 non-null  object\n",
      " 4   question2     404287 non-null  object\n",
      " 5   is_duplicate  404287 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 21.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba8c1cbe-708b-4e80-b74b-32276b4e29f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    255024\n",
       "1    149263\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.is_duplicate.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f3f1ec-39df-4a75-b61b-4d9b18b0aa72",
   "metadata": {},
   "source": [
    "## We will clean all data (regardless of test/val/train) with the same process before proceeding\n",
    "\n",
    "**_Will not be removing stopwords as stop words like \"how\"/\"what\", etc is important in differentiating the nature of the question_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5296eac-1f16-45a3-88d2-f1783c45c259",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lem = nltk.WordNetLemmatizer()\n",
    "\n",
    "def preprocessing(sentence):\n",
    "    sent = sentence.lower()\n",
    "    \n",
    "    # Removing selected symbols, keeping numbers\n",
    "    sent = re.sub(\"\\(|\\)|\\/|\\-|\\#|\\!|\\?|\\.|\\,|\\\"|\\'|\\*|\\[|\\]|\\{|\\}|\\$\", \"\", sent)\n",
    "    \n",
    "    # Removing emails\n",
    "    sent = re.sub(\"\\S*@\\S*\\s?\", \"\", sent)\n",
    "    \n",
    "    # Removing numbers\n",
    "    sent = re.sub(\"\\d+\", \"\", sent)\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8d3c921-30aa-4ce2-ae33-eda0afff6c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the step by step guide to invest in share market in india?\n"
     ]
    }
   ],
   "source": [
    "print('What is the step by step guide to invest in share market in india?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "762e1359-eebe-45d8-a665-2114e48ce36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is the step by step guide to invest in share market in india'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing('What is the step by step guide to invest in share market in india?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db30bed9-074d-4c49-9117-873c2e79bf56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how can i know who logged in to my gmail account by telling his ip address or device name'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing('How can I know who logged in to my Gmail account? (by telling his IP address or device name)?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77bd56ac-77be-44e4-af84-5c3f4173ff61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how do i log out of my gmail account on my friends phone'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing(\"How do I log out of my Gmail account on my friend's phone?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f61e8-303b-43f3-9a56-8ec18797f98c",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ec6a530-8795-4b78-a1dc-2afc731e7ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('is_duplicate', axis=1)\n",
    "y = df.is_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d59141e-9f7f-4e28-84fd-544521312bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  \n",
       "0  What is the step by step guide to invest in sh...  \n",
       "1  What would happen if the Indian government sto...  \n",
       "2  How can Internet speed be increased by hacking...  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...  \n",
       "4            Which fish would survive in salt water?  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "638a246f-26cd-4c13-9d5b-41aae361b22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7437de69-2ec0-4ffc-9d08-544d1a07bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1be7805e-d8f5-4514-bb28-13866dde7733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    204019\n",
       "1    119410\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c14fa149-ac87-41b3-ba32-6efbef7a3ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25503\n",
       "1    14926\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dbb2bec-b2e3-4934-b07a-91afd250da73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25502\n",
       "1    14927\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "792c79b2-0841-435d-b524-ae2c3bd6dd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79897</th>\n",
       "      <td>79897</td>\n",
       "      <td>135943</td>\n",
       "      <td>135944</td>\n",
       "      <td>How come when a plane is crashing the pilots p...</td>\n",
       "      <td>I am a final year mech engg student with 2 cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57848</th>\n",
       "      <td>57848</td>\n",
       "      <td>101600</td>\n",
       "      <td>101601</td>\n",
       "      <td>I lost a Moto IMEI after rebooting. It is show...</td>\n",
       "      <td>The phone is not registering to the network an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6890</th>\n",
       "      <td>6890</td>\n",
       "      <td>13485</td>\n",
       "      <td>13486</td>\n",
       "      <td>Can I charge my phone rated at 5V/1A with 5.1V...</td>\n",
       "      <td>How long will it take (minimum) to charge a 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151555</th>\n",
       "      <td>151555</td>\n",
       "      <td>26093</td>\n",
       "      <td>56615</td>\n",
       "      <td>Why are so many people on Quora obsessed with IQ?</td>\n",
       "      <td>Why are most Quora users so obsessed with ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41174</th>\n",
       "      <td>41174</td>\n",
       "      <td>74376</td>\n",
       "      <td>74377</td>\n",
       "      <td>What are guilty pleasures?</td>\n",
       "      <td>What is your \"Guilty Pleasure\"?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "79897    79897  135943  135944   \n",
       "57848    57848  101600  101601   \n",
       "6890      6890   13485   13486   \n",
       "151555  151555   26093   56615   \n",
       "41174    41174   74376   74377   \n",
       "\n",
       "                                                question1  \\\n",
       "79897   How come when a plane is crashing the pilots p...   \n",
       "57848   I lost a Moto IMEI after rebooting. It is show...   \n",
       "6890    Can I charge my phone rated at 5V/1A with 5.1V...   \n",
       "151555  Why are so many people on Quora obsessed with IQ?   \n",
       "41174                          What are guilty pleasures?   \n",
       "\n",
       "                                                question2  \n",
       "79897   I am a final year mech engg student with 2 cur...  \n",
       "57848   The phone is not registering to the network an...  \n",
       "6890    How long will it take (minimum) to charge a 16...  \n",
       "151555  Why are most Quora users so obsessed with ques...  \n",
       "41174                     What is your \"Guilty Pleasure\"?  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99770347-68ca-4b19-9398-8aefcef36754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79897     0\n",
       "57848     0\n",
       "6890      0\n",
       "151555    1\n",
       "41174     0\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96e2e94d-15a5-496c-b50a-2b5e95df1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting indexes for subsequent processing (less confusing to tally)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_val.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_val.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f47b584-b9f8-4b2c-806e-9317d0ff5780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79897</td>\n",
       "      <td>135943</td>\n",
       "      <td>135944</td>\n",
       "      <td>How come when a plane is crashing the pilots p...</td>\n",
       "      <td>I am a final year mech engg student with 2 cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57848</td>\n",
       "      <td>101600</td>\n",
       "      <td>101601</td>\n",
       "      <td>I lost a Moto IMEI after rebooting. It is show...</td>\n",
       "      <td>The phone is not registering to the network an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6890</td>\n",
       "      <td>13485</td>\n",
       "      <td>13486</td>\n",
       "      <td>Can I charge my phone rated at 5V/1A with 5.1V...</td>\n",
       "      <td>How long will it take (minimum) to charge a 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151555</td>\n",
       "      <td>26093</td>\n",
       "      <td>56615</td>\n",
       "      <td>Why are so many people on Quora obsessed with IQ?</td>\n",
       "      <td>Why are most Quora users so obsessed with ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41174</td>\n",
       "      <td>74376</td>\n",
       "      <td>74377</td>\n",
       "      <td>What are guilty pleasures?</td>\n",
       "      <td>What is your \"Guilty Pleasure\"?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2                                          question1  \\\n",
       "0   79897  135943  135944  How come when a plane is crashing the pilots p...   \n",
       "1   57848  101600  101601  I lost a Moto IMEI after rebooting. It is show...   \n",
       "2    6890   13485   13486  Can I charge my phone rated at 5V/1A with 5.1V...   \n",
       "3  151555   26093   56615  Why are so many people on Quora obsessed with IQ?   \n",
       "4   41174   74376   74377                         What are guilty pleasures?   \n",
       "\n",
       "                                           question2  \n",
       "0  I am a final year mech engg student with 2 cur...  \n",
       "1  The phone is not registering to the network an...  \n",
       "2  How long will it take (minimum) to charge a 16...  \n",
       "3  Why are most Quora users so obsessed with ques...  \n",
       "4                    What is your \"Guilty Pleasure\"?  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21ff4132-8715-4800-8e1e-6e2ac584efdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d0f7e-94b0-44e5-8f3a-0205b0920187",
   "metadata": {},
   "source": [
    "## Preprocessing all input text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "554136b2-40b2-439f-8c46-cb2e4be08219",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['q1_preprocessed'] = [preprocessing(i) for i in X_train.question1]\n",
    "X_val['q1_preprocessed'] = [preprocessing(i) for i in X_val.question1]\n",
    "X_test['q1_preprocessed'] = [preprocessing(i) for i in X_test.question1]\n",
    "\n",
    "X_train['q2_preprocessed'] = [preprocessing(i) for i in X_train.question2]\n",
    "X_val['q2_preprocessed'] = [preprocessing(i) for i in X_val.question2]\n",
    "X_test['q2_preprocessed'] = [preprocessing(i) for i in X_test.question2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6248deef-e35c-4d50-bead-9524a397de34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>q1_preprocessed</th>\n",
       "      <th>q2_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>358005</td>\n",
       "      <td>363993</td>\n",
       "      <td>487434</td>\n",
       "      <td>Why would Ivanka Trump fly coach Jet Blue with...</td>\n",
       "      <td>I am manufacturing medicine (ayurvedic powder)...</td>\n",
       "      <td>why would ivanka trump fly coach jet blue with...</td>\n",
       "      <td>i am manufacturing medicine ayurvedic powder t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153870</td>\n",
       "      <td>241428</td>\n",
       "      <td>241429</td>\n",
       "      <td>I have decided to make money through blogging ...</td>\n",
       "      <td>Which blogging niche can make money these days?</td>\n",
       "      <td>i have decided to make money through blogging ...</td>\n",
       "      <td>which blogging niche can make money these days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221480</td>\n",
       "      <td>328832</td>\n",
       "      <td>328833</td>\n",
       "      <td>What are you thinking about when you are runni...</td>\n",
       "      <td>How can I stop belly button infection? What ar...</td>\n",
       "      <td>what are you thinking about when you are runni...</td>\n",
       "      <td>how can i stop belly button infection what are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>298342</td>\n",
       "      <td>19721</td>\n",
       "      <td>33675</td>\n",
       "      <td>How long does meth stay in your system if you ...</td>\n",
       "      <td>How long does meth stay in your system? If las...</td>\n",
       "      <td>how long does meth stay in your system if you ...</td>\n",
       "      <td>how long does meth stay in your system if last...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64262</td>\n",
       "      <td>111695</td>\n",
       "      <td>15659</td>\n",
       "      <td>What is your review of M.S. Dhoni: The Untold ...</td>\n",
       "      <td>How is the movie MS Dhoni untold story?</td>\n",
       "      <td>what is your review of ms dhoni: the untold story</td>\n",
       "      <td>how is the movie ms dhoni untold story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    qid1    qid2                                          question1  \\\n",
       "0  358005  363993  487434  Why would Ivanka Trump fly coach Jet Blue with...   \n",
       "1  153870  241428  241429  I have decided to make money through blogging ...   \n",
       "2  221480  328832  328833  What are you thinking about when you are runni...   \n",
       "3  298342   19721   33675  How long does meth stay in your system if you ...   \n",
       "4   64262  111695   15659  What is your review of M.S. Dhoni: The Untold ...   \n",
       "\n",
       "                                           question2  \\\n",
       "0  I am manufacturing medicine (ayurvedic powder)...   \n",
       "1    Which blogging niche can make money these days?   \n",
       "2  How can I stop belly button infection? What ar...   \n",
       "3  How long does meth stay in your system? If las...   \n",
       "4            How is the movie MS Dhoni untold story?   \n",
       "\n",
       "                                     q1_preprocessed  \\\n",
       "0  why would ivanka trump fly coach jet blue with...   \n",
       "1  i have decided to make money through blogging ...   \n",
       "2  what are you thinking about when you are runni...   \n",
       "3  how long does meth stay in your system if you ...   \n",
       "4  what is your review of ms dhoni: the untold story   \n",
       "\n",
       "                                     q2_preprocessed  \n",
       "0  i am manufacturing medicine ayurvedic powder t...  \n",
       "1     which blogging niche can make money these days  \n",
       "2  how can i stop belly button infection what are...  \n",
       "3  how long does meth stay in your system if last...  \n",
       "4             how is the movie ms dhoni untold story  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7aed506-3471-4c3f-bb00-40556dfc7e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns which are no longer needed\n",
    "X_train.drop(['qid1', 'qid2', 'question1', 'question2'], axis=1, inplace=True)\n",
    "X_val.drop(['qid1', 'qid2', 'question1', 'question2'], axis=1, inplace=True)\n",
    "X_test.drop(['qid1', 'qid2', 'question1', 'question2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5de0f6f3-30db-45c8-b6cb-d9942a917465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q1_preprocessed</th>\n",
       "      <th>q2_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79897</td>\n",
       "      <td>how come when a plane is crashing the pilots p...</td>\n",
       "      <td>i am a final year mech engg student with  curr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57848</td>\n",
       "      <td>i lost a moto imei after rebooting it is showi...</td>\n",
       "      <td>the phone is not registering to the network an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6890</td>\n",
       "      <td>can i charge my phone rated at va with va powe...</td>\n",
       "      <td>how long will it take minimum to charge a mah ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151555</td>\n",
       "      <td>why are so many people on quora obsessed with iq</td>\n",
       "      <td>why are most quora users so obsessed with ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41174</td>\n",
       "      <td>what are guilty pleasures</td>\n",
       "      <td>what is your guilty pleasure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                    q1_preprocessed  \\\n",
       "0   79897  how come when a plane is crashing the pilots p...   \n",
       "1   57848  i lost a moto imei after rebooting it is showi...   \n",
       "2    6890  can i charge my phone rated at va with va powe...   \n",
       "3  151555   why are so many people on quora obsessed with iq   \n",
       "4   41174                          what are guilty pleasures   \n",
       "\n",
       "                                     q2_preprocessed  \n",
       "0  i am a final year mech engg student with  curr...  \n",
       "1  the phone is not registering to the network an...  \n",
       "2  how long will it take minimum to charge a mah ...  \n",
       "3  why are most quora users so obsessed with ques...  \n",
       "4                       what is your guilty pleasure  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c6fcb-8d6a-4066-83c6-0b411c953872",
   "metadata": {},
   "source": [
    "## Tokenising input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44426730-f927-4106-8b0b-4390326578c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def building_vocab(df, columns=None):\n",
    "    \n",
    "    assert columns\n",
    "    \n",
    "    input_series = []\n",
    "    \n",
    "    for column in columns:\n",
    "        input_series += df[column].tolist()\n",
    "        \n",
    "    tokenized = [i.split() for i in input_series]\n",
    "        \n",
    "    # Building vocabulary\n",
    "    unique_words = ['<PAD>', '<UNK>'] + list(set(itertools.chain.from_iterable(tokenized)))\n",
    "    vocabulary = dict(zip(unique_words, range(len(unique_words))))\n",
    "\n",
    "    return vocabulary, len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "103461c1-cdba-45cc-9cfb-53eaf8cc2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_padding(input_series, max_len, vocabulary=None):\n",
    "\n",
    "    assert vocabulary\n",
    "    \n",
    "    if type(input_series)!=list:\n",
    "        try:\n",
    "            input_series = input_series.tolist()\n",
    "        except:\n",
    "            print (\"input_series must be list or of type which can be converter to list\")\n",
    "    \n",
    "    tokenized = [i.split() for i in input_series]\n",
    "    \n",
    "    # Encoding and padding\n",
    "    document = []\n",
    "    \n",
    "    for i in tokenized:\n",
    "        tok_sent = [vocabulary[j] if j in vocabulary else 1 for j in i]\n",
    "        document.append(tok_sent)\n",
    "        \n",
    "    for i in range(len(document)):\n",
    "        if len(document[i])<=max_len:\n",
    "            document[i] = [0]*(max_len-len(document[i])) + document[i]\n",
    "        else:\n",
    "            document[i] = document[i][-max_len:]\n",
    "            \n",
    "    output = [np.array(i) for i in document]\n",
    "\n",
    "    return np.vstack(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "617ffb95-0c9b-4135-867e-f86c0ae1c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters for modeling\n",
    "max_length = seq_len = n_units = 50\n",
    "d_features = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df54689e-01fd-4304-b721-b5c924eb0a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building vocabulary\n",
    "X_train_vocab, X_train_vocab_size = building_vocab(X_train, columns=['q1_preprocessed', 'q2_preprocessed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b0216b9-8d60-4b90-a08c-3db225b03ca7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<UNK>': 1,\n",
       " 'aia': 2,\n",
       " 'bhel': 3,\n",
       " 'shatter': 4,\n",
       " 'goswami': 5,\n",
       " 'audtion': 6,\n",
       " 'thedielinecom': 7,\n",
       " 'screenhero': 8,\n",
       " '“user': 9,\n",
       " 'differencesimilarities': 10,\n",
       " 'yoy': 11,\n",
       " 'int>': 12,\n",
       " 'excellence': 13,\n",
       " 'amniotic': 14,\n",
       " 'noteworthy': 15,\n",
       " 'afroamericans': 16,\n",
       " 'giloy': 17,\n",
       " 'spaniard': 18,\n",
       " 'islamic': 19,\n",
       " 'totem': 20,\n",
       " 'skinny': 21,\n",
       " 'cablestayed': 22,\n",
       " 'dolearn': 23,\n",
       " 'hospitalized': 24,\n",
       " 'worst': 25,\n",
       " 'roti': 26,\n",
       " 'gently': 27,\n",
       " '‘your': 28,\n",
       " 'solidified': 29,\n",
       " 'goods:': 30,\n",
       " 'sujoy': 31,\n",
       " 'sporty': 32,\n",
       " 'custid': 33,\n",
       " 'tellcontact': 34,\n",
       " 'religion': 35,\n",
       " 'hitleapcom': 36,\n",
       " 'confined': 37,\n",
       " 'oglecom': 38,\n",
       " 'foreig': 39,\n",
       " 'articlesbase': 40,\n",
       " 'vocabularycom': 41,\n",
       " 'stardelta': 42,\n",
       " 'loveunity': 43,\n",
       " 'anybuddy': 44,\n",
       " 'oscarnominated': 45,\n",
       " 'semiautomatic': 46,\n",
       " 'ulimoj': 47,\n",
       " 'filled': 48,\n",
       " 'singledouble': 49,\n",
       " 'viewership': 50,\n",
       " 'sephora': 51,\n",
       " 'gulfcom': 52,\n",
       " 'pimples': 53,\n",
       " 'needham': 54,\n",
       " 'germans': 55,\n",
       " 'biographics': 56,\n",
       " 'shallots': 57,\n",
       " 'railcar': 58,\n",
       " 'incinerate': 59,\n",
       " 'citys': 60,\n",
       " 'luggagehand': 61,\n",
       " 'awarded': 62,\n",
       " 'deed': 63,\n",
       " 'kicking': 64,\n",
       " 'schengen': 65,\n",
       " 'mallya': 66,\n",
       " 'metalheads': 67,\n",
       " 'praxis': 68,\n",
       " 'mooc': 69,\n",
       " 'collieborder': 70,\n",
       " '‘uncontrollably': 71,\n",
       " 'audrey': 72,\n",
       " 'yugi': 73,\n",
       " 'lossprofit': 74,\n",
       " 'rai': 75,\n",
       " 'moultrie': 76,\n",
       " 'amaravati': 77,\n",
       " 'acaccommodate': 78,\n",
       " 'glans': 79,\n",
       " 'apostlesjudas': 80,\n",
       " 'jayate': 81,\n",
       " 'unconditional': 82,\n",
       " 'vorkosigan': 83,\n",
       " '“freed”': 84,\n",
       " 'martinere': 85,\n",
       " 'bobak': 86,\n",
       " 'dread': 87,\n",
       " 'antivmy': 88,\n",
       " 'rrb': 89,\n",
       " 'fingerstyle': 90,\n",
       " 'presentationwhat': 91,\n",
       " 'optionfor': 92,\n",
       " 'mouthswab': 93,\n",
       " 'classs': 94,\n",
       " 'aldehyde': 95,\n",
       " 'dog': 96,\n",
       " 'somvar': 97,\n",
       " 'ghd': 98,\n",
       " 'سوسيس؟': 99,\n",
       " 'institute': 100,\n",
       " 'tumour': 101,\n",
       " 'ovulate': 102,\n",
       " '&sim': 103,\n",
       " 'numericals': 104,\n",
       " 'pushmo': 105,\n",
       " 'y^x^': 106,\n",
       " 'kwargs': 107,\n",
       " 'ashramtype': 108,\n",
       " 'vakilsearch': 109,\n",
       " 'abg': 110,\n",
       " 'decree': 111,\n",
       " 'bernadotte': 112,\n",
       " '“friends': 113,\n",
       " '=xxmath': 114,\n",
       " 'middleages': 115,\n",
       " 'bayer': 116,\n",
       " 'permagnate': 117,\n",
       " 'sanitizer': 118,\n",
       " 'gattaca': 119,\n",
       " 'collectcollected': 120,\n",
       " 'demonetizing': 121,\n",
       " 'secede': 122,\n",
       " 'ratioslr': 123,\n",
       " 'maturbate': 124,\n",
       " 'albanias': 125,\n",
       " 'airwaysindigo': 126,\n",
       " 'nesslers': 127,\n",
       " 'magma': 128,\n",
       " 'licked': 129,\n",
       " 'dslu': 130,\n",
       " 'unfalsifiable': 131,\n",
       " 'shirtless': 132,\n",
       " 'akand': 133,\n",
       " 'transsexual': 134,\n",
       " 'tall': 135,\n",
       " 'dixie': 136,\n",
       " 'carks': 137,\n",
       " 'engages': 138,\n",
       " 'nonbiased': 139,\n",
       " 'idolised': 140,\n",
       " 'gale': 141,\n",
       " 'pocketed': 142,\n",
       " 'agitation': 143,\n",
       " 'drp': 144,\n",
       " 'aircrarft': 145,\n",
       " 'meateating': 146,\n",
       " 'rommel': 147,\n",
       " 'plating': 148,\n",
       " 'bartending': 149,\n",
       " 'sitter': 150,\n",
       " 'patron': 151,\n",
       " 'gaffar': 152,\n",
       " 'thoughtbots': 153,\n",
       " 'holly': 154,\n",
       " 'इसका': 155,\n",
       " 'earthshaker': 156,\n",
       " 'allowances': 157,\n",
       " 'feared': 158,\n",
       " '“emotiv”': 159,\n",
       " 'basketballtennis': 160,\n",
       " 'naproxen': 161,\n",
       " 'kernel': 162,\n",
       " 'wiccan': 163,\n",
       " 'dats': 164,\n",
       " 'posse': 165,\n",
       " 'statusnet': 166,\n",
       " 'burrow': 167,\n",
       " 'vip': 168,\n",
       " 'drivers’': 169,\n",
       " 'somatosensory': 170,\n",
       " 'ghetto': 171,\n",
       " 'seens': 172,\n",
       " 'sjmsom': 173,\n",
       " 'hydroquinone': 174,\n",
       " 'abdullah': 175,\n",
       " 'batmanspiderman': 176,\n",
       " 'muscaria': 177,\n",
       " 'std': 178,\n",
       " 'trematoda': 179,\n",
       " 'techniciannetwork': 180,\n",
       " 'tnt': 181,\n",
       " 'likewise': 182,\n",
       " 'psk': 183,\n",
       " 'indefinetely': 184,\n",
       " 'prilosec': 185,\n",
       " 'notsogreat': 186,\n",
       " 'twelvth': 187,\n",
       " 'brands:': 188,\n",
       " 'stroustrup': 189,\n",
       " 'judgesupreme': 190,\n",
       " 'banyan': 191,\n",
       " 'documented': 192,\n",
       " 'kathryn': 193,\n",
       " 'cranberrygrape': 194,\n",
       " 'colleterol': 195,\n",
       " 'ronin': 196,\n",
       " 'chadar': 197,\n",
       " 'dreamy': 198,\n",
       " 'jockeys': 199,\n",
       " 'infringement': 200,\n",
       " 'itd': 201,\n",
       " 'v^': 202,\n",
       " 'spirits': 203,\n",
       " 'acronym': 204,\n",
       " 'appliances:': 205,\n",
       " 'divorced': 206,\n",
       " 'niels': 207,\n",
       " 'value’': 208,\n",
       " 'individuals': 209,\n",
       " 'yang': 210,\n",
       " 'mhrd': 211,\n",
       " 'burnout': 212,\n",
       " 'πrh': 213,\n",
       " 'zukerberg': 214,\n",
       " 'wallah': 215,\n",
       " 'kaku': 216,\n",
       " '=\\\\degmath': 217,\n",
       " 'gall': 218,\n",
       " 'ministerwhats': 219,\n",
       " 'antonym': 220,\n",
       " 'sansserif': 221,\n",
       " 'venturing': 222,\n",
       " 'scion': 223,\n",
       " 'reformat': 224,\n",
       " 'plentiful': 225,\n",
       " 'collinear': 226,\n",
       " 'overcooked': 227,\n",
       " 'ty': 228,\n",
       " 'hcf': 229,\n",
       " 'transplanted': 230,\n",
       " 'nris': 231,\n",
       " 'spatiotemporal': 232,\n",
       " 'brownorange': 233,\n",
       " 'strangers': 234,\n",
       " 'forgetful': 235,\n",
       " 'disrespects': 236,\n",
       " 'absolute': 237,\n",
       " 'sceince': 238,\n",
       " 'kutztown': 239,\n",
       " 'rayonier': 240,\n",
       " 'ebook': 241,\n",
       " 'summit—hangzhou': 242,\n",
       " 'believers:': 243,\n",
       " 'templates:': 244,\n",
       " 'phonetics:': 245,\n",
       " 'radler': 246,\n",
       " 'totake': 247,\n",
       " 'conversing': 248,\n",
       " 'narayanastra': 249,\n",
       " 'isis': 250,\n",
       " 'welldone': 251,\n",
       " 'spacemacs': 252,\n",
       " 'bellsouth': 253,\n",
       " 'kreuzberg': 254,\n",
       " 'arrests': 255,\n",
       " 'grammarly': 256,\n",
       " 'unnecessary': 257,\n",
       " 'motives': 258,\n",
       " 'loancheck': 259,\n",
       " 'ssctype': 260,\n",
       " 'salesdriven': 261,\n",
       " 'marooning': 262,\n",
       " 'preinstall': 263,\n",
       " 'embrassing': 264,\n",
       " 'matrimonials': 265,\n",
       " 'svtcxs': 266,\n",
       " 'is:': 267,\n",
       " 'chronal': 268,\n",
       " 'operas:': 269,\n",
       " 'deepcrush': 270,\n",
       " 'dummies': 271,\n",
       " 'taslima': 272,\n",
       " 'bigpipe': 273,\n",
       " 'mathematiciansphysicists': 274,\n",
       " 'hovering': 275,\n",
       " 'speaking:': 276,\n",
       " 'familycontrolled': 277,\n",
       " 'lightdark': 278,\n",
       " 'situ': 279,\n",
       " 'soy': 280,\n",
       " 'positve': 281,\n",
       " 'betablockers': 282,\n",
       " 'silicified': 283,\n",
       " 'security:': 284,\n",
       " 'directors:': 285,\n",
       " 'suicides': 286,\n",
       " 'mrcp': 287,\n",
       " 'beant': 288,\n",
       " 'sanskari': 289,\n",
       " 'namenode': 290,\n",
       " 'onenetworkdirect': 291,\n",
       " 'whiplash': 292,\n",
       " 'lincon': 293,\n",
       " 'm&m': 294,\n",
       " '‘winning': 295,\n",
       " 'pastramie': 296,\n",
       " 'screenlock': 297,\n",
       " 'disconnects': 298,\n",
       " 'latenight': 299,\n",
       " 'insat': 300,\n",
       " 'sonus': 301,\n",
       " 'jaqen': 302,\n",
       " 'datastage': 303,\n",
       " 'cooking': 304,\n",
       " 'але́хин': 305,\n",
       " 'ssn': 306,\n",
       " 'tetration': 307,\n",
       " 'space': 308,\n",
       " 'imr': 309,\n",
       " 'averagegood': 310,\n",
       " 'timer': 311,\n",
       " 'rachit': 312,\n",
       " 'inscriptions': 313,\n",
       " 'associativity': 314,\n",
       " 'yearafter': 315,\n",
       " 'dishs': 316,\n",
       " 'measures': 317,\n",
       " 'barack': 318,\n",
       " 'sinaro': 319,\n",
       " 'flutists': 320,\n",
       " 'chicka': 321,\n",
       " 'daggers': 322,\n",
       " 'vel': 323,\n",
       " 'devanagari': 324,\n",
       " 'switzerlands': 325,\n",
       " 'siberians': 326,\n",
       " 'abuts': 327,\n",
       " 'huánuco': 328,\n",
       " 'କିରି': 329,\n",
       " 'stairbuilder': 330,\n",
       " 'fecro': 331,\n",
       " 'bananasbanana': 332,\n",
       " 'yankee': 333,\n",
       " 'constaint': 334,\n",
       " 'tracheal': 335,\n",
       " 'armpit': 336,\n",
       " 'unicorns': 337,\n",
       " 'hydrate': 338,\n",
       " '££k': 339,\n",
       " 'stags': 340,\n",
       " 'sightedness': 341,\n",
       " 'asis': 342,\n",
       " 'mco': 343,\n",
       " 'turkish': 344,\n",
       " 'fats': 345,\n",
       " 'elviscocom': 346,\n",
       " 'cambodia:': 347,\n",
       " 'pes': 348,\n",
       " 'greet': 349,\n",
       " 'verbatim': 350,\n",
       " 'clear:': 351,\n",
       " 'pantaloons': 352,\n",
       " 'comical': 353,\n",
       " '분위기': 354,\n",
       " 'wildfly': 355,\n",
       " 'tricky': 356,\n",
       " 'drinks:': 357,\n",
       " 'phillipe': 358,\n",
       " 'pathgoal': 359,\n",
       " 'muhurtham': 360,\n",
       " 'accreditaton': 361,\n",
       " 'assertiveness': 362,\n",
       " 'dalal': 363,\n",
       " 'calciumwhat': 364,\n",
       " 'na': 365,\n",
       " 'withrubbed': 366,\n",
       " 'bhisma': 367,\n",
       " 'blows': 368,\n",
       " 'qualify': 369,\n",
       " 'girls…': 370,\n",
       " 'energise': 371,\n",
       " 'prerequisitesnew': 372,\n",
       " 'romantictearinducing': 373,\n",
       " 'electricitygenerating': 374,\n",
       " 'combinational': 375,\n",
       " 'strongestbest': 376,\n",
       " 'ketosys': 377,\n",
       " 'initially': 378,\n",
       " 'antigun': 379,\n",
       " 'plantain': 380,\n",
       " 'mailinglist': 381,\n",
       " 'scorecard': 382,\n",
       " 'gerson': 383,\n",
       " 'alonso': 384,\n",
       " 'vigyan': 385,\n",
       " 'virar': 386,\n",
       " 'fated': 387,\n",
       " 'itshe': 388,\n",
       " 'desulphurization': 389,\n",
       " 'debotosh': 390,\n",
       " 'bhanwar': 391,\n",
       " 'disaronno': 392,\n",
       " 'combatting': 393,\n",
       " 'beedie': 394,\n",
       " 'pasturised': 395,\n",
       " 'kandam': 396,\n",
       " 'meli': 397,\n",
       " 'rainymoodcom': 398,\n",
       " 'devise': 399,\n",
       " 'hatching': 400,\n",
       " 'civics': 401,\n",
       " 'cvp': 402,\n",
       " 'acting:': 403,\n",
       " 'corruped': 404,\n",
       " 'tufts': 405,\n",
       " 'testmysitecom': 406,\n",
       " 'rims': 407,\n",
       " 'amass': 408,\n",
       " 'sandberg:': 409,\n",
       " 'activefloor': 410,\n",
       " '“fly': 411,\n",
       " 'escp': 412,\n",
       " '“mrs”': 413,\n",
       " 'inductive': 414,\n",
       " 'copilot': 415,\n",
       " 'makekeep': 416,\n",
       " 'modelslayout': 417,\n",
       " 'depreciated': 418,\n",
       " 'varian': 419,\n",
       " 'nonconfucians': 420,\n",
       " 'enhancement': 421,\n",
       " 'shaking': 422,\n",
       " 'connote': 423,\n",
       " 'intermedia': 424,\n",
       " 'mural': 425,\n",
       " 'wayapi': 426,\n",
       " 'cordinator': 427,\n",
       " 'killerstartupscom': 428,\n",
       " 'annexure': 429,\n",
       " 'xbmc': 430,\n",
       " 'magical': 431,\n",
       " 'centred': 432,\n",
       " 'pericoronal': 433,\n",
       " 'phantom': 434,\n",
       " 'potatoe': 435,\n",
       " 'tashi': 436,\n",
       " 'kawasaki': 437,\n",
       " 'atanwhat': 438,\n",
       " 'unawkward': 439,\n",
       " 'loréal': 440,\n",
       " 'percy': 441,\n",
       " 'tana': 442,\n",
       " 'standalone': 443,\n",
       " 'i’d': 444,\n",
       " 'turtles': 445,\n",
       " 'oceanography': 446,\n",
       " 'insas': 447,\n",
       " 'hospot': 448,\n",
       " 'nh': 449,\n",
       " 'unprocessed': 450,\n",
       " 'sclera': 451,\n",
       " 'mermail': 452,\n",
       " 'populists': 453,\n",
       " 'cumejaculate': 454,\n",
       " 'missouri': 455,\n",
       " 'jokers': 456,\n",
       " 'tkdiff': 457,\n",
       " 'wasiyat': 458,\n",
       " '“johnny': 459,\n",
       " 'diseconomies': 460,\n",
       " 'schein': 461,\n",
       " 'teammates': 462,\n",
       " 'stationed': 463,\n",
       " 'usubstitution': 464,\n",
       " 'cisneros': 465,\n",
       " 'miniatures': 466,\n",
       " 'πe': 467,\n",
       " 'schwartz': 468,\n",
       " 'datas': 469,\n",
       " 'supervisors': 470,\n",
       " 'black;': 471,\n",
       " '“gone': 472,\n",
       " 'begusarai': 473,\n",
       " '“im': 474,\n",
       " 'vasistha': 475,\n",
       " '++++': 476,\n",
       " 'studentsalumni': 477,\n",
       " 'beacuse': 478,\n",
       " 'parenting:': 479,\n",
       " 'temperature:': 480,\n",
       " 'raiding': 481,\n",
       " 'nonvoice': 482,\n",
       " 'algorithms': 483,\n",
       " 'portrays': 484,\n",
       " 'noses': 485,\n",
       " 'fanshawe': 486,\n",
       " 'xenophobia': 487,\n",
       " 'wada': 488,\n",
       " 'math\\\\tana+b': 489,\n",
       " 'heredity': 490,\n",
       " 'unsolved': 491,\n",
       " 'airflow': 492,\n",
       " '“nowipe”': 493,\n",
       " 'gynecomastia': 494,\n",
       " 'eumelanin': 495,\n",
       " 'enters': 496,\n",
       " 'horrorsuspense': 497,\n",
       " 'abolition': 498,\n",
       " 'summary': 499,\n",
       " 'normaaly': 500,\n",
       " 'natalia': 501,\n",
       " 'safehaven': 502,\n",
       " 'ugc': 503,\n",
       " 'amps': 504,\n",
       " '“not': 505,\n",
       " 'visualisation': 506,\n",
       " 'chirality': 507,\n",
       " 'stripping': 508,\n",
       " 'lecturtes': 509,\n",
       " 'midsection': 510,\n",
       " 'causing': 511,\n",
       " 'rasagullah': 512,\n",
       " 'dehradun': 513,\n",
       " 'watauga': 514,\n",
       " 'mlp': 515,\n",
       " 'murr': 516,\n",
       " 'amc': 517,\n",
       " 'actionpriority': 518,\n",
       " 'affects': 519,\n",
       " 'beagleaustralian': 520,\n",
       " 'interction': 521,\n",
       " 'jeopardize': 522,\n",
       " 'yamaguchi': 523,\n",
       " 'wakeup': 524,\n",
       " 'mostinfluential': 525,\n",
       " 'rematch': 526,\n",
       " 'angelvc': 527,\n",
       " 'rappers': 528,\n",
       " 'viswanathans': 529,\n",
       " 'vichy': 530,\n",
       " 'adjourned': 531,\n",
       " 'onlive': 532,\n",
       " 'patients’': 533,\n",
       " 'xlvii': 534,\n",
       " 'noncompliance': 535,\n",
       " 'mosambi': 536,\n",
       " 'basf': 537,\n",
       " 'hydronium': 538,\n",
       " 'gamertags': 539,\n",
       " 'handluggage': 540,\n",
       " 'ernest': 541,\n",
       " 'vbnet': 542,\n",
       " 'funniestdumbestweirdest': 543,\n",
       " 'navaneethan': 544,\n",
       " 'moviename': 545,\n",
       " 'sharesesops': 546,\n",
       " 'mam': 547,\n",
       " 'capulet': 548,\n",
       " 'longroomcom': 549,\n",
       " 'mandarins': 550,\n",
       " 'dopaminergic': 551,\n",
       " 'madara': 552,\n",
       " 'being': 553,\n",
       " 'karan:': 554,\n",
       " 'months': 555,\n",
       " 'aryaka': 556,\n",
       " 'matt': 557,\n",
       " 'kannadathi': 558,\n",
       " 'multand': 559,\n",
       " 'plotly': 560,\n",
       " 'owl': 561,\n",
       " 'aisee': 562,\n",
       " 'shortest': 563,\n",
       " 'x+y+z=': 564,\n",
       " 'fj': 565,\n",
       " 'barc': 566,\n",
       " 'acet': 567,\n",
       " 'as”': 568,\n",
       " 'lurm': 569,\n",
       " 'gym:': 570,\n",
       " 'viviparous': 571,\n",
       " 'pss': 572,\n",
       " 'volunteers': 573,\n",
       " 'hdts': 574,\n",
       " 'offshore': 575,\n",
       " 'homogeneous': 576,\n",
       " 'acquaintances': 577,\n",
       " 'superfluous': 578,\n",
       " 'contemplate': 579,\n",
       " 'cemetery': 580,\n",
       " 'perc': 581,\n",
       " 'albanians': 582,\n",
       " 'ported': 583,\n",
       " 'novwhich': 584,\n",
       " 'liferay': 585,\n",
       " 'targetcom': 586,\n",
       " 'skyrim': 587,\n",
       " 'readytouse': 588,\n",
       " 'touchbar': 589,\n",
       " 'universities:': 590,\n",
       " 'onthego': 591,\n",
       " 'pandavas': 592,\n",
       " 'fxa': 593,\n",
       " 'wilp': 594,\n",
       " 'numinous': 595,\n",
       " 'thomson': 596,\n",
       " 'holocausting': 597,\n",
       " '“v”': 598,\n",
       " 'bhuj': 599,\n",
       " 'emds': 600,\n",
       " 'fibrin': 601,\n",
       " 'unrewarded': 602,\n",
       " 'suppor': 603,\n",
       " 'particular': 604,\n",
       " 'shooting:': 605,\n",
       " 'hkers': 606,\n",
       " 'nightmares': 607,\n",
       " 'geogira': 608,\n",
       " 'cbsse': 609,\n",
       " 'noncombat': 610,\n",
       " 'kgp’s': 611,\n",
       " 'gizmodo': 612,\n",
       " 'nonstatutory': 613,\n",
       " 'juri': 614,\n",
       " '“riches”': 615,\n",
       " 'finalyear': 616,\n",
       " 'barkhas': 617,\n",
       " 'noncommercial': 618,\n",
       " 'cca': 619,\n",
       " 'lathering': 620,\n",
       " 'willthis': 621,\n",
       " 'cord': 622,\n",
       " 'modded': 623,\n",
       " '“service”': 624,\n",
       " 'zola': 625,\n",
       " 'bhagat’s': 626,\n",
       " 'knesset': 627,\n",
       " 'entrycanada': 628,\n",
       " 'inconsistency': 629,\n",
       " 'cussler:': 630,\n",
       " 'graduationcommerce': 631,\n",
       " 'balinese': 632,\n",
       " 'sweep': 633,\n",
       " 'nextbigwhat': 634,\n",
       " 'fma': 635,\n",
       " 'elliott': 636,\n",
       " 'lowerranked': 637,\n",
       " 'irreverent': 638,\n",
       " 'seemandra': 639,\n",
       " 'boogers': 640,\n",
       " 'gilroyis': 641,\n",
       " 'nota': 642,\n",
       " 'mustafar': 643,\n",
       " 'anonymize': 644,\n",
       " 'insult': 645,\n",
       " 'vsti': 646,\n",
       " 'riak': 647,\n",
       " 'parentsfriendschildren': 648,\n",
       " 'cabo': 649,\n",
       " 'navodaya': 650,\n",
       " 'lightspeed': 651,\n",
       " 'viralmostcom': 652,\n",
       " 'sheshardripuram': 653,\n",
       " 'competecom': 654,\n",
       " 'onlog': 655,\n",
       " 'jocksnerdsgeeks': 656,\n",
       " 'expired': 657,\n",
       " 'jinchuuriki': 658,\n",
       " 'subbu': 659,\n",
       " 'plansgoals': 660,\n",
       " 'iqhubcom': 661,\n",
       " 'fstock': 662,\n",
       " 'sentinels': 663,\n",
       " 'fascism': 664,\n",
       " 'vtec': 665,\n",
       " 'tany': 666,\n",
       " 'tunisian': 667,\n",
       " 'surendra': 668,\n",
       " 'vellores': 669,\n",
       " 'mba': 670,\n",
       " 'delhilite': 671,\n",
       " 'adversity;': 672,\n",
       " 'bugle': 673,\n",
       " 'mlstatistics': 674,\n",
       " 'physiotherapy': 675,\n",
       " 'soni': 676,\n",
       " 'flipping': 677,\n",
       " 'sahib': 678,\n",
       " 'hijack': 679,\n",
       " 'keira': 680,\n",
       " 'pavements': 681,\n",
       " 'deflections': 682,\n",
       " 'prcard': 683,\n",
       " 'desperate': 684,\n",
       " 'horrors': 685,\n",
       " 'clapping': 686,\n",
       " 'accustomed': 687,\n",
       " 'illeducated': 688,\n",
       " 'whereas': 689,\n",
       " 'mali': 690,\n",
       " 'musks': 691,\n",
       " 'yellowknife': 692,\n",
       " 'rcd': 693,\n",
       " 'martial': 694,\n",
       " 'serbian': 695,\n",
       " 'predesigned': 696,\n",
       " 'missile:': 697,\n",
       " 'un’': 698,\n",
       " 'rohan': 699,\n",
       " 'today”': 700,\n",
       " 'mconnected': 701,\n",
       " 'struct': 702,\n",
       " 'catelynn': 703,\n",
       " 'mischievous': 704,\n",
       " 'prix': 705,\n",
       " 'proffesors': 706,\n",
       " 'channelsblogstutorials': 707,\n",
       " 'sachs': 708,\n",
       " 'aiaas': 709,\n",
       " 'eriksons': 710,\n",
       " 'crossbreed': 711,\n",
       " 'estonia': 712,\n",
       " 'gojeecom': 713,\n",
       " 'free': 714,\n",
       " 'aeronautics': 715,\n",
       " 'autographs': 716,\n",
       " 'appsee': 717,\n",
       " 'captured': 718,\n",
       " 'components': 719,\n",
       " 'huracan': 720,\n",
       " 'usuru': 721,\n",
       " 'apg': 722,\n",
       " 'lounges': 723,\n",
       " 'frackingwaste': 724,\n",
       " 'innovated': 725,\n",
       " 'lhs': 726,\n",
       " 'bengay': 727,\n",
       " 'crusade': 728,\n",
       " 'ifo': 729,\n",
       " 'furtwangen': 730,\n",
       " 'ಗೂಟ': 731,\n",
       " 'duster': 732,\n",
       " 'cheering': 733,\n",
       " 'ysabel': 734,\n",
       " 'foucaults': 735,\n",
       " 'interstellaer': 736,\n",
       " 'ojha': 737,\n",
       " 'liverpools': 738,\n",
       " 'bondable': 739,\n",
       " 'greekroman': 740,\n",
       " 'codeless': 741,\n",
       " 'yoo': 742,\n",
       " 'monsoon': 743,\n",
       " 'moniter': 744,\n",
       " 'warhammer': 745,\n",
       " 'dissipate': 746,\n",
       " 'roofing': 747,\n",
       " 'plasticine': 748,\n",
       " 'slits': 749,\n",
       " 'stockmarket': 750,\n",
       " 'loon': 751,\n",
       " 'fourth': 752,\n",
       " '^=at': 753,\n",
       " 'inferences': 754,\n",
       " 'chases': 755,\n",
       " 'shangqiu': 756,\n",
       " 'tarapur': 757,\n",
       " 'yaarab': 758,\n",
       " 'arachnids': 759,\n",
       " 'cancelation': 760,\n",
       " 'isolated': 761,\n",
       " 'amour': 762,\n",
       " 'wee': 763,\n",
       " 'talenthousecom': 764,\n",
       " 'icsid': 765,\n",
       " 'abrogate': 766,\n",
       " 'café': 767,\n",
       " 'rwth': 768,\n",
       " 'grapich': 769,\n",
       " 'ripley': 770,\n",
       " 'lim': 771,\n",
       " 'reorganizedrebuilt': 772,\n",
       " 'joke': 773,\n",
       " 'sensor': 774,\n",
       " 'myriad': 775,\n",
       " 'subaru': 776,\n",
       " 'thunderquote': 777,\n",
       " 'motrocycle': 778,\n",
       " 'dates': 779,\n",
       " 'punemumbai': 780,\n",
       " 'playbacks': 781,\n",
       " 'vadukut': 782,\n",
       " 'crop': 783,\n",
       " 'bbg': 784,\n",
       " 'amendent': 785,\n",
       " 'nmos': 786,\n",
       " 'rrn': 787,\n",
       " 'impingement': 788,\n",
       " 'yellowstone': 789,\n",
       " 'chi': 790,\n",
       " 'fivethirtyeight': 791,\n",
       " 'adense': 792,\n",
       " 'niners': 793,\n",
       " 'paralysis': 794,\n",
       " 'autocomplete': 795,\n",
       " 'cimplicity': 796,\n",
       " 'receipts': 797,\n",
       " 'appcleaner': 798,\n",
       " 'pricespecs': 799,\n",
       " 'wwwairjordanhotcom': 800,\n",
       " 'blurring': 801,\n",
       " 'affleck': 802,\n",
       " 'shooter': 803,\n",
       " 'chaga': 804,\n",
       " 'hazaras': 805,\n",
       " 'journalconference': 806,\n",
       " 'infosyshr': 807,\n",
       " 'marketo': 808,\n",
       " 'inu': 809,\n",
       " 'expectorants': 810,\n",
       " 'checkpoint_required': 811,\n",
       " 'xceligent': 812,\n",
       " 'avurvedic': 813,\n",
       " 'mycenaean': 814,\n",
       " 'wilkins': 815,\n",
       " 'mcgrath': 816,\n",
       " 'backronyms': 817,\n",
       " 'caledonian': 818,\n",
       " 'logit': 819,\n",
       " 'legally': 820,\n",
       " 'poops': 821,\n",
       " 'heriot': 822,\n",
       " 'tunisia:': 823,\n",
       " 'prop': 824,\n",
       " 'frog': 825,\n",
       " 'biotechi': 826,\n",
       " 'vatsa': 827,\n",
       " 'tennessees': 828,\n",
       " 'anodized': 829,\n",
       " 'ebix': 830,\n",
       " 'parables': 831,\n",
       " 'angavastram': 832,\n",
       " 'lsd': 833,\n",
       " 'tommorow': 834,\n",
       " 'sciencesecret': 835,\n",
       " 'instruction': 836,\n",
       " 'dualcore': 837,\n",
       " 'understandfeel': 838,\n",
       " 'volga': 839,\n",
       " 'beaten': 840,\n",
       " 'pahlaj': 841,\n",
       " 'testing': 842,\n",
       " 'polka': 843,\n",
       " 'reflecting': 844,\n",
       " 'projectors': 845,\n",
       " 'hotelling’s': 846,\n",
       " 'krusty': 847,\n",
       " 'atts': 848,\n",
       " 'moderately': 849,\n",
       " 'wala': 850,\n",
       " 'nene': 851,\n",
       " 'pipelines': 852,\n",
       " 'sweater': 853,\n",
       " 'madmen': 854,\n",
       " 'knock': 855,\n",
       " 'yellowish': 856,\n",
       " 'reunited': 857,\n",
       " 'footing': 858,\n",
       " 'exynos': 859,\n",
       " 'getregistration': 860,\n",
       " 'sfv': 861,\n",
       " 'filledsupplied': 862,\n",
       " 'atwhole': 863,\n",
       " 'optionsjobs': 864,\n",
       " 'wieber': 865,\n",
       " 'credila': 866,\n",
       " 'y=x^x^x': 867,\n",
       " 'dies': 868,\n",
       " 'x^+y^+=': 869,\n",
       " 'simplyuniquestylecom': 870,\n",
       " 'nsfw': 871,\n",
       " 'nucleosynthesis': 872,\n",
       " 'facilitator': 873,\n",
       " 'tawas': 874,\n",
       " 'medium': 875,\n",
       " 'inprove': 876,\n",
       " 'vaidya': 877,\n",
       " 'sme’s': 878,\n",
       " 'hightech': 879,\n",
       " 'aita': 880,\n",
       " 'requitrments': 881,\n",
       " 'quarantine': 882,\n",
       " 'levels': 883,\n",
       " 'retweet': 884,\n",
       " 'acetylation': 885,\n",
       " 'mullers': 886,\n",
       " 'parsefloat': 887,\n",
       " 'repelling': 888,\n",
       " 'magone': 889,\n",
       " 'mindanao': 890,\n",
       " 'fundacquire': 891,\n",
       " 'us’': 892,\n",
       " 'flyback': 893,\n",
       " 'smarty': 894,\n",
       " 'floyd’': 895,\n",
       " 'motel': 896,\n",
       " 'yohe': 897,\n",
       " 'parasympathetic': 898,\n",
       " 'turn': 899,\n",
       " 'aphrodite': 900,\n",
       " 'miniladd': 901,\n",
       " 'puncher': 902,\n",
       " 'ascending': 903,\n",
       " 'welingkars': 904,\n",
       " 've': 905,\n",
       " 'boku': 906,\n",
       " 'privatize': 907,\n",
       " 'semiperpetual': 908,\n",
       " 'mistry': 909,\n",
       " 'coker': 910,\n",
       " 'insurer': 911,\n",
       " 'booksmaterials': 912,\n",
       " 'zogenix': 913,\n",
       " 'musicianartist': 914,\n",
       " 'fired': 915,\n",
       " 'spec': 916,\n",
       " 'hard': 917,\n",
       " 'perceptive': 918,\n",
       " 'canteens': 919,\n",
       " 'haridwar': 920,\n",
       " 'scoff': 921,\n",
       " 'beryllium': 922,\n",
       " 'congressled': 923,\n",
       " 'approximation': 924,\n",
       " 'pmam': 925,\n",
       " 'ɽφʉʛƕlook': 926,\n",
       " 'downprevent': 927,\n",
       " 'pantium': 928,\n",
       " 'queef': 929,\n",
       " 'dispatchers': 930,\n",
       " 'caltech': 931,\n",
       " 'slardar': 932,\n",
       " 's=geb': 933,\n",
       " 'fluent': 934,\n",
       " 'budd': 935,\n",
       " 'gilmours': 936,\n",
       " 'itinerary': 937,\n",
       " 'starspoked': 938,\n",
       " 'zscore': 939,\n",
       " 'dogo': 940,\n",
       " 'agendas': 941,\n",
       " 'proceeding': 942,\n",
       " 'foolish': 943,\n",
       " 'rancid': 944,\n",
       " 'sunearth': 945,\n",
       " 'flawlessly': 946,\n",
       " 'sqrt': 947,\n",
       " 'kerberos': 948,\n",
       " 'isthe': 949,\n",
       " 'minddoes': 950,\n",
       " 'fuckbook': 951,\n",
       " 'ringtones': 952,\n",
       " '“slavedriving”': 953,\n",
       " 'pujaras': 954,\n",
       " 'creditdebit': 955,\n",
       " 'return;': 956,\n",
       " 'surrenders': 957,\n",
       " 'niobium': 958,\n",
       " 'evans': 959,\n",
       " 'btech\\\\be': 960,\n",
       " 'marathi': 961,\n",
       " 'passward': 962,\n",
       " 'deriphyllin': 963,\n",
       " 'mckinney': 964,\n",
       " 'selfsupport': 965,\n",
       " 'hydranth': 966,\n",
       " 'commitments': 967,\n",
       " 'genere': 968,\n",
       " 'nl': 969,\n",
       " 'rehire': 970,\n",
       " 'monthlyweekely': 971,\n",
       " 'corgishepherd': 972,\n",
       " 'florence:': 973,\n",
       " 'maxwellboltzmann': 974,\n",
       " 'fillings': 975,\n",
       " 'csvm': 976,\n",
       " 'scottsdale': 977,\n",
       " 'hammer': 978,\n",
       " 'byrds': 979,\n",
       " 'moot': 980,\n",
       " 'gojeecoms': 981,\n",
       " 'gravitys': 982,\n",
       " 'co+': 983,\n",
       " 'fairys': 984,\n",
       " 'users”': 985,\n",
       " 'returned': 986,\n",
       " 'willingly': 987,\n",
       " 'handbags': 988,\n",
       " 'veritaserum': 989,\n",
       " 'bitters': 990,\n",
       " 'germanium': 991,\n",
       " 'monetization': 992,\n",
       " 'nadh': 993,\n",
       " 'arabisraeli': 994,\n",
       " 'brazil:': 995,\n",
       " 'coincide': 996,\n",
       " 'pycham': 997,\n",
       " 'simcitytype': 998,\n",
       " 'hoarder': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb8e5723-ac24-4c58-858d-d166a29fdae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_anchor_padded_doc= tokenizer_padding(X_train.q1_preprocessed, max_len=max_length, vocabulary=X_train_vocab)\n",
    "X_val_anchor_padded_doc = tokenizer_padding(X_val.q1_preprocessed, max_len=max_length, vocabulary=X_train_vocab)\n",
    "X_test_anchor_padded_doc = tokenizer_padding(X_test.q1_preprocessed, max_len=max_length, vocabulary=X_train_vocab)\n",
    "\n",
    "X_train_comparison_padded_doc= tokenizer_padding(X_train.q2_preprocessed, max_len=max_length, vocabulary=X_train_vocab)\n",
    "X_val_comparison_padded_doc = tokenizer_padding(X_val.q2_preprocessed, max_len=max_length, vocabulary=X_train_vocab)\n",
    "X_test_comparison_padded_doc = tokenizer_padding(X_test.q2_preprocessed, max_len=max_length, vocabulary=X_train_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e73bd8-dcf8-425d-9c4d-d8dc56f98ca6",
   "metadata": {},
   "source": [
    "### Validating data sequence and pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0f5cee5-3891-42d6-a165-e6a6e5192259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0, 45264,\n",
       "        32179,  7741, 46350, 10398, 64459, 74552, 70818, 44030, 41621,\n",
       "        12829, 45354, 42652, 70818, 66319]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_anchor_padded_doc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecdadd1d-666e-4320-8055-cb2ddd8b10d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0, 13735,  1783, 46350, 89562,\n",
       "        68170, 82135, 19652, 73998, 78824, 40181, 29355, 37175, 61221,\n",
       "         5993, 55547, 51494, 59279, 73686, 13735, 32941, 55547, 70251,\n",
       "        70818, 38127, 37175, 91538, 74440]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_comparison_padded_doc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c41ab3a-e268-4e16-9f79-31eeddef89a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                             79897\n",
       "q1_preprocessed    how come when a plane is crashing the pilots p...\n",
       "q2_preprocessed    i am a final year mech engg student with  curr...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8b8374c-28c2-4fd9-b7f2-b4a740f807e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how come when a plane is crashing the pilots put one arm on the dashboard'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0,:]['q1_preprocessed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b2ebe85-6afd-4a94-859b-6f77f7647e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am a final year mech engg student with  current backlogs and who wants to apply for fall’ i need to send the transcripts and draft sophow'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0,:]['q2_preprocessed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1562bfce-d5cd-41da-b1f8-1d867f873b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tokenizer_padding([X_train.iloc[0,:]['q1_preprocessed']], max_len=max_length, vocabulary=X_train_vocab)\n",
    "b = tokenizer_padding([X_train.iloc[0,:]['q2_preprocessed']], max_len=max_length, vocabulary=X_train_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4343024-3b56-4e30-8964-53c82d5da111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0, 45264,\n",
       "        32179,  7741, 46350, 10398, 64459, 74552, 70818, 44030, 41621,\n",
       "        12829, 45354, 42652, 70818, 66319]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2a82d43-0749-4b61-8b35-f864f2dd5905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0, 13735,  1783, 46350, 89562,\n",
       "        68170, 82135, 19652, 73998, 78824, 40181, 29355, 37175, 61221,\n",
       "         5993, 55547, 51494, 59279, 73686, 13735, 32941, 55547, 70251,\n",
       "        70818, 38127, 37175, 91538, 74440]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f661d8b2-9c28-436a-bdff-f476c6c743f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56c647d6-a9fb-4756-917f-8273f07758c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>386274</th>\n",
       "      <td>386274</td>\n",
       "      <td>11174</td>\n",
       "      <td>95350</td>\n",
       "      <td>How could we know that we are falling in love?</td>\n",
       "      <td>How will you come to know that you are in love?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id   qid1   qid2                                       question1  \\\n",
       "386274  386274  11174  95350  How could we know that we are falling in love?   \n",
       "\n",
       "                                              question2  is_duplicate  \n",
       "386274  How will you come to know that you are in love?             1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.id==386274]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e7598-9dbf-4125-afc0-ff423af880fd",
   "metadata": {},
   "source": [
    "## Preparing data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "89e901cc-4ec9-4713-b97c-3666318c5031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to tensors\n",
    "train_X_anchor = torch.tensor(X_train_anchor_padded_doc)\n",
    "train_X_comparison = torch.tensor(X_train_comparison_padded_doc)\n",
    "train_y = torch.tensor(y_train.astype(float))\n",
    "\n",
    "test_X_anchor = torch.tensor(X_test_anchor_padded_doc)\n",
    "test_X_comparison = torch.tensor(X_test_comparison_padded_doc)\n",
    "test_y = torch.tensor(y_test.astype(float))\n",
    "\n",
    "val_X_anchor = torch.tensor(X_val_anchor_padded_doc)\n",
    "val_X_comparison = torch.tensor(X_val_comparison_padded_doc)\n",
    "val_y = torch.tensor(y_val.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f702a50-5879-4023-b80d-1a6a04006ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 64\n",
    "\n",
    "# FOR TRAINING\n",
    "# Wrap tensors\n",
    "train_data = TensorDataset(train_X_anchor, train_X_comparison, train_y)\n",
    "\n",
    "# Sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# Dataloader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "# FOR VALIDATING\n",
    "# Wrap tensors\n",
    "val_data = TensorDataset(val_X_anchor, val_X_comparison, val_y)\n",
    "\n",
    "# Sampler for sampling the data during validation for training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# Dataloader for val set\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7b1cb6-c9f8-4b08-a0f7-dfd89b21d529",
   "metadata": {},
   "source": [
    "## Modeling without class balancing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44809e9d-8b45-4335-ba38-9728abce95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('D:\\DSAI\\Pre-Trained Models\\word2vec\\GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b8ad58c-7abc-4243-bc4e-ce6cc609ae55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95670, 300)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting embedding matrix for pre-trained Word2Vec model\n",
    "embeddings_index = dict()\n",
    "\n",
    "# We will populate the embeddings_index dictionary with all the key<->vector pairs in the Word2Vec model\n",
    "for line in range(len(w2v_model.index_to_key)):\n",
    "    embeddings_index[w2v_model.index_to_key[line]] = w2v_model.get_vector(w2v_model.index_to_key[line])\n",
    "    \n",
    "# Create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((X_train_vocab_size, 300)) # Change X_train_vocab_size\n",
    "for word, i in X_train_vocab.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94e12c2f-a438-4000-9d75-64aa93f574ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95670"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f340e3-7d7f-49bc-abda-131f19872c9d",
   "metadata": {},
   "source": [
    "## Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b7edc8a-1c68-47d1-b2d1-4a34a4aa6d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters for modeling\n",
    "max_length = seq_len = n_units = 50\n",
    "d_features = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a697ae1c-9fc0-483a-b4cc-b3a61b907db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95670, 300)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71e10d6b-279d-44ce-a49e-4efb9af173f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\.conda\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(input_size=X_train_vocab_size,\n",
    "                  embedding_size=embedding_matrix.shape[1], \n",
    "                  embedding_matrix=embedding_matrix, \n",
    "                  hidden_size=100, \n",
    "                  num_layers=1, \n",
    "                  dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14458d9e-6d28-40e9-8164-e1c08647d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseNetwork(encoder=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5df455a4-2aa1-4a11-976f-f62889ccb5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiameseNetwork(\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (embedding): Embedding(95670, 300, padding_idx=0)\n",
      "    (lstm): LSTM(300, 100, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  )\n",
      "  (cosinesimilarity): CosineSimilarity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6de51966-f3e0-4d26-a491-92a50ac01d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7755502c-5bb1-4324-847a-12e22a422474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "# Define optimiser\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f5996bc-6e69-4553-978b-254b880946a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    204019\n",
       "1    119410\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e990af1-d90f-4924-8c76-d149bd14a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = np.array(y_train.value_counts()[0]/y_train.value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "90370690-f103-4397-b396-48a3a157f3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.70855875)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "21b856e2-6e96-4881-9b9f-e4ebccb516a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting list of class weights to a tensor\n",
    "weights = torch.tensor(weight, dtype=torch.float)\n",
    "\n",
    "# Push weights to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# Define loss function\n",
    "cross_entropy = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "\n",
    "# No of training epochs\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f86bc-0865-405d-b731-c0bd97bfda4c",
   "metadata": {},
   "source": [
    "## Define Training & Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5335f967-58f1-4c7c-b6cb-6006a810d536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    \n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # Empty list to save model predictions\n",
    "    total_preds = []\n",
    "    \n",
    "    # Iterate over batches\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Progress update for every 50 batches\n",
    "        if step%50==0 and not step==0:\n",
    "            print ('Batch {:>5,} of {:>5,}.'.format(step, len(train_dataloader)))\n",
    "            \n",
    "        # Push batch to GPU\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        \n",
    "        anchor_sent, comparison_sent, labels = batch\n",
    "\n",
    "        # Clear previously calculated gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Get model predictions for the current batch\n",
    "        preds = model(anchor_sent, comparison_sent)\n",
    "        \n",
    "        # Compute loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "        \n",
    "        # Add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "        \n",
    "        # Backward pass to calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip gradients to 1.0. It helps in preventing exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Model predictions are stored on GPU, so push it to CPU\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        \n",
    "        # Append model predictions\n",
    "        total_preds.append(preds)\n",
    "        \n",
    "    # Compute training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    \n",
    "    # Predictions are in the form of (no. of batches, size of batch, no of classes)\n",
    "    # Reshape the prediction in form of (no of samples, no of classes)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "    \n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e427105c-c0d4-453a-afb5-a216a290789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    print ('\\nEvaluating...')\n",
    "    \n",
    "    # Deactivate dropout layers\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # Empty list to save model predictions\n",
    "    total_preds = []\n",
    "    \n",
    "    # Iterate over batches\n",
    "    for step, batch in enumerate(val_dataloader):\n",
    "        # Progress update for every 50 batches\n",
    "        if step%50==0 and not step==0:\n",
    "            print ('Batch {:>5,} of {:>5,}.'.format(step, len(val_dataloader)))\n",
    "            \n",
    "        # Push batch to GPU\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        \n",
    "        anchor_sent, comparison_sent, labels = batch\n",
    "        \n",
    "        # Deactivate autograd()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Model predictions\n",
    "            preds = model(anchor_sent, comparison_sent)\n",
    "            \n",
    "            # Compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            \n",
    "            total_loss = total_loss + loss.item()\n",
    "            \n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            \n",
    "            total_preds.append(preds)\n",
    "            \n",
    "    # Compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "    \n",
    "    # Reshape the predictions in form of (no of samples, no of classes)\n",
    "    total_preds = np.concatenate(total_preds, axis=0)\n",
    "    \n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c32aba-e27d-4e1e-bf44-c5c84b631779",
   "metadata": {},
   "source": [
    "## Iterate through training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f416d8ca-97f6-4ce9-865a-5fcd8af8c9d4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/ 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\AppData\\Local\\Temp\\ipykernel_5356\\3622700757.py:36: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch    50 of 5,054.\n",
      "Batch   100 of 5,054.\n",
      "Batch   150 of 5,054.\n",
      "Batch   200 of 5,054.\n",
      "Batch   250 of 5,054.\n",
      "Batch   300 of 5,054.\n",
      "Batch   350 of 5,054.\n",
      "Batch   400 of 5,054.\n",
      "Batch   450 of 5,054.\n",
      "Batch   500 of 5,054.\n",
      "Batch   550 of 5,054.\n",
      "Batch   600 of 5,054.\n",
      "Batch   650 of 5,054.\n",
      "Batch   700 of 5,054.\n",
      "Batch   750 of 5,054.\n",
      "Batch   800 of 5,054.\n",
      "Batch   850 of 5,054.\n",
      "Batch   900 of 5,054.\n",
      "Batch   950 of 5,054.\n",
      "Batch 1,000 of 5,054.\n",
      "Batch 1,050 of 5,054.\n",
      "Batch 1,100 of 5,054.\n",
      "Batch 1,150 of 5,054.\n",
      "Batch 1,200 of 5,054.\n",
      "Batch 1,250 of 5,054.\n",
      "Batch 1,300 of 5,054.\n",
      "Batch 1,350 of 5,054.\n",
      "Batch 1,400 of 5,054.\n",
      "Batch 1,450 of 5,054.\n",
      "Batch 1,500 of 5,054.\n",
      "Batch 1,550 of 5,054.\n",
      "Batch 1,600 of 5,054.\n",
      "Batch 1,650 of 5,054.\n",
      "Batch 1,700 of 5,054.\n",
      "Batch 1,750 of 5,054.\n",
      "Batch 1,800 of 5,054.\n",
      "Batch 1,850 of 5,054.\n",
      "Batch 1,900 of 5,054.\n",
      "Batch 1,950 of 5,054.\n",
      "Batch 2,000 of 5,054.\n",
      "Batch 2,050 of 5,054.\n",
      "Batch 2,100 of 5,054.\n",
      "Batch 2,150 of 5,054.\n",
      "Batch 2,200 of 5,054.\n",
      "Batch 2,250 of 5,054.\n",
      "Batch 2,300 of 5,054.\n",
      "Batch 2,350 of 5,054.\n",
      "Batch 2,400 of 5,054.\n",
      "Batch 2,450 of 5,054.\n",
      "Batch 2,500 of 5,054.\n",
      "Batch 2,550 of 5,054.\n",
      "Batch 2,600 of 5,054.\n",
      "Batch 2,650 of 5,054.\n",
      "Batch 2,700 of 5,054.\n",
      "Batch 2,750 of 5,054.\n",
      "Batch 2,800 of 5,054.\n",
      "Batch 2,850 of 5,054.\n",
      "Batch 2,900 of 5,054.\n",
      "Batch 2,950 of 5,054.\n",
      "Batch 3,000 of 5,054.\n",
      "Batch 3,050 of 5,054.\n",
      "Batch 3,100 of 5,054.\n",
      "Batch 3,150 of 5,054.\n",
      "Batch 3,200 of 5,054.\n",
      "Batch 3,250 of 5,054.\n",
      "Batch 3,300 of 5,054.\n",
      "Batch 3,350 of 5,054.\n",
      "Batch 3,400 of 5,054.\n",
      "Batch 3,450 of 5,054.\n",
      "Batch 3,500 of 5,054.\n",
      "Batch 3,550 of 5,054.\n",
      "Batch 3,600 of 5,054.\n",
      "Batch 3,650 of 5,054.\n",
      "Batch 3,700 of 5,054.\n",
      "Batch 3,750 of 5,054.\n",
      "Batch 3,800 of 5,054.\n",
      "Batch 3,850 of 5,054.\n",
      "Batch 3,900 of 5,054.\n",
      "Batch 3,950 of 5,054.\n",
      "Batch 4,000 of 5,054.\n",
      "Batch 4,050 of 5,054.\n",
      "Batch 4,100 of 5,054.\n",
      "Batch 4,150 of 5,054.\n",
      "Batch 4,200 of 5,054.\n",
      "Batch 4,250 of 5,054.\n",
      "Batch 4,300 of 5,054.\n",
      "Batch 4,350 of 5,054.\n",
      "Batch 4,400 of 5,054.\n",
      "Batch 4,450 of 5,054.\n",
      "Batch 4,500 of 5,054.\n",
      "Batch 4,550 of 5,054.\n",
      "Batch 4,600 of 5,054.\n",
      "Batch 4,650 of 5,054.\n",
      "Batch 4,700 of 5,054.\n",
      "Batch 4,750 of 5,054.\n",
      "Batch 4,800 of 5,054.\n",
      "Batch 4,850 of 5,054.\n",
      "Batch 4,900 of 5,054.\n",
      "Batch 4,950 of 5,054.\n",
      "Batch 5,000 of 5,054.\n",
      "Batch 5,050 of 5,054.\n",
      "\n",
      "Evaluating...\n",
      "Batch    50 of   632.\n",
      "Batch   100 of   632.\n",
      "Batch   150 of   632.\n",
      "Batch   200 of   632.\n",
      "Batch   250 of   632.\n",
      "Batch   300 of   632.\n",
      "Batch   350 of   632.\n",
      "Batch   400 of   632.\n",
      "Batch   450 of   632.\n",
      "Batch   500 of   632.\n",
      "Batch   550 of   632.\n",
      "Batch   600 of   632.\n",
      "\n",
      "Training Loss: 0.84427\n",
      "Validation Loss: 0.83976\n",
      "\n",
      "Epoch 2/ 5\n",
      "Batch    50 of 5,054.\n",
      "Batch   100 of 5,054.\n",
      "Batch   150 of 5,054.\n",
      "Batch   200 of 5,054.\n",
      "Batch   250 of 5,054.\n",
      "Batch   300 of 5,054.\n",
      "Batch   350 of 5,054.\n",
      "Batch   400 of 5,054.\n",
      "Batch   450 of 5,054.\n",
      "Batch   500 of 5,054.\n",
      "Batch   550 of 5,054.\n",
      "Batch   600 of 5,054.\n",
      "Batch   650 of 5,054.\n",
      "Batch   700 of 5,054.\n",
      "Batch   750 of 5,054.\n",
      "Batch   800 of 5,054.\n",
      "Batch   850 of 5,054.\n",
      "Batch   900 of 5,054.\n",
      "Batch   950 of 5,054.\n",
      "Batch 1,000 of 5,054.\n",
      "Batch 1,050 of 5,054.\n",
      "Batch 1,100 of 5,054.\n",
      "Batch 1,150 of 5,054.\n",
      "Batch 1,200 of 5,054.\n",
      "Batch 1,250 of 5,054.\n",
      "Batch 1,300 of 5,054.\n",
      "Batch 1,350 of 5,054.\n",
      "Batch 1,400 of 5,054.\n",
      "Batch 1,450 of 5,054.\n",
      "Batch 1,500 of 5,054.\n",
      "Batch 1,550 of 5,054.\n",
      "Batch 1,600 of 5,054.\n",
      "Batch 1,650 of 5,054.\n",
      "Batch 1,700 of 5,054.\n",
      "Batch 1,750 of 5,054.\n",
      "Batch 1,800 of 5,054.\n",
      "Batch 1,850 of 5,054.\n",
      "Batch 1,900 of 5,054.\n",
      "Batch 1,950 of 5,054.\n",
      "Batch 2,000 of 5,054.\n",
      "Batch 2,050 of 5,054.\n",
      "Batch 2,100 of 5,054.\n",
      "Batch 2,150 of 5,054.\n",
      "Batch 2,200 of 5,054.\n",
      "Batch 2,250 of 5,054.\n",
      "Batch 2,300 of 5,054.\n",
      "Batch 2,350 of 5,054.\n",
      "Batch 2,400 of 5,054.\n",
      "Batch 2,450 of 5,054.\n",
      "Batch 2,500 of 5,054.\n",
      "Batch 2,550 of 5,054.\n",
      "Batch 2,600 of 5,054.\n",
      "Batch 2,650 of 5,054.\n",
      "Batch 2,700 of 5,054.\n",
      "Batch 2,750 of 5,054.\n",
      "Batch 2,800 of 5,054.\n",
      "Batch 2,850 of 5,054.\n",
      "Batch 2,900 of 5,054.\n",
      "Batch 2,950 of 5,054.\n",
      "Batch 3,000 of 5,054.\n",
      "Batch 3,050 of 5,054.\n",
      "Batch 3,100 of 5,054.\n",
      "Batch 3,150 of 5,054.\n",
      "Batch 3,200 of 5,054.\n",
      "Batch 3,250 of 5,054.\n",
      "Batch 3,300 of 5,054.\n",
      "Batch 3,350 of 5,054.\n",
      "Batch 3,400 of 5,054.\n",
      "Batch 3,450 of 5,054.\n",
      "Batch 3,500 of 5,054.\n",
      "Batch 3,550 of 5,054.\n",
      "Batch 3,600 of 5,054.\n",
      "Batch 3,650 of 5,054.\n",
      "Batch 3,700 of 5,054.\n",
      "Batch 3,750 of 5,054.\n",
      "Batch 3,800 of 5,054.\n",
      "Batch 3,850 of 5,054.\n",
      "Batch 3,900 of 5,054.\n",
      "Batch 3,950 of 5,054.\n",
      "Batch 4,000 of 5,054.\n",
      "Batch 4,050 of 5,054.\n",
      "Batch 4,100 of 5,054.\n",
      "Batch 4,150 of 5,054.\n",
      "Batch 4,200 of 5,054.\n",
      "Batch 4,250 of 5,054.\n",
      "Batch 4,300 of 5,054.\n",
      "Batch 4,350 of 5,054.\n",
      "Batch 4,400 of 5,054.\n",
      "Batch 4,450 of 5,054.\n",
      "Batch 4,500 of 5,054.\n",
      "Batch 4,550 of 5,054.\n",
      "Batch 4,600 of 5,054.\n",
      "Batch 4,650 of 5,054.\n",
      "Batch 4,700 of 5,054.\n",
      "Batch 4,750 of 5,054.\n",
      "Batch 4,800 of 5,054.\n",
      "Batch 4,850 of 5,054.\n",
      "Batch 4,900 of 5,054.\n",
      "Batch 4,950 of 5,054.\n",
      "Batch 5,000 of 5,054.\n",
      "Batch 5,050 of 5,054.\n",
      "\n",
      "Evaluating...\n",
      "Batch    50 of   632.\n",
      "Batch   100 of   632.\n",
      "Batch   150 of   632.\n",
      "Batch   200 of   632.\n",
      "Batch   250 of   632.\n",
      "Batch   300 of   632.\n",
      "Batch   350 of   632.\n",
      "Batch   400 of   632.\n",
      "Batch   450 of   632.\n",
      "Batch   500 of   632.\n",
      "Batch   550 of   632.\n",
      "Batch   600 of   632.\n",
      "\n",
      "Training Loss: 0.83373\n",
      "Validation Loss: 0.83410\n",
      "\n",
      "Epoch 3/ 5\n",
      "Batch    50 of 5,054.\n",
      "Batch   100 of 5,054.\n",
      "Batch   150 of 5,054.\n",
      "Batch   200 of 5,054.\n",
      "Batch   250 of 5,054.\n",
      "Batch   300 of 5,054.\n",
      "Batch   350 of 5,054.\n",
      "Batch   400 of 5,054.\n",
      "Batch   450 of 5,054.\n",
      "Batch   500 of 5,054.\n",
      "Batch   550 of 5,054.\n",
      "Batch   600 of 5,054.\n",
      "Batch   650 of 5,054.\n",
      "Batch   700 of 5,054.\n",
      "Batch   750 of 5,054.\n",
      "Batch   800 of 5,054.\n",
      "Batch   850 of 5,054.\n",
      "Batch   900 of 5,054.\n",
      "Batch   950 of 5,054.\n",
      "Batch 1,000 of 5,054.\n",
      "Batch 1,050 of 5,054.\n",
      "Batch 1,100 of 5,054.\n",
      "Batch 1,150 of 5,054.\n",
      "Batch 1,200 of 5,054.\n",
      "Batch 1,250 of 5,054.\n",
      "Batch 1,300 of 5,054.\n",
      "Batch 1,350 of 5,054.\n",
      "Batch 1,400 of 5,054.\n",
      "Batch 1,450 of 5,054.\n",
      "Batch 1,500 of 5,054.\n",
      "Batch 1,550 of 5,054.\n",
      "Batch 1,600 of 5,054.\n",
      "Batch 1,650 of 5,054.\n",
      "Batch 1,700 of 5,054.\n",
      "Batch 1,750 of 5,054.\n",
      "Batch 1,800 of 5,054.\n",
      "Batch 1,850 of 5,054.\n",
      "Batch 1,900 of 5,054.\n",
      "Batch 1,950 of 5,054.\n",
      "Batch 2,000 of 5,054.\n",
      "Batch 2,050 of 5,054.\n",
      "Batch 2,100 of 5,054.\n",
      "Batch 2,150 of 5,054.\n",
      "Batch 2,200 of 5,054.\n",
      "Batch 2,250 of 5,054.\n",
      "Batch 2,300 of 5,054.\n",
      "Batch 2,350 of 5,054.\n",
      "Batch 2,400 of 5,054.\n",
      "Batch 2,450 of 5,054.\n",
      "Batch 2,500 of 5,054.\n",
      "Batch 2,550 of 5,054.\n",
      "Batch 2,600 of 5,054.\n",
      "Batch 2,650 of 5,054.\n",
      "Batch 2,700 of 5,054.\n",
      "Batch 2,750 of 5,054.\n",
      "Batch 2,800 of 5,054.\n",
      "Batch 2,850 of 5,054.\n",
      "Batch 2,900 of 5,054.\n",
      "Batch 2,950 of 5,054.\n",
      "Batch 3,000 of 5,054.\n",
      "Batch 3,050 of 5,054.\n",
      "Batch 3,100 of 5,054.\n",
      "Batch 3,150 of 5,054.\n",
      "Batch 3,200 of 5,054.\n",
      "Batch 3,250 of 5,054.\n",
      "Batch 3,300 of 5,054.\n",
      "Batch 3,350 of 5,054.\n",
      "Batch 3,400 of 5,054.\n",
      "Batch 3,450 of 5,054.\n",
      "Batch 3,500 of 5,054.\n",
      "Batch 3,550 of 5,054.\n",
      "Batch 3,600 of 5,054.\n",
      "Batch 3,650 of 5,054.\n",
      "Batch 3,700 of 5,054.\n",
      "Batch 3,750 of 5,054.\n",
      "Batch 3,800 of 5,054.\n",
      "Batch 3,850 of 5,054.\n",
      "Batch 3,900 of 5,054.\n",
      "Batch 3,950 of 5,054.\n",
      "Batch 4,000 of 5,054.\n",
      "Batch 4,050 of 5,054.\n",
      "Batch 4,100 of 5,054.\n",
      "Batch 4,150 of 5,054.\n",
      "Batch 4,200 of 5,054.\n",
      "Batch 4,250 of 5,054.\n",
      "Batch 4,300 of 5,054.\n",
      "Batch 4,350 of 5,054.\n",
      "Batch 4,400 of 5,054.\n",
      "Batch 4,450 of 5,054.\n",
      "Batch 4,500 of 5,054.\n",
      "Batch 4,550 of 5,054.\n",
      "Batch 4,600 of 5,054.\n",
      "Batch 4,650 of 5,054.\n",
      "Batch 4,700 of 5,054.\n",
      "Batch 4,750 of 5,054.\n",
      "Batch 4,800 of 5,054.\n",
      "Batch 4,850 of 5,054.\n",
      "Batch 4,900 of 5,054.\n",
      "Batch 4,950 of 5,054.\n",
      "Batch 5,000 of 5,054.\n",
      "Batch 5,050 of 5,054.\n",
      "\n",
      "Evaluating...\n",
      "Batch    50 of   632.\n",
      "Batch   100 of   632.\n",
      "Batch   150 of   632.\n",
      "Batch   200 of   632.\n",
      "Batch   250 of   632.\n",
      "Batch   300 of   632.\n",
      "Batch   350 of   632.\n",
      "Batch   400 of   632.\n",
      "Batch   450 of   632.\n",
      "Batch   500 of   632.\n",
      "Batch   550 of   632.\n",
      "Batch   600 of   632.\n",
      "\n",
      "Training Loss: 0.82727\n",
      "Validation Loss: 0.82993\n",
      "\n",
      "Epoch 4/ 5\n",
      "Batch    50 of 5,054.\n",
      "Batch   100 of 5,054.\n",
      "Batch   150 of 5,054.\n",
      "Batch   200 of 5,054.\n",
      "Batch   250 of 5,054.\n",
      "Batch   300 of 5,054.\n",
      "Batch   350 of 5,054.\n",
      "Batch   400 of 5,054.\n",
      "Batch   450 of 5,054.\n",
      "Batch   500 of 5,054.\n",
      "Batch   550 of 5,054.\n",
      "Batch   600 of 5,054.\n",
      "Batch   650 of 5,054.\n",
      "Batch   700 of 5,054.\n",
      "Batch   750 of 5,054.\n",
      "Batch   800 of 5,054.\n",
      "Batch   850 of 5,054.\n",
      "Batch   900 of 5,054.\n",
      "Batch   950 of 5,054.\n",
      "Batch 1,000 of 5,054.\n",
      "Batch 1,050 of 5,054.\n",
      "Batch 1,100 of 5,054.\n",
      "Batch 1,150 of 5,054.\n",
      "Batch 1,200 of 5,054.\n",
      "Batch 1,250 of 5,054.\n",
      "Batch 1,300 of 5,054.\n",
      "Batch 1,350 of 5,054.\n",
      "Batch 1,400 of 5,054.\n",
      "Batch 1,450 of 5,054.\n",
      "Batch 1,500 of 5,054.\n",
      "Batch 1,550 of 5,054.\n",
      "Batch 1,600 of 5,054.\n",
      "Batch 1,650 of 5,054.\n",
      "Batch 1,700 of 5,054.\n",
      "Batch 1,750 of 5,054.\n",
      "Batch 1,800 of 5,054.\n",
      "Batch 1,850 of 5,054.\n",
      "Batch 1,900 of 5,054.\n",
      "Batch 1,950 of 5,054.\n",
      "Batch 2,000 of 5,054.\n",
      "Batch 2,050 of 5,054.\n",
      "Batch 2,100 of 5,054.\n",
      "Batch 2,150 of 5,054.\n",
      "Batch 2,200 of 5,054.\n",
      "Batch 2,250 of 5,054.\n",
      "Batch 2,300 of 5,054.\n",
      "Batch 2,350 of 5,054.\n",
      "Batch 2,400 of 5,054.\n",
      "Batch 2,450 of 5,054.\n",
      "Batch 2,500 of 5,054.\n",
      "Batch 2,550 of 5,054.\n",
      "Batch 2,600 of 5,054.\n",
      "Batch 2,650 of 5,054.\n",
      "Batch 2,700 of 5,054.\n",
      "Batch 2,750 of 5,054.\n",
      "Batch 2,800 of 5,054.\n",
      "Batch 2,850 of 5,054.\n",
      "Batch 2,900 of 5,054.\n",
      "Batch 2,950 of 5,054.\n",
      "Batch 3,000 of 5,054.\n",
      "Batch 3,050 of 5,054.\n",
      "Batch 3,100 of 5,054.\n",
      "Batch 3,150 of 5,054.\n",
      "Batch 3,200 of 5,054.\n",
      "Batch 3,250 of 5,054.\n",
      "Batch 3,300 of 5,054.\n",
      "Batch 3,350 of 5,054.\n",
      "Batch 3,400 of 5,054.\n",
      "Batch 3,450 of 5,054.\n",
      "Batch 3,500 of 5,054.\n",
      "Batch 3,550 of 5,054.\n",
      "Batch 3,600 of 5,054.\n",
      "Batch 3,650 of 5,054.\n",
      "Batch 3,700 of 5,054.\n",
      "Batch 3,750 of 5,054.\n",
      "Batch 3,800 of 5,054.\n",
      "Batch 3,850 of 5,054.\n",
      "Batch 3,900 of 5,054.\n",
      "Batch 3,950 of 5,054.\n",
      "Batch 4,000 of 5,054.\n",
      "Batch 4,050 of 5,054.\n",
      "Batch 4,100 of 5,054.\n",
      "Batch 4,150 of 5,054.\n",
      "Batch 4,200 of 5,054.\n",
      "Batch 4,250 of 5,054.\n",
      "Batch 4,300 of 5,054.\n",
      "Batch 4,350 of 5,054.\n",
      "Batch 4,400 of 5,054.\n",
      "Batch 4,450 of 5,054.\n",
      "Batch 4,500 of 5,054.\n",
      "Batch 4,550 of 5,054.\n",
      "Batch 4,600 of 5,054.\n",
      "Batch 4,650 of 5,054.\n",
      "Batch 4,700 of 5,054.\n",
      "Batch 4,750 of 5,054.\n",
      "Batch 4,800 of 5,054.\n",
      "Batch 4,850 of 5,054.\n",
      "Batch 4,900 of 5,054.\n",
      "Batch 4,950 of 5,054.\n",
      "Batch 5,000 of 5,054.\n",
      "Batch 5,050 of 5,054.\n",
      "\n",
      "Evaluating...\n",
      "Batch    50 of   632.\n",
      "Batch   100 of   632.\n",
      "Batch   150 of   632.\n",
      "Batch   200 of   632.\n",
      "Batch   250 of   632.\n",
      "Batch   300 of   632.\n",
      "Batch   350 of   632.\n",
      "Batch   400 of   632.\n",
      "Batch   450 of   632.\n",
      "Batch   500 of   632.\n",
      "Batch   550 of   632.\n",
      "Batch   600 of   632.\n",
      "\n",
      "Training Loss: 0.82300\n",
      "Validation Loss: 0.82707\n",
      "\n",
      "Epoch 5/ 5\n",
      "Batch    50 of 5,054.\n",
      "Batch   100 of 5,054.\n",
      "Batch   150 of 5,054.\n",
      "Batch   200 of 5,054.\n",
      "Batch   250 of 5,054.\n",
      "Batch   300 of 5,054.\n",
      "Batch   350 of 5,054.\n",
      "Batch   400 of 5,054.\n",
      "Batch   450 of 5,054.\n",
      "Batch   500 of 5,054.\n",
      "Batch   550 of 5,054.\n",
      "Batch   600 of 5,054.\n",
      "Batch   650 of 5,054.\n",
      "Batch   700 of 5,054.\n",
      "Batch   750 of 5,054.\n",
      "Batch   800 of 5,054.\n",
      "Batch   850 of 5,054.\n",
      "Batch   900 of 5,054.\n",
      "Batch   950 of 5,054.\n",
      "Batch 1,000 of 5,054.\n",
      "Batch 1,050 of 5,054.\n",
      "Batch 1,100 of 5,054.\n",
      "Batch 1,150 of 5,054.\n",
      "Batch 1,200 of 5,054.\n",
      "Batch 1,250 of 5,054.\n",
      "Batch 1,300 of 5,054.\n",
      "Batch 1,350 of 5,054.\n",
      "Batch 1,400 of 5,054.\n",
      "Batch 1,450 of 5,054.\n",
      "Batch 1,500 of 5,054.\n",
      "Batch 1,550 of 5,054.\n",
      "Batch 1,600 of 5,054.\n",
      "Batch 1,650 of 5,054.\n",
      "Batch 1,700 of 5,054.\n",
      "Batch 1,750 of 5,054.\n",
      "Batch 1,800 of 5,054.\n",
      "Batch 1,850 of 5,054.\n",
      "Batch 1,900 of 5,054.\n",
      "Batch 1,950 of 5,054.\n",
      "Batch 2,000 of 5,054.\n",
      "Batch 2,050 of 5,054.\n",
      "Batch 2,100 of 5,054.\n",
      "Batch 2,150 of 5,054.\n",
      "Batch 2,200 of 5,054.\n",
      "Batch 2,250 of 5,054.\n",
      "Batch 2,300 of 5,054.\n",
      "Batch 2,350 of 5,054.\n",
      "Batch 2,400 of 5,054.\n",
      "Batch 2,450 of 5,054.\n",
      "Batch 2,500 of 5,054.\n",
      "Batch 2,550 of 5,054.\n",
      "Batch 2,600 of 5,054.\n",
      "Batch 2,650 of 5,054.\n",
      "Batch 2,700 of 5,054.\n",
      "Batch 2,750 of 5,054.\n",
      "Batch 2,800 of 5,054.\n",
      "Batch 2,850 of 5,054.\n",
      "Batch 2,900 of 5,054.\n",
      "Batch 2,950 of 5,054.\n",
      "Batch 3,000 of 5,054.\n",
      "Batch 3,050 of 5,054.\n",
      "Batch 3,100 of 5,054.\n",
      "Batch 3,150 of 5,054.\n",
      "Batch 3,200 of 5,054.\n",
      "Batch 3,250 of 5,054.\n",
      "Batch 3,300 of 5,054.\n",
      "Batch 3,350 of 5,054.\n",
      "Batch 3,400 of 5,054.\n",
      "Batch 3,450 of 5,054.\n",
      "Batch 3,500 of 5,054.\n",
      "Batch 3,550 of 5,054.\n",
      "Batch 3,600 of 5,054.\n",
      "Batch 3,650 of 5,054.\n",
      "Batch 3,700 of 5,054.\n",
      "Batch 3,750 of 5,054.\n",
      "Batch 3,800 of 5,054.\n",
      "Batch 3,850 of 5,054.\n",
      "Batch 3,900 of 5,054.\n",
      "Batch 3,950 of 5,054.\n",
      "Batch 4,000 of 5,054.\n",
      "Batch 4,050 of 5,054.\n",
      "Batch 4,100 of 5,054.\n",
      "Batch 4,150 of 5,054.\n",
      "Batch 4,200 of 5,054.\n",
      "Batch 4,250 of 5,054.\n",
      "Batch 4,300 of 5,054.\n",
      "Batch 4,350 of 5,054.\n",
      "Batch 4,400 of 5,054.\n",
      "Batch 4,450 of 5,054.\n",
      "Batch 4,500 of 5,054.\n",
      "Batch 4,550 of 5,054.\n",
      "Batch 4,600 of 5,054.\n",
      "Batch 4,650 of 5,054.\n",
      "Batch 4,700 of 5,054.\n",
      "Batch 4,750 of 5,054.\n",
      "Batch 4,800 of 5,054.\n",
      "Batch 4,850 of 5,054.\n",
      "Batch 4,900 of 5,054.\n",
      "Batch 4,950 of 5,054.\n",
      "Batch 5,000 of 5,054.\n",
      "Batch 5,050 of 5,054.\n",
      "\n",
      "Evaluating...\n",
      "Batch    50 of   632.\n",
      "Batch   100 of   632.\n",
      "Batch   150 of   632.\n",
      "Batch   200 of   632.\n",
      "Batch   250 of   632.\n",
      "Batch   300 of   632.\n",
      "Batch   350 of   632.\n",
      "Batch   400 of   632.\n",
      "Batch   450 of   632.\n",
      "Batch   500 of   632.\n",
      "Batch   550 of   632.\n",
      "Batch   600 of   632.\n",
      "\n",
      "Training Loss: 0.81944\n",
      "Validation Loss: 0.82432\n"
     ]
    }
   ],
   "source": [
    "# Set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# Empty lists to store training and validation loss of each epoch\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "# For each epoch\n",
    "for epoch in range(epochs):\n",
    "    print ('\\nEpoch {:}/ {:}'.format(epoch+1, epochs))\n",
    "    \n",
    "    # Train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    # Evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    # Save the best model\n",
    "    if valid_loss<best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_model_weights/pytorch_siamese_network.pt')\n",
    "        \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print (f\"\\nTraining Loss: {train_loss:.5f}\")\n",
    "    print (f\"Validation Loss: {valid_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b496953-263f-49c8-8d0a-9cfd8751b8a5",
   "metadata": {},
   "source": [
    "## Visualise training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dba1a685-bfe1-49ca-9d8f-30ffef744a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x220f03fd270>,\n",
       " <matplotlib.lines.Line2D at 0x220f03fd2a0>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, 'g', valid_losses, 'r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
