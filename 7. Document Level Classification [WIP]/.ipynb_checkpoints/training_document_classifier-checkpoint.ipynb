{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e421ede4-03c8-4333-b0ba-311d5b5b452c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\miniconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from doc_classifier import doc_classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68b7b706-2de6-456b-984d-1ae66ebd0541",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:\\Data\\datasets\\imdb_long_text_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3979bca5-f021-41dd-9a16-3baf1d1d63fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>token_lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So im not a big fan of Boll's work but then ag...</td>\n",
       "      <td>negative</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The Cell\" is an exotic masterpiece, a dizzyin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'War movie' is a Hollywood genre that has been...</td>\n",
       "      <td>positive</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taut and organically gripping, Edward Dmytryk'...</td>\n",
       "      <td>positive</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One of the most significant quotes from the en...</td>\n",
       "      <td>positive</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  token_lengths\n",
       "0  So im not a big fan of Boll's work but then ag...  negative            563\n",
       "1  \"The Cell\" is an exotic masterpiece, a dizzyin...  positive            749\n",
       "2  'War movie' is a Hollywood genre that has been...  positive            845\n",
       "3  Taut and organically gripping, Edward Dmytryk'...  positive            608\n",
       "4  One of the most significant quotes from the en...  positive            908"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94fd28cd-5368-41f0-a46f-dde23d662f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], stratify=df['sentiment'], test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeafbc44-2efc-4ada-a19b-2d14471e7d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test\n",
      " sentiment\n",
      "positive    0.514089\n",
      "negative    0.485911\n",
      "Name: proportion, dtype: float64 \n",
      "\n",
      "y_val\n",
      " sentiment\n",
      "positive    0.514605\n",
      "negative    0.485395\n",
      "Name: proportion, dtype: float64 \n",
      "\n",
      "y_train\n",
      " sentiment\n",
      "positive    0.514071\n",
      "negative    0.485929\n",
      "Name: proportion, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"y_test\\n\", y_test.value_counts(normalize=True), '\\n')\n",
    "print (\"y_val\\n\", y_val.value_counts(normalize=True), '\\n')\n",
    "print (\"y_train\\n\", y_train.value_counts(normalize=True), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82dde6d3-dc65-4df9-860b-1d20aca7fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading spacy as sentence chunker\n",
    "# nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc1eb6e-c9e9-4216-abef-3c2797e71824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking each document\n",
    "# X_train_chunked = [nlp(each_sent) for each_sent in X_train]\n",
    "# X_train_chunked = [[sent for sent in nlp(each_sent).sents] for each_sent in X_train[:20]]\n",
    "\n",
    "\n",
    "# # Spacy takes too long, will chunk lexically first\n",
    "# X_train_chunked = [each_sent.split(\". \") for each_sent in X_train]\n",
    "# X_val_chunked = [each_sent.split(\". \") for each_sent in X_val\n",
    "# X_test_chunked = [each_sent.split(\". \") for each_sent in X_test]\n",
    "\n",
    "# Spacy takes too long, will chunk lexically first\n",
    "X_train_chunked = [each_sent.split(\". \") for each_sent in X_train[:20]]\n",
    "X_val_chunked = [each_sent.split(\". \") for each_sent in X_val[:10]]\n",
    "X_test_chunked = [each_sent.split(\". \") for each_sent in X_test[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1afd66c-d5ce-4a59-ae03-e2e2b7592a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max chunk length for X_train:  54\n",
      "Max chunk length for X_val:  31\n",
      "Max chunk length for X_test:  32\n"
     ]
    }
   ],
   "source": [
    "# Check max chunk length\n",
    "print (\"Max chunk length for X_train: \", max([len(chunks) for chunks in X_train_chunked]))\n",
    "print (\"Max chunk length for X_val: \", max([len(chunks) for chunks in X_val_chunked]))\n",
    "print (\"Max chunk length for X_test: \", max([len(chunks) for chunks in X_test_chunked]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14127fba-d0a3-427e-a26c-87dacf9d2c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4655"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a18e6b60-25a9-46c3-9a14-7521734121c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f03ede0-dab9-48dd-b218-86e5c7abadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f722b56-3b31-416a-8084-f89e92383f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\miniconda3\\envs\\nlp\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoder_path = \"D:\\\\DSAI\\\\Pre-Trained Models\\\\distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(encoder_path)\n",
    "encoder = AutoModel.from_pretrained(encoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a29c766-73ef-4aad-a86a-32bfd372d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = [[tokenizer(each_sent, padding='max_length', truncation=True, return_tensors='pt') for each_sent in each_doc] for each_doc in X_train_chunked]\n",
    "X_val_tokenized = [[tokenizer(each_sent, padding='max_length', truncation=True, return_tensors='pt') for each_sent in each_doc] for each_doc in X_val_chunked]\n",
    "X_test_tokenized = [[tokenizer(each_sent, padding='max_length', truncation=True, return_tensors='pt') for each_sent in each_doc] for each_doc in X_test_chunked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec02f1d6-9458-4add-b074-26702adee9f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train_tokenized[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90b3bba3-af81-46d5-914e-5d0094d407c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train_tokenized[0][0]['input_ids'].clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2de89c11-fabd-4b0d-9f04-4547598d6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_seq = [[sent['input_ids'].clone().detach() for sent in doc] for doc in X_train_tokenized]\n",
    "# train_mask = [[sent['attention_mask'].clone().detach() for sent in doc] for doc in X_train_tokenized]\n",
    "\n",
    "# val_seq = [[sent['input_ids'].clone().detach() for sent in doc] for doc in X_val_tokenized]\n",
    "# val_mask = [[sent['attention_mask'].clone().detach() for sent in doc] for doc in X_val_tokenized]\n",
    "\n",
    "# test_seq = [[sent['input_ids'].clone().detach() for sent in doc] for doc in X_test_tokenized]\n",
    "# test_mask = [[sent['attention_mask'].clone().detach() for sent in doc] for doc in X_test_tokenized]\n",
    "\n",
    "# train_label = torch.tensor(y_train.map({'positive':1, 'negative':0}).tolist())\n",
    "# val_label = torch.tensor(y_val.map({'positive':1, 'negative':0}).tolist())\n",
    "# test_label = torch.tensor(y_test.map({'positive':1, 'negative':0}).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd0f79ce-a785-438f-b12a-4dc5d563342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_tensors(document_corpus, embedding_to_extract, max_chunks=30, max_sentence_token_len=512):\n",
    "    doc_list = []\n",
    "    for doc in document_corpus:\n",
    "        sent_list = []\n",
    "        for sent in doc:\n",
    "            sent_list.append(sent[embedding_to_extract].clone().detach()[0])\n",
    "            \n",
    "        sent_seqs = torch.stack(sent_list, dim=0)\n",
    "    \n",
    "        if sent_seqs.size()[0] < max_chunks: # keep it below 30 sentences for now\n",
    "            empty_sent_to_pad = torch.zeros(max_chunks-sent_seqs.size()[0], max_sentence_token_len)\n",
    "    \n",
    "            sent_seqs = torch.cat((empty_sent_to_pad, sent_seqs), dim=0)\n",
    "    \n",
    "        else:\n",
    "            sent_seqs = sent_seqs[:max_chunks, :]\n",
    "    \n",
    "        doc_list.append(sent_seqs)\n",
    "\n",
    "    return torch.stack(doc_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c298891a-8589-4829-b684-06c2048501b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = get_doc_tensors(X_train_tokenized, embedding_to_extract='input_ids', max_chunks=10)\n",
    "train_mask = get_doc_tensors(X_train_tokenized, embedding_to_extract='attention_mask', max_chunks=10)\n",
    "\n",
    "val_seq = get_doc_tensors(X_val_tokenized, embedding_to_extract='input_ids', max_chunks=10)\n",
    "val_mask = get_doc_tensors(X_val_tokenized, embedding_to_extract='attention_mask', max_chunks=10)\n",
    "\n",
    "test_seq = get_doc_tensors(X_test_tokenized, embedding_to_extract='input_ids', max_chunks=10)\n",
    "test_mask = get_doc_tensors(X_test_tokenized, embedding_to_extract='attention_mask', max_chunks=10)\n",
    "\n",
    "# train_label = torch.tensor(y_train.map({'positive':1, 'negative':0}).tolist())\n",
    "# val_label = torch.tensor(y_val.map({'positive':1, 'negative':0}).tolist())\n",
    "# test_label = torch.tensor(y_test.map({'positive':1, 'negative':0}).tolist())\n",
    "\n",
    "train_label = torch.tensor(y_train.map({'positive':1, 'negative':0}).tolist()[:20])\n",
    "val_label = torch.tensor(y_val.map({'positive':1, 'negative':0}).tolist()[:10])\n",
    "test_label = torch.tensor(y_test.map({'positive':1, 'negative':0}).tolist()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54d7d7e0-e72d-422a-b045-e24de3602769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_list = []\n",
    "# for doc in X_train_tokenized:\n",
    "#     sent_list = []\n",
    "#     for sent in doc:\n",
    "#         sent_list.append(sent['input_ids'].clone().detach()[0])\n",
    "        \n",
    "#     sent_seqs = torch.stack(sent_list, dim=0)\n",
    "\n",
    "#     if sent_seqs.size()[0] < 30: # keep it below 30 sentences for now\n",
    "#         empty_sent_to_pad = torch.zeros(30-sent_seqs.size()[0], 512)\n",
    "\n",
    "#         sent_seqs = torch.cat((empty_sent_to_pad, sent_seqs), dim=0)\n",
    "\n",
    "#     else:\n",
    "#         sent_seqs = sent_seqs[:30, :]\n",
    "\n",
    "#     doc_list.append(sent_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c988505-9961-4067-ae35-3643f0ddd10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_seqs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "887b298e-9005-4e45-9b19-9a7eda41801c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.zeros(5, 512).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72c15c73-8520-45af-8af6-bd368917026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_seqs[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bff2607-928f-40ce-939a-7e7c9418720a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7475533-e0b8-48a3-af27-2d42877f8cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462fafb4-4f87-437c-b329-ae96e75fe443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3763e0e-ec17-4172-9139-61fe2f3946a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_seq = torch.stack(doc_list, dim=0) # Need to pas to max length for this one! Else the shape wont fit\n",
    "\n",
    "# Probably have to do the torch.zeros method and slowly fill in the tensor??\n",
    "## Dont need can just manuall pad the fucking thing.. damn annoying - Solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "018c13ae-9d09-454c-aec8-5fb6143408da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_seq.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "066ec74e-c2cf-4301-8480-57bb61b434df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_train_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18ceb388-e1a2-401b-bd2e-8c3b3ae504a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# len(X_train_tokenized[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57261f87-bba0-4ee8-9d16-d3ba41920542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_train_tokenized[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd9d09b7-fca2-4715-9ed6-bdfda7d77695",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sent_seqs[-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "087c0cb0-2ac6-4ee6-b4a6-7ad48d40b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_seq.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e2d70-e1f7-4329-9f06-d694011a83cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "342f1225-5dcc-493a-8825-18d8f0d775e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FOR TRAINING\n",
    "# # Define batch size\n",
    "# batch_size = 8\n",
    "\n",
    "# # Wrap tensors\n",
    "# train_data = TensorDataset(doc_seq)\n",
    "# # Sampler for sampling the data during training\n",
    "# train_sampler = SequentialSampler(train_data)\n",
    "# # Dataloader for train set\n",
    "# train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd215089-1149-4ab4-93b0-33e38ec7d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1997cec6-0410-4661-a9a8-b66d24dfc718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for num, batch in enumerate(train_dataloader):\n",
    "#     see = batch\n",
    "\n",
    "#     print (see[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2b34d56-b4ec-426b-b39e-37b9a7b33da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3236635-740e-48c4-b571-9daf47519332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sent_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fe82276-17d3-428d-a780-6580d9504d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.equal(see[0][-1], sent_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1835dfeb-daa5-4fa5-9845-0ffb0610bcf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# doc_seq[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6689195-4122-4193-a1c2-42cf07a29d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see[0][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e202593-013b-460a-a852-cf6e744eaccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.equal(see[0][-2], doc_seq[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b40cd79-162d-4477-9fcf-bf18537b982c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8e57e-e9dc-4370-9730-8e85a3d98d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92d8ca78-1c9f-49dd-9292-40de21b7b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.map({'positive':1, 'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db675143-4a25-4151-bfbe-a54b55189ea7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.tensor(y_train.map({'positive':1, 'negative':0}).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef52ef71-b6e1-4df8-ad93-4ec84bbcea81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f54ef36-4f5a-49b6-a601-2d9667603fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TRAINING\n",
    "# Define batch size\n",
    "batch_size = 4\n",
    "\n",
    "# Wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_label)\n",
    "# Sampler for sampling the data during training\n",
    "# train_sampler = SequentialSampler(train_data)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# Dataloader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_label)\n",
    "# Sampler for sampling the data during validation for training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "# Dataloader for val set\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Wrap tensors\n",
    "test_data = TensorDataset(test_seq, test_mask, test_label)\n",
    "# Sampler for sampling the data for testing\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "# Dataloader for test set\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8eec708-ec0d-4e14-b36d-82dacd84aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FOR TRAINING\n",
    "# # Define batch size\n",
    "# batch_size = 8\n",
    "\n",
    "# # Wrap tensors\n",
    "# train_data = TensorDataset(train_seq, train_mask, train_label)\n",
    "# # Sampler for sampling the data during training\n",
    "# train_sampler = RandomSampler(train_data)\n",
    "# # Dataloader for train set\n",
    "# train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# # Wrap tensors\n",
    "# val_data = TensorDataset(val_seq, val_mask, val_label)\n",
    "# # Sampler for sampling the data during validation for training\n",
    "# val_sampler = SequentialSampler(val_data)\n",
    "# # Dataloader for val set\n",
    "# val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# # Wrap tensors\n",
    "# test_data = TensorDataset(test_seq, test_mask, test_label)\n",
    "# # Sampler for sampling the data for testing\n",
    "# test_sampler = SequentialSampler(test_data)\n",
    "# # Dataloader for test set\n",
    "# test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b0d24b6-e199-4206-84af-4fd4e05b0d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_anchor_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d53fa88-2399-45a4-a87f-4a75e958b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_anchor_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91f82804-bc65-4675-b110-dd0c07c643f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_anchor_seq[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "693b5b37-5fc4-4ca7-908f-cee6a2dabeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_train_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1785d149-9fe5-44c4-aea9-b508cc8d6f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train_chunked[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "edac36f0-c83f-42e2-ac37-ab3fe9cfad44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# len(X_train_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188a6c18-8a8c-4168-91bd-1e87d4cef4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94b10116-ec31-4a00-8980-12d0b529c8f8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "282a9df2-dfb4-480a-b9f6-06720e44f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for step, batch in enumerate(train_dataloader):\n",
    "#     if step == 0:\n",
    "#         train_seq, train_mask, train_label = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d2a204a-cd7b-4bdb-ab28-2cb46f4d3642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see_tok = tokenizer(['first sentence', 'second sentence'], padding='max_length', truncation=True, return_tensors='pt')\n",
    "# # see_tok = tokenizer(['second sentence'], padding='max_length', truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db4d086c-4266-4fd1-8c53-f34e9599aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see_embed = encoder(see_tok['input_ids'], see_tok['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b38e82b5-d23c-4def-aa58-b18e21314e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see_tok # Seems like there is CLS tokens for distilbert as well (id \"101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d53d0eb-bec7-41f6-8ea7-0c0c9cf84df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see_embed.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb5ab9-8907-4b4b-a8da-740f31740fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec9ce888-220f-40de-9b3d-b430c8956e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([[[1,1,1], [2,2,2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02f644d8-bfd5-4621-a47c-c8669daf4d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.zeros((2,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "725a2c79-43da-4201-b72a-ce4b08648b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = np.ones((8,10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "894fc4e2-1d7a-4a7a-b452-ed23cb58d6e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c2740ae-69b2-40fc-a6f4-0f30598ae453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a[0,0] = [2,2,2]\n",
    "# a[1,0] = [1,1,1]\n",
    "# a[2,0] = [1,1,1]\n",
    "# a[3,0] = [1,1,1]\n",
    "# a[4,0] = [1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6468ddc4-45a0-4cf6-9373-a31560786e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6463ff1-e130-46cd-95cf-c57fc7e462b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c9c88-dd30-4dec-9610-5333e015f0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89da651a-9c40-4a28-a708-bd20e526b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_seq.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d57345f-ab28-4375-bae1-1f32dbff7a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_seq.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "97701150-1f1b-45d4-b443-758a4b76e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_seq.size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1c9cad6-c547-47f4-8d76-7f590ef28fa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e3c235-e288-4e80-9864-97e46049812d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d03d1-c063-4327-a38e-32378e8e46fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cfbe81-a667-4fb6-a456-eb096b923665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8c53926-4181-4a99-8717-92af7f282933",
   "metadata": {},
   "source": [
    "---\n",
    "## Training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4eb587be-34fa-48ee-9ee8-bf9acc63a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = doc_classifier(encoder, dropout=0.2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b3e1f188-5d36-4ba8-abcf-f42c5cf5360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87b14626-0a3a-423f-abe4-2b9781c9a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "# Define optimiser\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18460847-43b2-4ddb-99f8-c322878aed5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\AppData\\Local\\Temp\\ipykernel_14356\\3720588486.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  weight = np.array(y_train.value_counts()[0]/y_train.value_counts()[1])\n",
      "C:\\Users\\solom\\AppData\\Local\\Temp\\ipykernel_14356\\3720588486.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  weight = np.array(y_train.value_counts()[0]/y_train.value_counts()[1])\n"
     ]
    }
   ],
   "source": [
    "weight = np.array(y_train.value_counts()[0]/y_train.value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c0908ad-99da-4c99-8a77-0fd427644ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting list of class weights to a tensor\n",
    "weights = torch.tensor(weight, dtype=torch.float)\n",
    "\n",
    "# Push weights to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# Define loss function\n",
    "cross_entropy = nn.BCEWithLogitsLoss(pos_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "559242b9-1630-4508-8dd4-22d5db6a778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # Empty list to save model predictions\n",
    "    total_preds = []\n",
    "    \n",
    "    # Iterate over batches\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Progress update for every 50 batches\n",
    "        if step%10==0 and not step==0:\n",
    "            print ('Batch {:>5,} of {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        # Push batch to GPU\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        train_input_seq, train_input_mask, train_input_label = batch\n",
    "\n",
    "        # Clear previously calculated gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Get model predictions for the current batch\n",
    "        train_output = model(train_input_seq, train_input_mask)\n",
    "        \n",
    "        \"\"\"\n",
    "        nn.CosineSimilarity measures similarity between 2 outputs, the more similar, the bigger the score.\n",
    "        However for triplet loss, the positive cases are supposed to be closer and have a smaller score.\n",
    "        To make things easier, we flipped the negative and positive positions\n",
    "        i.e. loss(anchor, positive, negative) --> loss(anchor, negative, positive)\n",
    "        \"\"\"\n",
    "\n",
    "        # print (train_output, train_input_label)\n",
    "        # print (torch.squeeze(train_output))\n",
    "        \n",
    "        # Compute loss \n",
    "        # loss = cross_entropy(train_output, train_input_label)\n",
    "        loss = cross_entropy(torch.squeeze(train_output), train_input_label.float())\n",
    "\n",
    "        # Add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # Backward pass to calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    # Compute training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "99269c15-840a-43b9-acc8-fd18b59ef47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val_dataloader):\n",
    "    print ('\\nEvaluating...')\n",
    "    \n",
    "    # Deactivate dropout layers\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # Empty list to save model predictions\n",
    "    total_preds = []\n",
    "    \n",
    "    # Iterate over batches\n",
    "    for step, batch in enumerate(val_dataloader):\n",
    "        # Progress update for every 50 batches\n",
    "        if step%10==0 and not step==0:\n",
    "            print ('Batch {:>5,} of {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # Push batch to GPU\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        val_input_seq, val_input_mask, val_input_label = batch\n",
    "\n",
    "        # Deactivate autograd()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            \n",
    "            # Get model predictions for the current batch\n",
    "            val_output = model(val_input_seq, val_input_mask)\n",
    "        \n",
    "            \"\"\"\n",
    "            nn.CosineSimilarity measures similarity between 2 outputs, the more similar, the bigger the score.\n",
    "            However for triplet loss, the positive cases are supposed to be closer and have a smaller score.\n",
    "            To make things easier, we flipped the negative and positive positions\n",
    "            i.e. loss(anchor, positive, negative) --> loss(anchor, negative, positive)\n",
    "            \"\"\"\n",
    "\n",
    "            # Compute loss \n",
    "            # loss = cross_entropy(val_output, val_input_label)\n",
    "            loss = cross_entropy(torch.squeeze(val_output), val_input_label.float())\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "    # Compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fa283ff2-855a-48bf-acad-88f3e713cab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/ 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.72460\n",
      "Validation Loss: 0.74800\n",
      "\n",
      "Epoch 2/ 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.69192\n",
      "Validation Loss: 0.73894\n",
      "\n",
      "Epoch 3/ 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.66993\n",
      "Validation Loss: 0.71230\n",
      "\n",
      "Epoch 4/ 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.64219\n",
      "Validation Loss: 0.70120\n",
      "\n",
      "Epoch 5/ 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.56997\n",
      "Validation Loss: 0.71520\n",
      "\n",
      "Epoch 6/ 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.48410\n",
      "Validation Loss: 0.69667\n",
      "\n",
      "Epoch 7/ 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.38769\n",
      "Validation Loss: 0.64958\n",
      "\n",
      "Epoch 8/ 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.26072\n",
      "Validation Loss: 0.65996\n",
      "\n",
      "Epoch 9/ 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.17890\n",
      "Validation Loss: 0.59853\n",
      "\n",
      "Epoch 10/ 10\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.09914\n",
      "Validation Loss: 0.58876\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "# Set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# Empty lists to store training and validation loss of each epoch\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "# For each epoch\n",
    "for epoch in range(epochs):\n",
    "    print ('\\nEpoch {:}/ {:}'.format(epoch+1, epochs))\n",
    "    \n",
    "    # Train model\n",
    "    train_loss = train(train_dataloader)\n",
    "    \n",
    "    # Evaluate model\n",
    "    valid_loss = evaluate(val_dataloader)\n",
    "    \n",
    "    # Save the best model\n",
    "    if valid_loss<best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'test_model.pt')\n",
    "        \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print (f\"\\nTraining Loss: {train_loss:.5f}\")\n",
    "    print (f\"Validation Loss: {valid_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b191b225-66f0-47a3-a4c7-7345072d2731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1763b800880>,\n",
       " <matplotlib.lines.Line2D at 0x1763b800970>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, 'g', valid_losses, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eca2964-13de-452b-b0f2-74375bef51ae",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16cef46a-f3df-4904-b3bf-391ff1aa44ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\AppData\\Local\\Temp\\ipykernel_14356\\1946172375.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'test_model.pt'\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf75e4ac-86f0-4ba9-870c-f34311b776a9",
   "metadata": {},
   "source": [
    "### Train Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b3e6364-eaf5-4a65-b403-65dea34fa2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs_logits = []\n",
    "labels = []\n",
    "\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    # Push batch to GPU\n",
    "    batch = [r.to(device) for r in batch]\n",
    "    train_input_seq, train_input_mask, train_input_label = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get model predictions for the current batch\n",
    "        train_output = model(train_input_seq, train_input_mask)\n",
    "\n",
    "        all_outputs_logits += train_output\n",
    "        labels += train_input_label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5f1c481d-ee09-4220-8eb5-8cdd83931585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f6705d20-c003-4c3f-9775-d84ad7aa6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "957eb4c8-d110-4680-8678-85460cf470a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs_proba = []\n",
    "for each in all_outputs_logits:\n",
    "    all_outputs_proba += sigmoid(each).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6546f20c-6a40-47f9-a3ce-a01892338c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs = [1 if i>0.5 else 0 for i in all_outputs_proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7da27c37-756b-4479-a4c2-37d1df540f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(all_outputs, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed8a52d-eb30-4143-ac39-572a034e5f54",
   "metadata": {},
   "source": [
    "### Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b92de497-ec2d-481c-84b5-608f4d72b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_outputs_logits = []\n",
    "test_labels = []\n",
    "\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    # Push batch to GPU\n",
    "    batch = [r.to(device) for r in batch]\n",
    "    test_input_seq, test_input_mask, test_input_label = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get model predictions for the current batch\n",
    "        test_output = model(test_input_seq, test_input_mask)\n",
    "\n",
    "        all_test_outputs_logits += test_output\n",
    "        test_labels += test_input_label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f0b4406-4368-4c92-9d23-6797016e5c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_outputs_proba = []\n",
    "for each in all_test_outputs_logits:\n",
    "    all_test_outputs_proba += sigmoid(each).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "53879a1e-43a9-4b1a-97cd-93867aaa586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_outputs = [1 if i>0.35 else 0 for i in all_test_outputs_proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b9be5a7c-57c9-47b6-b664-beafb6aca17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         3\n",
      "           1       0.86      0.86      0.86         7\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.76      0.76      0.76        10\n",
      "weighted avg       0.80      0.80      0.80        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(all_test_outputs, test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
