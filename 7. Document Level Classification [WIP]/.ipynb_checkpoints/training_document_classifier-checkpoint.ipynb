{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e421ede4-03c8-4333-b0ba-311d5b5b452c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\miniconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from doc_classifier import doc_classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68b7b706-2de6-456b-984d-1ae66ebd0541",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:\\Data\\datasets\\imdb_long_text_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3979bca5-f021-41dd-9a16-3baf1d1d63fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>token_lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So im not a big fan of Boll's work but then ag...</td>\n",
       "      <td>negative</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The Cell\" is an exotic masterpiece, a dizzyin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'War movie' is a Hollywood genre that has been...</td>\n",
       "      <td>positive</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taut and organically gripping, Edward Dmytryk'...</td>\n",
       "      <td>positive</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One of the most significant quotes from the en...</td>\n",
       "      <td>positive</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  token_lengths\n",
       "0  So im not a big fan of Boll's work but then ag...  negative            563\n",
       "1  \"The Cell\" is an exotic masterpiece, a dizzyin...  positive            749\n",
       "2  'War movie' is a Hollywood genre that has been...  positive            845\n",
       "3  Taut and organically gripping, Edward Dmytryk'...  positive            608\n",
       "4  One of the most significant quotes from the en...  positive            908"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94fd28cd-5368-41f0-a46f-dde23d662f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], stratify=df['sentiment'], test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeafbc44-2efc-4ada-a19b-2d14471e7d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test\n",
      " sentiment\n",
      "positive    0.514089\n",
      "negative    0.485911\n",
      "Name: proportion, dtype: float64 \n",
      "\n",
      "y_val\n",
      " sentiment\n",
      "positive    0.514605\n",
      "negative    0.485395\n",
      "Name: proportion, dtype: float64 \n",
      "\n",
      "y_train\n",
      " sentiment\n",
      "positive    0.514071\n",
      "negative    0.485929\n",
      "Name: proportion, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"y_test\\n\", y_test.value_counts(normalize=True), '\\n')\n",
    "print (\"y_val\\n\", y_val.value_counts(normalize=True), '\\n')\n",
    "print (\"y_train\\n\", y_train.value_counts(normalize=True), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82dde6d3-dc65-4df9-860b-1d20aca7fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading spacy as sentence chunker\n",
    "# nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc1eb6e-c9e9-4216-abef-3c2797e71824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking each document\n",
    "# X_train_chunked = [nlp(each_sent) for each_sent in X_train]\n",
    "# X_train_chunked = [[sent for sent in nlp(each_sent).sents] for each_sent in X_train[:20]]\n",
    "\n",
    "\n",
    "# # Spacy takes too long, will chunk lexically first\n",
    "# X_train_chunked = [each_sent.split(\". \") for each_sent in X_train]\n",
    "# X_val_chunked = [each_sent.split(\". \") for each_sent in X_val\n",
    "# X_test_chunked = [each_sent.split(\". \") for each_sent in X_test]\n",
    "\n",
    "# Spacy takes too long, will chunk lexically first\n",
    "X_train_chunked = [each_sent.split(\". \") for each_sent in X_train[:40]]\n",
    "X_val_chunked = [each_sent.split(\". \") for each_sent in X_val[:40]]\n",
    "X_test_chunked = [each_sent.split(\". \") for each_sent in X_test[:40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1afd66c-d5ce-4a59-ae03-e2e2b7592a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max chunk length for X_train:  31\n",
      "Max chunk length for X_val:  51\n",
      "Max chunk length for X_test:  43\n"
     ]
    }
   ],
   "source": [
    "# Check max chunk length\n",
    "print (\"Max chunk length for X_train: \", max([len(chunks) for chunks in X_train_chunked]))\n",
    "print (\"Max chunk length for X_val: \", max([len(chunks) for chunks in X_val_chunked]))\n",
    "print (\"Max chunk length for X_test: \", max([len(chunks) for chunks in X_test_chunked]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14127fba-d0a3-427e-a26c-87dacf9d2c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4655"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a18e6b60-25a9-46c3-9a14-7521734121c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f03ede0-dab9-48dd-b218-86e5c7abadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f722b56-3b31-416a-8084-f89e92383f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\miniconda3\\envs\\nlp\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoder_path = \"D:\\\\DSAI\\\\Pre-Trained Models\\\\distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(encoder_path)\n",
    "encoder = AutoModel.from_pretrained(encoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a29c766-73ef-4aad-a86a-32bfd372d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = [[tokenizer(each_sent, padding='max_length', truncation=True, return_tensors='pt') for each_sent in each_doc] for each_doc in X_train_chunked]\n",
    "X_val_tokenized = [[tokenizer(each_sent, padding='max_length', truncation=True, return_tensors='pt') for each_sent in each_doc] for each_doc in X_val_chunked]\n",
    "X_test_tokenized = [[tokenizer(each_sent, padding='max_length', truncation=True, return_tensors='pt') for each_sent in each_doc] for each_doc in X_test_chunked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec02f1d6-9458-4add-b074-26702adee9f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train_tokenized[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90b3bba3-af81-46d5-914e-5d0094d407c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train_tokenized[0][0]['input_ids'].clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2de89c11-fabd-4b0d-9f04-4547598d6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_seq = [[sent['input_ids'].clone().detach() for sent in doc] for doc in X_train_tokenized]\n",
    "# train_mask = [[sent['attention_mask'].clone().detach() for sent in doc] for doc in X_train_tokenized]\n",
    "\n",
    "# val_seq = [[sent['input_ids'].clone().detach() for sent in doc] for doc in X_val_tokenized]\n",
    "# val_mask = [[sent['attention_mask'].clone().detach() for sent in doc] for doc in X_val_tokenized]\n",
    "\n",
    "# test_seq = [[sent['input_ids'].clone().detach() for sent in doc] for doc in X_test_tokenized]\n",
    "# test_mask = [[sent['attention_mask'].clone().detach() for sent in doc] for doc in X_test_tokenized]\n",
    "\n",
    "# train_label = torch.tensor(y_train.map({'positive':1, 'negative':0}).tolist())\n",
    "# val_label = torch.tensor(y_val.map({'positive':1, 'negative':0}).tolist())\n",
    "# test_label = torch.tensor(y_test.map({'positive':1, 'negative':0}).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd0f79ce-a785-438f-b12a-4dc5d563342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_tensors(document_corpus, embedding_to_extract, max_chunks=30, max_sentence_token_len=512):\n",
    "    doc_list = []\n",
    "    for doc in document_corpus:\n",
    "        sent_list = []\n",
    "        for sent in doc:\n",
    "            sent_list.append(sent[embedding_to_extract].clone().detach()[0])\n",
    "            \n",
    "        sent_seqs = torch.stack(sent_list, dim=0)\n",
    "    \n",
    "        if sent_seqs.size()[0] < max_chunks: # keep it below 30 sentences for now\n",
    "            empty_sent_to_pad = torch.zeros(max_chunks-sent_seqs.size()[0], max_sentence_token_len)\n",
    "    \n",
    "            sent_seqs = torch.cat((empty_sent_to_pad, sent_seqs), dim=0)\n",
    "    \n",
    "        else:\n",
    "            sent_seqs = sent_seqs[:max_chunks, :]\n",
    "    \n",
    "        doc_list.append(sent_seqs)\n",
    "\n",
    "    return torch.stack(doc_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c298891a-8589-4829-b684-06c2048501b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = get_doc_tensors(X_train_tokenized, embedding_to_extract='input_ids', max_chunks=10)\n",
    "train_mask = get_doc_tensors(X_train_tokenized, embedding_to_extract='attention_mask', max_chunks=10)\n",
    "\n",
    "val_seq = get_doc_tensors(X_val_tokenized, embedding_to_extract='input_ids', max_chunks=10)\n",
    "val_mask = get_doc_tensors(X_val_tokenized, embedding_to_extract='attention_mask', max_chunks=10)\n",
    "\n",
    "test_seq = get_doc_tensors(X_test_tokenized, embedding_to_extract='input_ids', max_chunks=10)\n",
    "test_mask = get_doc_tensors(X_test_tokenized, embedding_to_extract='attention_mask', max_chunks=10)\n",
    "\n",
    "# train_label = torch.tensor(y_train.map({'positive':1, 'negative':0}).tolist())\n",
    "# val_label = torch.tensor(y_val.map({'positive':1, 'negative':0}).tolist())\n",
    "# test_label = torch.tensor(y_test.map({'positive':1, 'negative':0}).tolist())\n",
    "\n",
    "train_label = torch.tensor(y_train.map({'positive':1, 'negative':0}).tolist()[:40])\n",
    "val_label = torch.tensor(y_val.map({'positive':1, 'negative':0}).tolist()[:40])\n",
    "test_label = torch.tensor(y_test.map({'positive':1, 'negative':0}).tolist()[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54d7d7e0-e72d-422a-b045-e24de3602769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_list = []\n",
    "# for doc in X_train_tokenized:\n",
    "#     sent_list = []\n",
    "#     for sent in doc:\n",
    "#         sent_list.append(sent['input_ids'].clone().detach()[0])\n",
    "        \n",
    "#     sent_seqs = torch.stack(sent_list, dim=0)\n",
    "\n",
    "#     if sent_seqs.size()[0] < 30: # keep it below 30 sentences for now\n",
    "#         empty_sent_to_pad = torch.zeros(30-sent_seqs.size()[0], 512)\n",
    "\n",
    "#         sent_seqs = torch.cat((empty_sent_to_pad, sent_seqs), dim=0)\n",
    "\n",
    "#     else:\n",
    "#         sent_seqs = sent_seqs[:30, :]\n",
    "\n",
    "#     doc_list.append(sent_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c988505-9961-4067-ae35-3643f0ddd10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_seqs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "887b298e-9005-4e45-9b19-9a7eda41801c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.zeros(5, 512).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72c15c73-8520-45af-8af6-bd368917026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_seqs[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bff2607-928f-40ce-939a-7e7c9418720a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7475533-e0b8-48a3-af27-2d42877f8cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462fafb4-4f87-437c-b329-ae96e75fe443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3763e0e-ec17-4172-9139-61fe2f3946a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_seq = torch.stack(doc_list, dim=0) # Need to pas to max length for this one! Else the shape wont fit\n",
    "\n",
    "# Probably have to do the torch.zeros method and slowly fill in the tensor??\n",
    "## Dont need can just manuall pad the fucking thing.. damn annoying - Solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "018c13ae-9d09-454c-aec8-5fb6143408da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_seq.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "066ec74e-c2cf-4301-8480-57bb61b434df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_train_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18ceb388-e1a2-401b-bd2e-8c3b3ae504a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# len(X_train_tokenized[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57261f87-bba0-4ee8-9d16-d3ba41920542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_train_tokenized[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd9d09b7-fca2-4715-9ed6-bdfda7d77695",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sent_seqs[-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "087c0cb0-2ac6-4ee6-b4a6-7ad48d40b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_seq.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e2d70-e1f7-4329-9f06-d694011a83cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "342f1225-5dcc-493a-8825-18d8f0d775e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FOR TRAINING\n",
    "# # Define batch size\n",
    "# batch_size = 8\n",
    "\n",
    "# # Wrap tensors\n",
    "# train_data = TensorDataset(doc_seq)\n",
    "# # Sampler for sampling the data during training\n",
    "# train_sampler = SequentialSampler(train_data)\n",
    "# # Dataloader for train set\n",
    "# train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd215089-1149-4ab4-93b0-33e38ec7d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1997cec6-0410-4661-a9a8-b66d24dfc718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for num, batch in enumerate(train_dataloader):\n",
    "#     see = batch\n",
    "\n",
    "#     print (see[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2b34d56-b4ec-426b-b39e-37b9a7b33da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3236635-740e-48c4-b571-9daf47519332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sent_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fe82276-17d3-428d-a780-6580d9504d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.equal(see[0][-1], sent_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1835dfeb-daa5-4fa5-9845-0ffb0610bcf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# doc_seq[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6689195-4122-4193-a1c2-42cf07a29d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see[0][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e202593-013b-460a-a852-cf6e744eaccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.equal(see[0][-2], doc_seq[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b40cd79-162d-4477-9fcf-bf18537b982c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8e57e-e9dc-4370-9730-8e85a3d98d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92d8ca78-1c9f-49dd-9292-40de21b7b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.map({'positive':1, 'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db675143-4a25-4151-bfbe-a54b55189ea7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.tensor(y_train.map({'positive':1, 'negative':0}).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef52ef71-b6e1-4df8-ad93-4ec84bbcea81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f54ef36-4f5a-49b6-a601-2d9667603fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TRAINING\n",
    "# Define batch size\n",
    "batch_size = 2\n",
    "\n",
    "# Wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_label)\n",
    "# Sampler for sampling the data during training\n",
    "# train_sampler = SequentialSampler(train_data)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# Dataloader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_label)\n",
    "# Sampler for sampling the data during validation for training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "# Dataloader for val set\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Wrap tensors\n",
    "test_data = TensorDataset(test_seq, test_mask, test_label)\n",
    "# Sampler for sampling the data for testing\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "# Dataloader for test set\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8eec708-ec0d-4e14-b36d-82dacd84aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FOR TRAINING\n",
    "# # Define batch size\n",
    "# batch_size = 8\n",
    "\n",
    "# # Wrap tensors\n",
    "# train_data = TensorDataset(train_seq, train_mask, train_label)\n",
    "# # Sampler for sampling the data during training\n",
    "# train_sampler = RandomSampler(train_data)\n",
    "# # Dataloader for train set\n",
    "# train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# # Wrap tensors\n",
    "# val_data = TensorDataset(val_seq, val_mask, val_label)\n",
    "# # Sampler for sampling the data during validation for training\n",
    "# val_sampler = SequentialSampler(val_data)\n",
    "# # Dataloader for val set\n",
    "# val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# # Wrap tensors\n",
    "# test_data = TensorDataset(test_seq, test_mask, test_label)\n",
    "# # Sampler for sampling the data for testing\n",
    "# test_sampler = SequentialSampler(test_data)\n",
    "# # Dataloader for test set\n",
    "# test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b0d24b6-e199-4206-84af-4fd4e05b0d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_anchor_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d53fa88-2399-45a4-a87f-4a75e958b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_anchor_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91f82804-bc65-4675-b110-dd0c07c643f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_anchor_seq[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "693b5b37-5fc4-4ca7-908f-cee6a2dabeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_train_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1785d149-9fe5-44c4-aea9-b508cc8d6f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train_chunked[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "edac36f0-c83f-42e2-ac37-ab3fe9cfad44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# len(X_train_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188a6c18-8a8c-4168-91bd-1e87d4cef4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94b10116-ec31-4a00-8980-12d0b529c8f8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "282a9df2-dfb4-480a-b9f6-06720e44f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for step, batch in enumerate(train_dataloader):\n",
    "#     if step == 0:\n",
    "#         train_seq, train_mask, train_label = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d2a204a-cd7b-4bdb-ab28-2cb46f4d3642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see_tok = tokenizer(['first sentence', 'second sentence'], padding='max_length', truncation=True, return_tensors='pt')\n",
    "# # see_tok = tokenizer(['second sentence'], padding='max_length', truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db4d086c-4266-4fd1-8c53-f34e9599aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see_embed = encoder(see_tok['input_ids'], see_tok['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b38e82b5-d23c-4def-aa58-b18e21314e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see_tok # Seems like there is CLS tokens for distilbert as well (id \"101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d53d0eb-bec7-41f6-8ea7-0c0c9cf84df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see_embed.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb5ab9-8907-4b4b-a8da-740f31740fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec9ce888-220f-40de-9b3d-b430c8956e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([[[1,1,1], [2,2,2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02f644d8-bfd5-4621-a47c-c8669daf4d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.zeros((2,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "725a2c79-43da-4201-b72a-ce4b08648b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = np.ones((8,10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "894fc4e2-1d7a-4a7a-b452-ed23cb58d6e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c2740ae-69b2-40fc-a6f4-0f30598ae453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a[0,0] = [2,2,2]\n",
    "# a[1,0] = [1,1,1]\n",
    "# a[2,0] = [1,1,1]\n",
    "# a[3,0] = [1,1,1]\n",
    "# a[4,0] = [1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6468ddc4-45a0-4cf6-9373-a31560786e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6463ff1-e130-46cd-95cf-c57fc7e462b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c9c88-dd30-4dec-9610-5333e015f0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89da651a-9c40-4a28-a708-bd20e526b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_seq.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d57345f-ab28-4375-bae1-1f32dbff7a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_seq.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "97701150-1f1b-45d4-b443-758a4b76e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_seq.size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1c9cad6-c547-47f4-8d76-7f590ef28fa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e3c235-e288-4e80-9864-97e46049812d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d03d1-c063-4327-a38e-32378e8e46fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cfbe81-a667-4fb6-a456-eb096b923665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8c53926-4181-4a99-8717-92af7f282933",
   "metadata": {},
   "source": [
    "---\n",
    "## Training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4eb587be-34fa-48ee-9ee8-bf9acc63a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = doc_classifier(encoder, dropout=0.2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b3e1f188-5d36-4ba8-abcf-f42c5cf5360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87b14626-0a3a-423f-abe4-2b9781c9a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "# Define optimiser\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18460847-43b2-4ddb-99f8-c322878aed5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\AppData\\Local\\Temp\\ipykernel_13100\\3720588486.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  weight = np.array(y_train.value_counts()[0]/y_train.value_counts()[1])\n",
      "C:\\Users\\solom\\AppData\\Local\\Temp\\ipykernel_13100\\3720588486.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  weight = np.array(y_train.value_counts()[0]/y_train.value_counts()[1])\n"
     ]
    }
   ],
   "source": [
    "weight = np.array(y_train.value_counts()[0]/y_train.value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c0908ad-99da-4c99-8a77-0fd427644ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting list of class weights to a tensor\n",
    "weights = torch.tensor(weight, dtype=torch.float)\n",
    "\n",
    "# Push weights to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# Define loss function\n",
    "cross_entropy = nn.BCEWithLogitsLoss(pos_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "559242b9-1630-4508-8dd4-22d5db6a778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # Empty list to save model predictions\n",
    "    total_preds = []\n",
    "    \n",
    "    # Iterate over batches\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Progress update for every 50 batches\n",
    "        if step%10==0 and not step==0:\n",
    "            print ('Batch {:>5,} of {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        # Push batch to GPU\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        train_input_seq, train_input_mask, train_input_label = batch\n",
    "\n",
    "        # Clear previously calculated gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Get model predictions for the current batch\n",
    "        train_output = model(train_input_seq, train_input_mask)\n",
    "        \n",
    "        \"\"\"\n",
    "        nn.CosineSimilarity measures similarity between 2 outputs, the more similar, the bigger the score.\n",
    "        However for triplet loss, the positive cases are supposed to be closer and have a smaller score.\n",
    "        To make things easier, we flipped the negative and positive positions\n",
    "        i.e. loss(anchor, positive, negative) --> loss(anchor, negative, positive)\n",
    "        \"\"\"\n",
    "\n",
    "        # print (train_output, train_input_label)\n",
    "        # print (torch.squeeze(train_output))\n",
    "        \n",
    "        # Compute loss \n",
    "        # loss = cross_entropy(train_output, train_input_label)\n",
    "        loss = cross_entropy(torch.squeeze(train_output), train_input_label.float())\n",
    "\n",
    "        # Add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # Backward pass to calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    # Compute training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "99269c15-840a-43b9-acc8-fd18b59ef47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val_dataloader):\n",
    "    print ('\\nEvaluating...')\n",
    "    \n",
    "    # Deactivate dropout layers\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # Empty list to save model predictions\n",
    "    total_preds = []\n",
    "    \n",
    "    # Iterate over batches\n",
    "    for step, batch in enumerate(val_dataloader):\n",
    "        # Progress update for every 50 batches\n",
    "        if step%10==0 and not step==0:\n",
    "            print ('Batch {:>5,} of {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # Push batch to GPU\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        val_input_seq, val_input_mask, val_input_label = batch\n",
    "\n",
    "        # Deactivate autograd()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            \n",
    "            # Get model predictions for the current batch\n",
    "            val_output = model(val_input_seq, val_input_mask)\n",
    "        \n",
    "            \"\"\"\n",
    "            nn.CosineSimilarity measures similarity between 2 outputs, the more similar, the bigger the score.\n",
    "            However for triplet loss, the positive cases are supposed to be closer and have a smaller score.\n",
    "            To make things easier, we flipped the negative and positive positions\n",
    "            i.e. loss(anchor, positive, negative) --> loss(anchor, negative, positive)\n",
    "            \"\"\"\n",
    "\n",
    "            # Compute loss \n",
    "            # loss = cross_entropy(val_output, val_input_label)\n",
    "            loss = cross_entropy(torch.squeeze(val_output), val_input_label.float())\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "    # Compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fa283ff2-855a-48bf-acad-88f3e713cab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/ 5\n",
      "Batch    10 of    20.\n",
      "\n",
      "Evaluating...\n",
      "Batch    10 of    20.\n",
      "\n",
      "Training Loss: 0.72917\n",
      "Validation Loss: 0.77497\n",
      "\n",
      "Epoch 2/ 5\n",
      "Batch    10 of    20.\n",
      "\n",
      "Evaluating...\n",
      "Batch    10 of    20.\n",
      "\n",
      "Training Loss: 0.68087\n",
      "Validation Loss: 0.74844\n",
      "\n",
      "Epoch 3/ 5\n",
      "Batch    10 of    20.\n",
      "\n",
      "Evaluating...\n",
      "Batch    10 of    20.\n",
      "\n",
      "Training Loss: 0.61163\n",
      "Validation Loss: 0.71481\n",
      "\n",
      "Epoch 4/ 5\n",
      "Batch    10 of    20.\n",
      "\n",
      "Evaluating...\n",
      "Batch    10 of    20.\n",
      "\n",
      "Training Loss: 0.40079\n",
      "Validation Loss: 0.75339\n",
      "\n",
      "Epoch 5/ 5\n",
      "Batch    10 of    20.\n",
      "\n",
      "Evaluating...\n",
      "Batch    10 of    20.\n",
      "\n",
      "Training Loss: 0.14257\n",
      "Validation Loss: 1.30281\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "# Set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# Empty lists to store training and validation loss of each epoch\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "# For each epoch\n",
    "for epoch in range(epochs):\n",
    "    print ('\\nEpoch {:}/ {:}'.format(epoch+1, epochs))\n",
    "    \n",
    "    # Train model\n",
    "    train_loss = train(train_dataloader)\n",
    "    \n",
    "    # Evaluate model\n",
    "    valid_loss = evaluate(val_dataloader)\n",
    "    \n",
    "    # Save the best model\n",
    "    if valid_loss<best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'test_model.pt')\n",
    "        \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print (f\"\\nTraining Loss: {train_loss:.5f}\")\n",
    "    print (f\"Validation Loss: {valid_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b191b225-66f0-47a3-a4c7-7345072d2731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25e35db7e50>,\n",
       " <matplotlib.lines.Line2D at 0x25e35db7f40>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, 'g', valid_losses, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eca2964-13de-452b-b0f2-74375bef51ae",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "16cef46a-f3df-4904-b3bf-391ff1aa44ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\AppData\\Local\\Temp\\ipykernel_13100\\1946172375.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'test_model.pt'\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b3e6364-eaf5-4a65-b403-65dea34fa2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs_logits = []\n",
    "labels = []\n",
    "\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    # Push batch to GPU\n",
    "    batch = [r.to(device) for r in batch]\n",
    "    train_input_seq, train_input_mask, train_input_label = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get model predictions for the current batch\n",
    "        train_output = model(train_input_seq, train_input_mask)\n",
    "\n",
    "        all_outputs_logits += train_output\n",
    "        labels += train_input_label.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5f1c481d-ee09-4220-8eb5-8cdd83931585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f6705d20-c003-4c3f-9775-d84ad7aa6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "957eb4c8-d110-4680-8678-85460cf470a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs_proba = []\n",
    "for each in all_outputs_logits:\n",
    "    all_outputs_proba += sigmoid(each).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6546f20c-6a40-47f9-a3ce-a01892338c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs = [1 if i>0.5 else 0 for i in all_outputs_proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7da27c37-756b-4479-a4c2-37d1df540f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.87        13\n",
      "           1       1.00      0.85      0.92        27\n",
      "\n",
      "    accuracy                           0.90        40\n",
      "   macro avg       0.88      0.93      0.89        40\n",
      "weighted avg       0.92      0.90      0.90        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(all_outputs, labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
