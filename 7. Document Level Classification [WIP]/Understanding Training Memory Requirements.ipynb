{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e421ede4-03c8-4333-b0ba-311d5b5b452c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\miniconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from doc_classifier import doc_classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68b7b706-2de6-456b-984d-1ae66ebd0541",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:\\Data\\datasets\\imdb_long_text_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3979bca5-f021-41dd-9a16-3baf1d1d63fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>token_lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So im not a big fan of Boll's work but then ag...</td>\n",
       "      <td>negative</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The Cell\" is an exotic masterpiece, a dizzyin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'War movie' is a Hollywood genre that has been...</td>\n",
       "      <td>positive</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taut and organically gripping, Edward Dmytryk'...</td>\n",
       "      <td>positive</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One of the most significant quotes from the en...</td>\n",
       "      <td>positive</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  token_lengths\n",
       "0  So im not a big fan of Boll's work but then ag...  negative            563\n",
       "1  \"The Cell\" is an exotic masterpiece, a dizzyin...  positive            749\n",
       "2  'War movie' is a Hollywood genre that has been...  positive            845\n",
       "3  Taut and organically gripping, Edward Dmytryk'...  positive            608\n",
       "4  One of the most significant quotes from the en...  positive            908"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94fd28cd-5368-41f0-a46f-dde23d662f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], stratify=df['sentiment'], test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeafbc44-2efc-4ada-a19b-2d14471e7d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test\n",
      " sentiment\n",
      "positive    0.514089\n",
      "negative    0.485911\n",
      "Name: proportion, dtype: float64 \n",
      "\n",
      "y_val\n",
      " sentiment\n",
      "positive    0.514605\n",
      "negative    0.485395\n",
      "Name: proportion, dtype: float64 \n",
      "\n",
      "y_train\n",
      " sentiment\n",
      "positive    0.514071\n",
      "negative    0.485929\n",
      "Name: proportion, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"y_test\\n\", y_test.value_counts(normalize=True), '\\n')\n",
    "print (\"y_val\\n\", y_val.value_counts(normalize=True), '\\n')\n",
    "print (\"y_train\\n\", y_train.value_counts(normalize=True), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82dde6d3-dc65-4df9-860b-1d20aca7fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading spacy as sentence chunker\n",
    "# nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc1eb6e-c9e9-4216-abef-3c2797e71824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking each document\n",
    "# X_train_chunked = [nlp(each_sent) for each_sent in X_train]\n",
    "# X_train_chunked = [[sent for sent in nlp(each_sent).sents] for each_sent in X_train[:20]]\n",
    "\n",
    "\n",
    "# # Spacy takes too long, will chunk lexically first\n",
    "# X_train_chunked = [each_sent.split(\". \") for each_sent in X_train]\n",
    "# X_val_chunked = [each_sent.split(\". \") for each_sent in X_val\n",
    "# X_test_chunked = [each_sent.split(\". \") for each_sent in X_test]\n",
    "\n",
    "# Spacy takes too long, will chunk lexically first\n",
    "X_train_chunked = [each_sent.split(\". \") for each_sent in X_train[:20]]\n",
    "X_val_chunked = [each_sent.split(\". \") for each_sent in X_val[:10]]\n",
    "X_test_chunked = [each_sent.split(\". \") for each_sent in X_test[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1afd66c-d5ce-4a59-ae03-e2e2b7592a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max chunk length for X_train:  44\n",
      "Max chunk length for X_val:  28\n",
      "Max chunk length for X_test:  37\n"
     ]
    }
   ],
   "source": [
    "# Check max chunk length\n",
    "print (\"Max chunk length for X_train: \", max([len(chunks) for chunks in X_train_chunked]))\n",
    "print (\"Max chunk length for X_val: \", max([len(chunks) for chunks in X_val_chunked]))\n",
    "print (\"Max chunk length for X_test: \", max([len(chunks) for chunks in X_test_chunked]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14127fba-d0a3-427e-a26c-87dacf9d2c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4655"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a18e6b60-25a9-46c3-9a14-7521734121c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f03ede0-dab9-48dd-b218-86e5c7abadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f722b56-3b31-416a-8084-f89e92383f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\miniconda3\\envs\\nlp\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoder_path = \"D:\\\\DSAI\\\\Pre-Trained Models\\\\distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(encoder_path)\n",
    "encoder = AutoModel.from_pretrained(encoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a29c766-73ef-4aad-a86a-32bfd372d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = [[tokenizer(each_sent, padding='max_length', truncation=True, return_tensors='pt') for each_sent in each_doc] for each_doc in X_train_chunked]\n",
    "X_val_tokenized = [[tokenizer(each_sent, padding='max_length', truncation=True, return_tensors='pt') for each_sent in each_doc] for each_doc in X_val_chunked]\n",
    "X_test_tokenized = [[tokenizer(each_sent, padding='max_length', truncation=True, return_tensors='pt') for each_sent in each_doc] for each_doc in X_test_chunked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec02f1d6-9458-4add-b074-26702adee9f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train_tokenized[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90b3bba3-af81-46d5-914e-5d0094d407c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train_tokenized[0][0]['input_ids'].clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2de89c11-fabd-4b0d-9f04-4547598d6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_seq = [[sent['input_ids'].clone().detach() for sent in doc] for doc in X_train_tokenized]\n",
    "# train_mask = [[sent['attention_mask'].clone().detach() for sent in doc] for doc in X_train_tokenized]\n",
    "\n",
    "# val_seq = [[sent['input_ids'].clone().detach() for sent in doc] for doc in X_val_tokenized]\n",
    "# val_mask = [[sent['attention_mask'].clone().detach() for sent in doc] for doc in X_val_tokenized]\n",
    "\n",
    "# test_seq = [[sent['input_ids'].clone().detach() for sent in doc] for doc in X_test_tokenized]\n",
    "# test_mask = [[sent['attention_mask'].clone().detach() for sent in doc] for doc in X_test_tokenized]\n",
    "\n",
    "# train_label = torch.tensor(y_train.map({'positive':1, 'negative':0}).tolist())\n",
    "# val_label = torch.tensor(y_val.map({'positive':1, 'negative':0}).tolist())\n",
    "# test_label = torch.tensor(y_test.map({'positive':1, 'negative':0}).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd0f79ce-a785-438f-b12a-4dc5d563342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_tensors(document_corpus, embedding_to_extract, max_chunks=30, max_sentence_token_len=512):\n",
    "    doc_list = []\n",
    "    for doc in document_corpus:\n",
    "        sent_list = []\n",
    "        for sent in doc:\n",
    "            sent_list.append(sent[embedding_to_extract].clone().detach()[0])\n",
    "            \n",
    "        sent_seqs = torch.stack(sent_list, dim=0)\n",
    "    \n",
    "        if sent_seqs.size()[0] < max_chunks: # keep it below 30 sentences for now\n",
    "            empty_sent_to_pad = torch.zeros(max_chunks-sent_seqs.size()[0], max_sentence_token_len)\n",
    "    \n",
    "            sent_seqs = torch.cat((empty_sent_to_pad, sent_seqs), dim=0)\n",
    "    \n",
    "        else:\n",
    "            sent_seqs = sent_seqs[:max_chunks, :]\n",
    "    \n",
    "        doc_list.append(sent_seqs)\n",
    "\n",
    "    return torch.stack(doc_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c298891a-8589-4829-b684-06c2048501b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = get_doc_tensors(X_train_tokenized, embedding_to_extract='input_ids', max_chunks=10)\n",
    "train_mask = get_doc_tensors(X_train_tokenized, embedding_to_extract='attention_mask', max_chunks=10)\n",
    "\n",
    "val_seq = get_doc_tensors(X_val_tokenized, embedding_to_extract='input_ids', max_chunks=10)\n",
    "val_mask = get_doc_tensors(X_val_tokenized, embedding_to_extract='attention_mask', max_chunks=10)\n",
    "\n",
    "test_seq = get_doc_tensors(X_test_tokenized, embedding_to_extract='input_ids', max_chunks=10)\n",
    "test_mask = get_doc_tensors(X_test_tokenized, embedding_to_extract='attention_mask', max_chunks=10)\n",
    "\n",
    "# train_label = torch.tensor(y_train.map({'positive':1, 'negative':0}).tolist())\n",
    "# val_label = torch.tensor(y_val.map({'positive':1, 'negative':0}).tolist())\n",
    "# test_label = torch.tensor(y_test.map({'positive':1, 'negative':0}).tolist())\n",
    "\n",
    "train_label = torch.tensor(y_train.map({'positive':1, 'negative':0}).tolist()[:20])\n",
    "val_label = torch.tensor(y_val.map({'positive':1, 'negative':0}).tolist()[:10])\n",
    "test_label = torch.tensor(y_test.map({'positive':1, 'negative':0}).tolist()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54d7d7e0-e72d-422a-b045-e24de3602769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_list = []\n",
    "# for doc in X_train_tokenized:\n",
    "#     sent_list = []\n",
    "#     for sent in doc:\n",
    "#         sent_list.append(sent['input_ids'].clone().detach()[0])\n",
    "        \n",
    "#     sent_seqs = torch.stack(sent_list, dim=0)\n",
    "\n",
    "#     if sent_seqs.size()[0] < 30: # keep it below 30 sentences for now\n",
    "#         empty_sent_to_pad = torch.zeros(30-sent_seqs.size()[0], 512)\n",
    "\n",
    "#         sent_seqs = torch.cat((empty_sent_to_pad, sent_seqs), dim=0)\n",
    "\n",
    "#     else:\n",
    "#         sent_seqs = sent_seqs[:30, :]\n",
    "\n",
    "#     doc_list.append(sent_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c988505-9961-4067-ae35-3643f0ddd10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_seqs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "887b298e-9005-4e45-9b19-9a7eda41801c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.zeros(5, 512).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72c15c73-8520-45af-8af6-bd368917026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_seqs[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bff2607-928f-40ce-939a-7e7c9418720a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7475533-e0b8-48a3-af27-2d42877f8cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462fafb4-4f87-437c-b329-ae96e75fe443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3763e0e-ec17-4172-9139-61fe2f3946a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_seq = torch.stack(doc_list, dim=0) # Need to pas to max length for this one! Else the shape wont fit\n",
    "\n",
    "# Probably have to do the torch.zeros method and slowly fill in the tensor??\n",
    "## Dont need can just manuall pad the fucking thing.. damn annoying - Solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "018c13ae-9d09-454c-aec8-5fb6143408da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_seq.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "066ec74e-c2cf-4301-8480-57bb61b434df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_train_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18ceb388-e1a2-401b-bd2e-8c3b3ae504a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# len(X_train_tokenized[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57261f87-bba0-4ee8-9d16-d3ba41920542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_train_tokenized[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd9d09b7-fca2-4715-9ed6-bdfda7d77695",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sent_seqs[-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "087c0cb0-2ac6-4ee6-b4a6-7ad48d40b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_seq.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e2d70-e1f7-4329-9f06-d694011a83cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "342f1225-5dcc-493a-8825-18d8f0d775e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FOR TRAINING\n",
    "# # Define batch size\n",
    "# batch_size = 8\n",
    "\n",
    "# # Wrap tensors\n",
    "# train_data = TensorDataset(doc_seq)\n",
    "# # Sampler for sampling the data during training\n",
    "# train_sampler = SequentialSampler(train_data)\n",
    "# # Dataloader for train set\n",
    "# train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd215089-1149-4ab4-93b0-33e38ec7d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1997cec6-0410-4661-a9a8-b66d24dfc718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for num, batch in enumerate(train_dataloader):\n",
    "#     see = batch\n",
    "\n",
    "#     print (see[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2b34d56-b4ec-426b-b39e-37b9a7b33da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# see[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3236635-740e-48c4-b571-9daf47519332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sent_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fe82276-17d3-428d-a780-6580d9504d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.equal(see[0][-1], sent_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1835dfeb-daa5-4fa5-9845-0ffb0610bcf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# doc_seq[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6689195-4122-4193-a1c2-42cf07a29d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see[0][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e202593-013b-460a-a852-cf6e744eaccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.equal(see[0][-2], doc_seq[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b40cd79-162d-4477-9fcf-bf18537b982c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8e57e-e9dc-4370-9730-8e85a3d98d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92d8ca78-1c9f-49dd-9292-40de21b7b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.map({'positive':1, 'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db675143-4a25-4151-bfbe-a54b55189ea7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.tensor(y_train.map({'positive':1, 'negative':0}).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef52ef71-b6e1-4df8-ad93-4ec84bbcea81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f54ef36-4f5a-49b6-a601-2d9667603fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TRAINING\n",
    "# Define batch size\n",
    "batch_size = 2\n",
    "\n",
    "# Wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_label)\n",
    "# Sampler for sampling the data during training\n",
    "# train_sampler = SequentialSampler(train_data)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# Dataloader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_label)\n",
    "# Sampler for sampling the data during validation for training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "# Dataloader for val set\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Wrap tensors\n",
    "test_data = TensorDataset(test_seq, test_mask, test_label)\n",
    "# Sampler for sampling the data for testing\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "# Dataloader for test set\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f680b7-b5fd-4d48-96d7-e0d2d6ea2cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "382149e3-072a-4eb6-9a3e-b1e63e504bbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for step, batch in enumerate(train_dataloader):\n",
    "#     batch = [r.to(device) for r in batch]\n",
    "#     train_seq, train_mask, train_label = batch\n",
    "\n",
    "#     print(torch.cuda.memory_summary())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8eec708-ec0d-4e14-b36d-82dacd84aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FOR TRAINING\n",
    "# # Define batch size\n",
    "# batch_size = 8\n",
    "\n",
    "# # Wrap tensors\n",
    "# train_data = TensorDataset(train_seq, train_mask, train_label)\n",
    "# # Sampler for sampling the data during training\n",
    "# train_sampler = RandomSampler(train_data)\n",
    "# # Dataloader for train set\n",
    "# train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# # Wrap tensors\n",
    "# val_data = TensorDataset(val_seq, val_mask, val_label)\n",
    "# # Sampler for sampling the data during validation for training\n",
    "# val_sampler = SequentialSampler(val_data)\n",
    "# # Dataloader for val set\n",
    "# val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# # Wrap tensors\n",
    "# test_data = TensorDataset(test_seq, test_mask, test_label)\n",
    "# # Sampler for sampling the data for testing\n",
    "# test_sampler = SequentialSampler(test_data)\n",
    "# # Dataloader for test set\n",
    "# test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b0d24b6-e199-4206-84af-4fd4e05b0d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_anchor_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d53fa88-2399-45a4-a87f-4a75e958b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_anchor_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91f82804-bc65-4675-b110-dd0c07c643f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_anchor_seq[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "693b5b37-5fc4-4ca7-908f-cee6a2dabeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_train_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1785d149-9fe5-44c4-aea9-b508cc8d6f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train_chunked[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "edac36f0-c83f-42e2-ac37-ab3fe9cfad44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# len(X_train_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188a6c18-8a8c-4168-91bd-1e87d4cef4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94b10116-ec31-4a00-8980-12d0b529c8f8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "282a9df2-dfb4-480a-b9f6-06720e44f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for step, batch in enumerate(train_dataloader):\n",
    "#     if step == 0:\n",
    "#         train_seq, train_mask, train_label = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d2a204a-cd7b-4bdb-ab28-2cb46f4d3642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see_tok = tokenizer(['first sentence', 'second sentence'], padding='max_length', truncation=True, return_tensors='pt')\n",
    "# # see_tok = tokenizer(['second sentence'], padding='max_length', truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db4d086c-4266-4fd1-8c53-f34e9599aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see_embed = encoder(see_tok['input_ids'], see_tok['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b38e82b5-d23c-4def-aa58-b18e21314e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see_tok # Seems like there is CLS tokens for distilbert as well (id \"101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d53d0eb-bec7-41f6-8ea7-0c0c9cf84df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see_embed.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb5ab9-8907-4b4b-a8da-740f31740fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ec9ce888-220f-40de-9b3d-b430c8956e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([[[1,1,1], [2,2,2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02f644d8-bfd5-4621-a47c-c8669daf4d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.zeros((2,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "725a2c79-43da-4201-b72a-ce4b08648b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = np.ones((8,10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "894fc4e2-1d7a-4a7a-b452-ed23cb58d6e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c2740ae-69b2-40fc-a6f4-0f30598ae453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a[0,0] = [2,2,2]\n",
    "# a[1,0] = [1,1,1]\n",
    "# a[2,0] = [1,1,1]\n",
    "# a[3,0] = [1,1,1]\n",
    "# a[4,0] = [1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6468ddc4-45a0-4cf6-9373-a31560786e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b6463ff1-e130-46cd-95cf-c57fc7e462b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c9c88-dd30-4dec-9610-5333e015f0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "89da651a-9c40-4a28-a708-bd20e526b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_seq.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2d57345f-ab28-4375-bae1-1f32dbff7a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_seq.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "97701150-1f1b-45d4-b443-758a4b76e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_seq.size()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1c9cad6-c547-47f4-8d76-7f590ef28fa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e3c235-e288-4e80-9864-97e46049812d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d03d1-c063-4327-a38e-32378e8e46fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cfbe81-a667-4fb6-a456-eb096b923665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8c53926-4181-4a99-8717-92af7f282933",
   "metadata": {},
   "source": [
    "---\n",
    "## Training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4eb587be-34fa-48ee-9ee8-bf9acc63a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = doc_classifier(encoder, dropout=0.2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b3e1f188-5d36-4ba8-abcf-f42c5cf5360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "87b14626-0a3a-423f-abe4-2b9781c9a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "# Define optimiser\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "18460847-43b2-4ddb-99f8-c322878aed5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\solom\\AppData\\Local\\Temp\\ipykernel_6012\\3720588486.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  weight = np.array(y_train.value_counts()[0]/y_train.value_counts()[1])\n",
      "C:\\Users\\solom\\AppData\\Local\\Temp\\ipykernel_6012\\3720588486.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  weight = np.array(y_train.value_counts()[0]/y_train.value_counts()[1])\n"
     ]
    }
   ],
   "source": [
    "weight = np.array(y_train.value_counts()[0]/y_train.value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3c0908ad-99da-4c99-8a77-0fd427644ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting list of class weights to a tensor\n",
    "weights = torch.tensor(weight, dtype=torch.float)\n",
    "\n",
    "# Push weights to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# Define loss function\n",
    "cross_entropy = nn.BCEWithLogitsLoss(pos_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "559242b9-1630-4508-8dd4-22d5db6a778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # Empty list to save model predictions\n",
    "    total_preds = []\n",
    "    \n",
    "    # Iterate over batches\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Progress update for every 50 batches\n",
    "        if step%10==0 and not step==0:\n",
    "            print ('Batch {:>5,} of {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        print(\"Before sending batch to GPU\")\n",
    "        print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "        print (\"-----\")\n",
    "\n",
    "        # Push batch to GPU\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        train_input_seq, train_input_mask, train_input_label = batch\n",
    "\n",
    "        print(\"After sending batch to GPU\")\n",
    "        print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "        print (\"-----\")\n",
    "\n",
    "        # Clear previously calculated gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        print(\"Before passing through model\")\n",
    "        print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "        print (\"-----\")\n",
    "\n",
    "\n",
    "        # Get model predictions for the current batch\n",
    "        train_output = model(train_input_seq, train_input_mask)\n",
    "\n",
    "        # def getActivation(name):\n",
    "        #     # the hook signature\n",
    "        #     def hook(model, input, output):\n",
    "        #         activation[name] = output.detach()\n",
    "        #         print(output.detach())\n",
    "        #     return hook\n",
    "        \n",
    "        # h = model.encoder.transformer.register_forward_hook(getActivation('output_layer_norm'))\n",
    "        # print (h.remove())\n",
    "\n",
    "        print(\"After passing through model\")\n",
    "        print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "        print (\"-----\")\n",
    "        \n",
    "        \"\"\"\n",
    "        nn.CosineSimilarity measures similarity between 2 outputs, the more similar, the bigger the score.\n",
    "        However for triplet loss, the positive cases are supposed to be closer and have a smaller score.\n",
    "        To make things easier, we flipped the negative and positive positions\n",
    "        i.e. loss(anchor, positive, negative) --> loss(anchor, negative, positive)\n",
    "        \"\"\"\n",
    "\n",
    "        # print (train_output, train_input_label)\n",
    "        # print (torch.squeeze(train_output))\n",
    "        \n",
    "        # Compute loss \n",
    "        # loss = cross_entropy(train_output, train_input_label)\n",
    "        loss = cross_entropy(torch.squeeze(train_output), train_input_label.float())\n",
    "\n",
    "        # Add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        print(\"Before backpropagation\")\n",
    "        print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "        print (\"-----\")\n",
    "\n",
    "        # Backward pass to calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\"After backpropagation\")\n",
    "        print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "        print(\"=====\")\n",
    "\n",
    "    # Compute training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "99269c15-840a-43b9-acc8-fd18b59ef47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val_dataloader):\n",
    "    print ('\\nEvaluating...')\n",
    "    \n",
    "    # Deactivate dropout layers\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    \n",
    "    # Empty list to save model predictions\n",
    "    total_preds = []\n",
    "    \n",
    "    # Iterate over batches\n",
    "    for step, batch in enumerate(val_dataloader):\n",
    "        # Progress update for every 50 batches\n",
    "        if step%10==0 and not step==0:\n",
    "            print ('Batch {:>5,} of {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # Push batch to GPU\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        val_input_seq, val_input_mask, val_input_label = batch\n",
    "\n",
    "        # Deactivate autograd()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            \n",
    "            # Get model predictions for the current batch\n",
    "            val_output = model(val_input_seq, val_input_mask)\n",
    "        \n",
    "            \"\"\"\n",
    "            nn.CosineSimilarity measures similarity between 2 outputs, the more similar, the bigger the score.\n",
    "            However for triplet loss, the positive cases are supposed to be closer and have a smaller score.\n",
    "            To make things easier, we flipped the negative and positive positions\n",
    "            i.e. loss(anchor, positive, negative) --> loss(anchor, negative, positive)\n",
    "            \"\"\"\n",
    "\n",
    "            # Compute loss \n",
    "            # loss = cross_entropy(val_output, val_input_label)\n",
    "            loss = cross_entropy(torch.squeeze(val_output), val_input_label.float())\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "    # Compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa283ff2-855a-48bf-acad-88f3e713cab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/ 10\n",
      "Before sending batch to GPU\n",
      "torch.cuda.memory_allocated: 0.257084GB\n",
      "torch.cuda.memory_reserved: 0.285156GB\n",
      "torch.cuda.max_memory_reserved: 0.285156GB\n",
      "-----\n",
      "After sending batch to GPU\n",
      "torch.cuda.memory_allocated: 0.257161GB\n",
      "torch.cuda.memory_reserved: 0.285156GB\n",
      "torch.cuda.max_memory_reserved: 0.285156GB\n",
      "-----\n",
      "Before passing through model\n",
      "torch.cuda.memory_allocated: 0.257161GB\n",
      "torch.cuda.memory_reserved: 0.285156GB\n",
      "torch.cuda.max_memory_reserved: 0.285156GB\n",
      "-----\n",
      "After passing through model\n",
      "torch.cuda.memory_allocated: 6.415343GB\n",
      "torch.cuda.memory_reserved: 6.441406GB\n",
      "torch.cuda.max_memory_reserved: 6.441406GB\n",
      "-----\n",
      "Before backpropagation\n",
      "torch.cuda.memory_allocated: 6.415344GB\n",
      "torch.cuda.memory_reserved: 6.441406GB\n",
      "torch.cuda.max_memory_reserved: 6.441406GB\n",
      "-----\n",
      "After backpropagation\n",
      "torch.cuda.memory_allocated: 1.072346GB\n",
      "torch.cuda.memory_reserved: 6.824219GB\n",
      "torch.cuda.max_memory_reserved: 6.824219GB\n",
      "=====\n",
      "Before sending batch to GPU\n",
      "torch.cuda.memory_allocated: 1.072346GB\n",
      "torch.cuda.memory_reserved: 6.824219GB\n",
      "torch.cuda.max_memory_reserved: 6.824219GB\n",
      "-----\n",
      "After sending batch to GPU\n",
      "torch.cuda.memory_allocated: 1.072346GB\n",
      "torch.cuda.memory_reserved: 6.824219GB\n",
      "torch.cuda.max_memory_reserved: 6.824219GB\n",
      "-----\n",
      "Before passing through model\n",
      "torch.cuda.memory_allocated: 0.807087GB\n",
      "torch.cuda.memory_reserved: 6.824219GB\n",
      "torch.cuda.max_memory_reserved: 6.824219GB\n",
      "-----\n",
      "After passing through model\n",
      "torch.cuda.memory_allocated: 6.961485GB\n",
      "torch.cuda.memory_reserved: 6.988281GB\n",
      "torch.cuda.max_memory_reserved: 6.988281GB\n",
      "-----\n",
      "Before backpropagation\n",
      "torch.cuda.memory_allocated: 6.961486GB\n",
      "torch.cuda.memory_reserved: 6.988281GB\n",
      "torch.cuda.max_memory_reserved: 6.988281GB\n",
      "-----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m/ \u001b[39m\u001b[38;5;132;01m{:}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, epochs))\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[0;32m     18\u001b[0m valid_loss \u001b[38;5;241m=\u001b[39m evaluate(val_dataloader)\n",
      "Cell \u001b[1;32mIn[72], line 84\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_dataloader)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-----\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Backward pass to calculate gradients\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[0;32m     87\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp\\lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp\\lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "# Set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# Empty lists to store training and validation loss of each epoch\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "# For each epoch\n",
    "for epoch in range(epochs):\n",
    "    print ('\\nEpoch {:}/ {:}'.format(epoch+1, epochs))\n",
    "    \n",
    "    # Train model\n",
    "    train_loss = train(train_dataloader)\n",
    "    \n",
    "    # Evaluate model\n",
    "    valid_loss = evaluate(val_dataloader)\n",
    "    \n",
    "    # Save the best model\n",
    "    if valid_loss<best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'test_model.pt')\n",
    "        \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print (f\"\\nTraining Loss: {train_loss:.5f}\")\n",
    "    print (f\"Validation Loss: {valid_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6ef0106f-6cbb-4bf4-ae93-4c76847157f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "203f4616-7391-4b32-aed2-7b17113be6da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0f818ff9-c4e1-4711-bdb1-521ce29a9de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = {}\n",
    "def get_activation_attn(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output[0].detach()\n",
    "    return hook\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c94c1b0e-4003-40c4-b37e-e5d465f55fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x2f0ae7d84c0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.transformer.layer[0].attention.register_forward_hook(get_activation_attn('out_lin'))\n",
    "model.register_forward_hook(get_activation('attn'))\n",
    "model.register_forward_hook(get_activation('fc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8dde33e4-f5f3-4e6d-9b59-6d4c9bf29864",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for each, batch in enumerate(train_dataloader):\n",
    "    # Push batch to GPU\n",
    "    batch = [r.to(device) for r in batch]\n",
    "    train_input_seq, train_input_mask, train_input_label = batch\n",
    "\n",
    "    # Clear previously calculated gradients\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Get model predictions for the current batch\n",
    "    train_output = model(train_input_seq, train_input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4e2d9ec1-6baf-4e23-9c60-2259e83a945c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2922],\n",
       "        [0.3030]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b6cf3a9f-59b5-4cc6-8578-05ae932d24ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0935, -0.2781,  0.0464,  ...,  0.2565,  0.1163,  0.4425],\n",
      "         [ 0.3404,  0.9756, -0.3835,  ...,  0.1363,  0.3854, -0.0914],\n",
      "         [-0.1750,  0.8955,  0.5584,  ...,  0.2086,  0.5893,  0.0634],\n",
      "         ...,\n",
      "         [ 0.5768,  0.2107,  0.3207,  ..., -0.3443,  0.2117, -0.1269],\n",
      "         [ 0.5465, -0.0526,  0.4327,  ...,  0.0870,  0.1898, -0.2098],\n",
      "         [ 0.5152,  0.1919,  0.3169,  ..., -0.2005,  0.2022, -0.0837]]],\n",
      "       device='cuda:0')\n",
      "-----\n",
      "tensor([[0.2922],\n",
      "        [0.3030]], device='cuda:0')\n",
      "-----\n",
      "tensor([[0.2922],\n",
      "        [0.3030]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(activation['out_lin'])\n",
    "print(\"-----\")\n",
    "print(activation['attn'])\n",
    "print(\"-----\")\n",
    "print(activation['fc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea76c914-16b2-44af-83ed-f9b055f5f32d",
   "metadata": {},
   "source": [
    "---\n",
    "Based on what I understand, during forward pass, the model saves the activation (or the intermediate output) values as well. This would mean that the memory requirements will scale with batch size.. i.e. for each layer, the `intermediate output memory requirements` X `batch size` will be the additional memory requirements as batch size scales.\n",
    "\n",
    "See the following article for further explanation on why gradient accumulation reduces memory requirements - https://medium.com/@mccartni/implications-of-batch-size-on-llm-training-and-inference-3320cb48d610#:~:text=Larger%20batch%20sizes%20mean%20more,which%20increases%20the%20memory%20footprint.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
