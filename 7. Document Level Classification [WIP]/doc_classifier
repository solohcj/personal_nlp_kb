import spacy
import torch
import torch.nn as nn

nlp = spacy.load("en_core_web_sm")

class doc_classifier(nn.Module):
    def __init__(self, encoder, dropout):
        super(doc_classifier, self).__init__()
        self.encoder = encoder
        # self.output_hidden_dim = encoder.config.dim

        # self.attn = nn.MultiheadAttention(embed_dim=self.hidden_size*2, num_heads=4, batch_first=True)
        # self.attn = MultiheadAttention(embed_dim=self.output_hidden_dim, num_heads=4, batch_first=True)
        self.attn = MultiheadAttention(embed_dim=768, num_heads=4, batch_first=True)
        self.fc = nn.Linear(self.output_hidden_dim, 1)
        self.dropout = nn.Dropout(dropout)


    def forward(self, document_seq, document_mask):
        for document in document_seq:
            encoded_sent = 




    # query = torch.ones(outputs.size()[0], 1, outputs.size()[2]).to(device) # Note: ".to(device)"" will not work when imported on another script, use alternatives!
    # attn_outputs = self.attn(query=query, key=outputs, value=outputs)

    
    # output = self.dropout(attn_outputs[:,-1,:])
    # output = self.fc(output)      